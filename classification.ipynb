{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XKRjcPtHpur1",
        "zUilbSpoFOVl",
        "Uk3KLCBaFQz9",
        "QLR9VZsUFZon",
        "hLEdcGlcFiu-",
        "IH6oe9pHppTG",
        "2vx4SfEJp084",
        "W71YiA0Wp8yd",
        "tE9_9O73qB5i",
        "XeMBgU_BAjTp",
        "jx92iAvB0LZk",
        "nnRI-iVO2a3w",
        "uNWxj_y15o1s",
        "H599mf_9WBnM",
        "UUGKpBBbH3LX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f1eeee7b5e540bfbdf734c16043e07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1dbd8d39a0b42b5833fb58ce596563d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_19128b56008748fca2b61805755b7ad4",
              "IPY_MODEL_48129374b85d439fb540c236a7855b12"
            ]
          }
        },
        "d1dbd8d39a0b42b5833fb58ce596563d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19128b56008748fca2b61805755b7ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_e86c42d813e14029888f565201f982da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d94c123e3b04d7bb7a3d0630f00b38e"
          }
        },
        "48129374b85d439fb540c236a7855b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df86252c504745d89a1e393a5ac41ee3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2adbe73dc9f44f7887194cfd66e4ec7b"
          }
        },
        "e86c42d813e14029888f565201f982da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d94c123e3b04d7bb7a3d0630f00b38e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df86252c504745d89a1e393a5ac41ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2adbe73dc9f44f7887194cfd66e4ec7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a6b659a22914b82960c19ac5cd6a1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e4c7182df454c84887a08b1c35539f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5036e38dafdd4918b778510544022393",
              "IPY_MODEL_f546fce7e8fd4f93b6954e7d00b62b19"
            ]
          }
        },
        "9e4c7182df454c84887a08b1c35539f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5036e38dafdd4918b778510544022393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_52a48de567444c5fbdc174c4dbc234c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.19MB of 0.19MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a6f654f092a458e81a63ea48ba94d75"
          }
        },
        "f546fce7e8fd4f93b6954e7d00b62b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63948d0e8d24447d88c1d5def15b3569",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f2c0c5f832f4d23af5a73546d84455b"
          }
        },
        "52a48de567444c5fbdc174c4dbc234c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a6f654f092a458e81a63ea48ba94d75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63948d0e8d24447d88c1d5def15b3569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f2c0c5f832f4d23af5a73546d84455b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c599a644682b4a9cbf492168d3d17a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ceb37a48d7940e9a4c7d3ada286a633",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06505e507b014867bb6fed4668f30b9d",
              "IPY_MODEL_c60bb9e03eb746cf8cfaa355a5ac0ffc"
            ]
          }
        },
        "6ceb37a48d7940e9a4c7d3ada286a633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06505e507b014867bb6fed4668f30b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_9b8a2eb1d4c14c09a9714e6339176afa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ffea6b840414361a6d59adceac8a4de"
          }
        },
        "c60bb9e03eb746cf8cfaa355a5ac0ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96444408c1ee4d20857dadf06d11d993",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ceb77a8fb5cb4239a8b99fa81471b285"
          }
        },
        "9b8a2eb1d4c14c09a9714e6339176afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ffea6b840414361a6d59adceac8a4de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96444408c1ee4d20857dadf06d11d993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ceb77a8fb5cb4239a8b99fa81471b285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "beba87e9c07c47ee948ee657e66148c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_31bbcfec2f59470ea10b85e42ad7ef71",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e6eb7c6cba58437aac5d0d18d0dd472a",
              "IPY_MODEL_b85ef77bcdbc44a2a8b333a165b11c66"
            ]
          }
        },
        "31bbcfec2f59470ea10b85e42ad7ef71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6eb7c6cba58437aac5d0d18d0dd472a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_07356664ee0f418c9108b69e4e98750a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6d9866ae62b4161925afe4376e14851"
          }
        },
        "b85ef77bcdbc44a2a8b333a165b11c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c4628bb8d2e249d2b2d6419b3fcb65be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c49671e2d1b642f7995141a2182dbdad"
          }
        },
        "07356664ee0f418c9108b69e4e98750a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6d9866ae62b4161925afe4376e14851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4628bb8d2e249d2b2d6419b3fcb65be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c49671e2d1b642f7995141a2182dbdad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5228558a715c4064826364e40d9b6e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d585c222da8d482bbf55a860eec69bbb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e64c5791a0e14519a0df184ca837e584",
              "IPY_MODEL_b4e81d47fbd24ed49b67db4291c992de"
            ]
          }
        },
        "d585c222da8d482bbf55a860eec69bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e64c5791a0e14519a0df184ca837e584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_61139f87c77b4b29a86f94db948ca8eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.12MB of 0.12MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3264703b613b4aa285b065b67ba9c4a2"
          }
        },
        "b4e81d47fbd24ed49b67db4291c992de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_07d439f61ae742cdb49b5c5ee5a0254d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_736ddf88c6f8456ca49f840bd0a22b37"
          }
        },
        "61139f87c77b4b29a86f94db948ca8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3264703b613b4aa285b065b67ba9c4a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07d439f61ae742cdb49b5c5ee5a0254d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "736ddf88c6f8456ca49f840bd0a22b37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2abf28ee14124ea1b80bd0ffc4c23cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_972a73e679414706a689234d11995bd3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03d5d7d97d8f41069834353e81325313",
              "IPY_MODEL_89ee3c829ed84894848551c4d4094c72"
            ]
          }
        },
        "972a73e679414706a689234d11995bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03d5d7d97d8f41069834353e81325313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_2b05cce10447431c9cbf2c49e9de01fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cac470f17304860aca892ce95e25db7"
          }
        },
        "89ee3c829ed84894848551c4d4094c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_67423c3a07514619aca225a6f2acfbe6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45414ac66e8a46c4acdadc456278dd5c"
          }
        },
        "2b05cce10447431c9cbf2c49e9de01fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cac470f17304860aca892ce95e25db7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67423c3a07514619aca225a6f2acfbe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45414ac66e8a46c4acdadc456278dd5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a79a6283d194f7f9067ea504f508687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a19a7be3cd144ce5bbe8c3c3cb5e4b41",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_80d5cd65eace459483ff43217695aefd",
              "IPY_MODEL_88738f1758a443c389c0ce3a4969fc36"
            ]
          }
        },
        "a19a7be3cd144ce5bbe8c3c3cb5e4b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80d5cd65eace459483ff43217695aefd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_43a28980aa6a4616b02199ca1cde9654",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f545e1623704e4ca6a7b7a1329f355a"
          }
        },
        "88738f1758a443c389c0ce3a4969fc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_abb74f89dc334aecae3547b3f753a2de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8274783bf8c741feaa15c3001a912067"
          }
        },
        "43a28980aa6a4616b02199ca1cde9654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f545e1623704e4ca6a7b7a1329f355a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abb74f89dc334aecae3547b3f753a2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8274783bf8c741feaa15c3001a912067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8c143ed8dc847c68faf2b1cd54f7953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_94a0771e4f364627a34ead8b5e590e8f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f5ab5fad565740529824fcd482c98c85",
              "IPY_MODEL_40f69fa409fd46f683b491c296fe72a4"
            ]
          }
        },
        "94a0771e4f364627a34ead8b5e590e8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5ab5fad565740529824fcd482c98c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_754a30f60c7a46f6856fb44151fc5a24",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.19MB of 0.19MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37669e9124c844939ae617bc3ad6096a"
          }
        },
        "40f69fa409fd46f683b491c296fe72a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0d02067f93764de7ab9447f86e4e8b69",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d07264cf1c4144e094fcc1083fea0ade"
          }
        },
        "754a30f60c7a46f6856fb44151fc5a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37669e9124c844939ae617bc3ad6096a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d02067f93764de7ab9447f86e4e8b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d07264cf1c4144e094fcc1083fea0ade": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "808a21cd4e1f407fb29c95915698a448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b295c88ea3f9419b920abbc36e7d4cd5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ade0e8fb0c0f475f819886244468b30f",
              "IPY_MODEL_fa9dac23c4c64db1987b9ea4baca9c95"
            ]
          }
        },
        "b295c88ea3f9419b920abbc36e7d4cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ade0e8fb0c0f475f819886244468b30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_f213e31a9c7f497188bb7009f90a480f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_639ab088891d420e9e824c058eb99629"
          }
        },
        "fa9dac23c4c64db1987b9ea4baca9c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc5c3838dc0c46ac9f705ee7975991fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ef432af29cd4fb9a8ef5e177a885de7"
          }
        },
        "f213e31a9c7f497188bb7009f90a480f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "639ab088891d420e9e824c058eb99629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc5c3838dc0c46ac9f705ee7975991fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ef432af29cd4fb9a8ef5e177a885de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKRjcPtHpur1"
      },
      "source": [
        "# IMPORTS + FILES 😵‍💫"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-HUeeg36Yu7",
        "outputId": "989466b8-ffde-4ff4-a350-0dd980fecd09"
      },
      "source": [
        "import dill\n",
        "from pathlib import Path\n",
        "Path('bink.pickle').write_bytes(dill.dumps(classification_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5397"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwXPvnYc9Rth"
      },
      "source": [
        "genius = pd.read_csv('DA_BIG_MAN_GENIUS_PCT_MINMAX_NO_ID.csv')\n",
        "pct_scaled_big_x = pd.read_csv('DA_BIG_MAN_PCT_MINMAX_NO_ID.csv')\n",
        "g10test = pd.read_csv('GENIUS_Y_TEST_10.csv')\n",
        "g10train = pd.read_csv('GENIUS_Y_TRAIN_10.csv')\n",
        "g6test = pd.read_csv('GENIUS_Y_TEST_6.csv')\n",
        "g6train = pd.read_csv('GENIUS_Y_TRAIN_6.csv')\n",
        "g3test = pd.read_csv('GENIUS_Y_TEST_TRI.csv')\n",
        "g3train = pd.read_csv('GENIUS_Y_TRAIN_TRI.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y4kIEDI_-u_"
      },
      "source": [
        "gxtrain = pd.read_csv('GENIUS_X_TRAIN.csv')\n",
        "gxtest = pd.read_csv('GENIUS_X_TEST.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVlluwsX9_QJ"
      },
      "source": [
        "the_real_one = pd.read_csv('THE_REAL_ONE.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zfeADYZoKpr"
      },
      "source": [
        "import numpy as np \n",
        "import sklearn as sk\n",
        "from sklearn import datasets\n",
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "from sklearn import linear_model\n",
        "from sklearn import cluster\n",
        "from sklearn import model_selection\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import Ridge, Lasso, ARDRegression\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import NuSVR, SVR\n",
        "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import FactorAnalysis, PCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_curve, roc_curve, accuracy_score\n",
        "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.feature_selection import f_regression\n",
        "import numpy as np \n",
        "import sklearn as sk\n",
        "from sklearn import datasets\n",
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "from sklearn import linear_model\n",
        "from sklearn import cluster\n",
        "from sklearn import model_selection\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import Ridge, Lasso, ARDRegression\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import NuSVR, SVR, SVC\n",
        "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import FactorAnalysis, PCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_curve, roc_curve, accuracy_score\n",
        "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score, average_precision_score, brier_score_loss, f1_score, jaccard_score, precision_recall_curve\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pClZBnnOM1ju"
      },
      "source": [
        "import dill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "_piKYds3NC9D",
        "outputId": "35195853-2608-4083-cfd1-5a0b97b3260e"
      },
      "source": [
        "dill.dump_session('bungus.db')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-353-1f006a4e1e37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bungus.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dill/_dill.py\u001b[0m in \u001b[0;36mdump_session\u001b[0;34m(filename, main, byref, **kwds)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recurse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;31m# disable pickling recursion for globals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# is best indicator of when pickling a session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# If newly opened file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dill/_dill.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mPicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mStockPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# clear record of 'recursion-sensitive' pickled objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dill/_dill.py\u001b[0m in \u001b[0;36msave_module\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 + [\"__builtins__\", \"__loader__\"]]\n\u001b[1;32m   1326\u001b[0m             pickler.save_reduce(_import_module, (obj.__name__,), obj=obj,\n\u001b[0;32m-> 1327\u001b[0;31m                                 state=_main_dict)\n\u001b[0m\u001b[1;32m   1328\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# M1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dill/_dill.py\u001b[0m in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0;31m# we only care about session the first pass thru\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0mStockPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# D2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    883\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dill/_dill.py\u001b[0m in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0;31m# we only care about session the first pass thru\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0mStockPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# D2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    883\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't pickle dict_keys objects"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edmeiNcmv6qS"
      },
      "source": [
        "x_scaled_test = pd.read_csv('X_SCALED_TEST.csv')\n",
        "x_scaled_train = pd.read_csv('X_SCALED_TRAIN.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk4laVd3W5ii"
      },
      "source": [
        "the_real_one = pd.read_csv('THE_REAL_ONE.csv')\n",
        "the_real_one = the_real_one.drop('pitchfork_id', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gFwBgfXSpJb"
      },
      "source": [
        "genius_scores = pd.read_csv('DA_BIG_MAN_GENIUS_PCT_MINMAX.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "OKc7mcvUTrf4",
        "outputId": "691b272b-1a45-4330-f648-4998b6cfb532"
      },
      "source": [
        "genius_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pitchfork_id</th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year_x</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_pct_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_pct_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_pct_followers</th>\n",
              "      <th>track0_dur_pct</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness_pct</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_pct</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness_pct</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>...</th>\n",
              "      <th>track18_percent_unique_words</th>\n",
              "      <th>track18_percent_expletive_words</th>\n",
              "      <th>track18_percentile_total_words</th>\n",
              "      <th>track18_lyric_happy_score</th>\n",
              "      <th>track18_lyric_surprise_score</th>\n",
              "      <th>track18_lyric_sad_score</th>\n",
              "      <th>track18_lyric_angry_score</th>\n",
              "      <th>track18_lyric_fear_score</th>\n",
              "      <th>track19_genius_pageviews</th>\n",
              "      <th>track19_is_eng</th>\n",
              "      <th>track19_ttr_lexical_richness</th>\n",
              "      <th>track19_nltk_neg</th>\n",
              "      <th>track19_nltk_neu</th>\n",
              "      <th>track19_nltk_pos</th>\n",
              "      <th>track19_nltk_compound</th>\n",
              "      <th>track19_textblob_polarity</th>\n",
              "      <th>track19_textblob_subjectivity</th>\n",
              "      <th>track19_percent_unique_words</th>\n",
              "      <th>track19_percent_expletive_words</th>\n",
              "      <th>track19_percentile_total_words</th>\n",
              "      <th>track19_lyric_happy_score</th>\n",
              "      <th>track19_lyric_surprise_score</th>\n",
              "      <th>track19_lyric_sad_score</th>\n",
              "      <th>track19_lyric_angry_score</th>\n",
              "      <th>track19_lyric_fear_score</th>\n",
              "      <th>artist_x</th>\n",
              "      <th>album_x</th>\n",
              "      <th>score_x</th>\n",
              "      <th>link_x</th>\n",
              "      <th>release_year_y</th>\n",
              "      <th>artist_y</th>\n",
              "      <th>album_y</th>\n",
              "      <th>score_y</th>\n",
              "      <th>link_y</th>\n",
              "      <th>release_year_x</th>\n",
              "      <th>artist</th>\n",
              "      <th>album</th>\n",
              "      <th>score</th>\n",
              "      <th>link</th>\n",
              "      <th>release_year_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>18</td>\n",
              "      <td>8.156342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.780297</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>11.10</td>\n",
              "      <td>19.191527</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>51.020574</td>\n",
              "      <td>60.0</td>\n",
              "      <td>14.90</td>\n",
              "      <td>78.776339</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>6.37</td>\n",
              "      <td>14.233384</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>57.351213</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Eve Adams</td>\n",
              "      <td>Metal Bird</td>\n",
              "      <td>7.5</td>\n",
              "      <td>/reviews/albums/eve-adams-metal-bird/</td>\n",
              "      <td>2021</td>\n",
              "      <td>Eve Adams</td>\n",
              "      <td>Metal Bird</td>\n",
              "      <td>7.5</td>\n",
              "      <td>/reviews/albums/eve-adams-metal-bird/</td>\n",
              "      <td>2021</td>\n",
              "      <td>Eve Adams</td>\n",
              "      <td>Metal Bird</td>\n",
              "      <td>7.5</td>\n",
              "      <td>/reviews/albums/eve-adams-metal-bird/</td>\n",
              "      <td>2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>69</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>73.725664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.840512</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.54</td>\n",
              "      <td>55.104087</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>41.435255</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.80</td>\n",
              "      <td>83.937167</td>\n",
              "      <td>100</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>8.82</td>\n",
              "      <td>37.670224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>28.077624</td>\n",
              "      <td>60.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Drakeo the Ruler</td>\n",
              "      <td>The Truth Hurts</td>\n",
              "      <td>7.7</td>\n",
              "      <td>/reviews/albums/drakeo-the-ruler-the-truth-hurts/</td>\n",
              "      <td>2021</td>\n",
              "      <td>Drakeo the Ruler</td>\n",
              "      <td>The Truth Hurts</td>\n",
              "      <td>7.7</td>\n",
              "      <td>/reviews/albums/drakeo-the-ruler-the-truth-hurts/</td>\n",
              "      <td>2021</td>\n",
              "      <td>Drakeo the Ruler</td>\n",
              "      <td>The Truth Hurts</td>\n",
              "      <td>7.7</td>\n",
              "      <td>/reviews/albums/drakeo-the-ruler-the-truth-hurts/</td>\n",
              "      <td>2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>99.677655</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>50</td>\n",
              "      <td>42.112094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.335592</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>66.70</td>\n",
              "      <td>9.573199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>51.196189</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.10</td>\n",
              "      <td>94.482624</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>45.454545</td>\n",
              "      <td>11.10</td>\n",
              "      <td>36.129761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>72.899161</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sam Gendel</td>\n",
              "      <td>Fresh Bread</td>\n",
              "      <td>6.5</td>\n",
              "      <td>/reviews/albums/sam-gendel-fresh-bread/</td>\n",
              "      <td>2021</td>\n",
              "      <td>Sam Gendel</td>\n",
              "      <td>Fresh Bread</td>\n",
              "      <td>6.5</td>\n",
              "      <td>/reviews/albums/sam-gendel-fresh-bread/</td>\n",
              "      <td>2021</td>\n",
              "      <td>Sam Gendel</td>\n",
              "      <td>Fresh Bread</td>\n",
              "      <td>6.5</td>\n",
              "      <td>/reviews/albums/sam-gendel-fresh-bread/</td>\n",
              "      <td>2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>43</td>\n",
              "      <td>64.511617</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>57</td>\n",
              "      <td>71.675516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.399671</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>5.37</td>\n",
              "      <td>31.657482</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>46.134125</td>\n",
              "      <td>80.0</td>\n",
              "      <td>44.30</td>\n",
              "      <td>74.196647</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>9.89</td>\n",
              "      <td>38.026507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>64.828019</td>\n",
              "      <td>80.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Altin Gün</td>\n",
              "      <td>Yol</td>\n",
              "      <td>7.6</td>\n",
              "      <td>/reviews/albums/altin-gun-yol/</td>\n",
              "      <td>2021</td>\n",
              "      <td>Altin Gün</td>\n",
              "      <td>Yol</td>\n",
              "      <td>7.6</td>\n",
              "      <td>/reviews/albums/altin-gun-yol/</td>\n",
              "      <td>2021</td>\n",
              "      <td>Altin Gün</td>\n",
              "      <td>Yol</td>\n",
              "      <td>7.6</td>\n",
              "      <td>/reviews/albums/altin-gun-yol/</td>\n",
              "      <td>2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>60</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>98.461538</td>\n",
              "      <td>68</td>\n",
              "      <td>87.244838</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.345579</td>\n",
              "      <td>100</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.70</td>\n",
              "      <td>50.087619</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>70.518085</td>\n",
              "      <td>60.0</td>\n",
              "      <td>90.50</td>\n",
              "      <td>82.834537</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>34.30</td>\n",
              "      <td>36.432998</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>55.915407</td>\n",
              "      <td>80.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>King Gizzard &amp; The Lizard Wizard</td>\n",
              "      <td>K.G.</td>\n",
              "      <td>8.0</td>\n",
              "      <td>/reviews/albums/king-gizzard-and-the-lizard-wi...</td>\n",
              "      <td>2021</td>\n",
              "      <td>King Gizzard &amp; The Lizard Wizard</td>\n",
              "      <td>K.G.</td>\n",
              "      <td>8.0</td>\n",
              "      <td>/reviews/albums/king-gizzard-and-the-lizard-wi...</td>\n",
              "      <td>2021</td>\n",
              "      <td>King Gizzard &amp; The Lizard Wizard</td>\n",
              "      <td>K.G.</td>\n",
              "      <td>8.0</td>\n",
              "      <td>/reviews/albums/king-gizzard-and-the-lizard-wi...</td>\n",
              "      <td>2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>22311</td>\n",
              "      <td>66</td>\n",
              "      <td>75.447026</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>73</td>\n",
              "      <td>93.678466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.129972</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>1.64</td>\n",
              "      <td>24.1</td>\n",
              "      <td>63.6</td>\n",
              "      <td>59.100000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>10.10</td>\n",
              "      <td>29.299943</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.79</td>\n",
              "      <td>41.004551</td>\n",
              "      <td>60.0</td>\n",
              "      <td>7.97</td>\n",
              "      <td>96.076926</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>47.00</td>\n",
              "      <td>58.7</td>\n",
              "      <td>56.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>6.44</td>\n",
              "      <td>34.015550</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.76</td>\n",
              "      <td>30.812300</td>\n",
              "      <td>80.0</td>\n",
              "      <td>52.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Blur</td>\n",
              "      <td>13</td>\n",
              "      <td>9.1</td>\n",
              "      <td>/reviews/albums/831-13/</td>\n",
              "      <td>1999</td>\n",
              "      <td>Blur</td>\n",
              "      <td>13</td>\n",
              "      <td>9.1</td>\n",
              "      <td>/reviews/albums/831-13/</td>\n",
              "      <td>1999</td>\n",
              "      <td>Blur</td>\n",
              "      <td>13</td>\n",
              "      <td>9.1</td>\n",
              "      <td>/reviews/albums/831-13/</td>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>22314</td>\n",
              "      <td>37</td>\n",
              "      <td>22.552001</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>50</td>\n",
              "      <td>66.253687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.036547</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>58.50</td>\n",
              "      <td>67.3</td>\n",
              "      <td>38.1</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>72.727273</td>\n",
              "      <td>8.18</td>\n",
              "      <td>37.243740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.10</td>\n",
              "      <td>52.891234</td>\n",
              "      <td>80.0</td>\n",
              "      <td>63.40</td>\n",
              "      <td>94.465206</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>93.30</td>\n",
              "      <td>35.9</td>\n",
              "      <td>13.3</td>\n",
              "      <td>3.810000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>11.30</td>\n",
              "      <td>21.650937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.53</td>\n",
              "      <td>27.781874</td>\n",
              "      <td>60.0</td>\n",
              "      <td>12.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Songs: Ohia</td>\n",
              "      <td>Axxess and Ace</td>\n",
              "      <td>8.0</td>\n",
              "      <td>/reviews/albums/7339-axxess-and-ace/</td>\n",
              "      <td>1999</td>\n",
              "      <td>Songs: Ohia</td>\n",
              "      <td>Axxess and Ace</td>\n",
              "      <td>8.0</td>\n",
              "      <td>/reviews/albums/7339-axxess-and-ace/</td>\n",
              "      <td>1999</td>\n",
              "      <td>Songs: Ohia</td>\n",
              "      <td>Axxess and Ace</td>\n",
              "      <td>8.0</td>\n",
              "      <td>/reviews/albums/7339-axxess-and-ace/</td>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>22318</td>\n",
              "      <td>12</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>29</td>\n",
              "      <td>25.174041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.597975</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>12.30</td>\n",
              "      <td>59.2</td>\n",
              "      <td>43.1</td>\n",
              "      <td>0.286000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>38.70</td>\n",
              "      <td>29.595262</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.10</td>\n",
              "      <td>45.191104</td>\n",
              "      <td>80.0</td>\n",
              "      <td>62.60</td>\n",
              "      <td>83.695423</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>73.5</td>\n",
              "      <td>63.2</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.80</td>\n",
              "      <td>32.301168</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.68</td>\n",
              "      <td>52.668638</td>\n",
              "      <td>80.0</td>\n",
              "      <td>23.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Looper</td>\n",
              "      <td>Up a Tree</td>\n",
              "      <td>8.1</td>\n",
              "      <td>/reviews/albums/4850-up-a-tree/</td>\n",
              "      <td>1999</td>\n",
              "      <td>Looper</td>\n",
              "      <td>Up a Tree</td>\n",
              "      <td>8.1</td>\n",
              "      <td>/reviews/albums/4850-up-a-tree/</td>\n",
              "      <td>1999</td>\n",
              "      <td>Looper</td>\n",
              "      <td>Up a Tree</td>\n",
              "      <td>8.1</td>\n",
              "      <td>/reviews/albums/4850-up-a-tree/</td>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>22321</td>\n",
              "      <td>56</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>67</td>\n",
              "      <td>86.023599</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.260367</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>9.33</td>\n",
              "      <td>49.746379</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>40.016664</td>\n",
              "      <td>80.0</td>\n",
              "      <td>49.40</td>\n",
              "      <td>76.848450</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>10.70</td>\n",
              "      <td>72.104077</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>29.819714</td>\n",
              "      <td>80.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Wilco</td>\n",
              "      <td>Summerteeth</td>\n",
              "      <td>9.4</td>\n",
              "      <td>/reviews/albums/8677-summer-teeth/</td>\n",
              "      <td>1999</td>\n",
              "      <td>Wilco</td>\n",
              "      <td>Summerteeth</td>\n",
              "      <td>9.4</td>\n",
              "      <td>/reviews/albums/8677-summer-teeth/</td>\n",
              "      <td>1999</td>\n",
              "      <td>Wilco</td>\n",
              "      <td>Summerteeth</td>\n",
              "      <td>9.4</td>\n",
              "      <td>/reviews/albums/8677-summer-teeth/</td>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>22324</td>\n",
              "      <td>38</td>\n",
              "      <td>86.902445</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>44</td>\n",
              "      <td>64.873156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.767862</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>17.80</td>\n",
              "      <td>65.756693</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>55.692952</td>\n",
              "      <td>80.0</td>\n",
              "      <td>48.60</td>\n",
              "      <td>77.469703</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>13.60</td>\n",
              "      <td>24.095041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>44.692703</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Sebadoh</td>\n",
              "      <td>The Sebadoh</td>\n",
              "      <td>7.4</td>\n",
              "      <td>/reviews/albums/7051-the-sebadoh/</td>\n",
              "      <td>1999</td>\n",
              "      <td>Sebadoh</td>\n",
              "      <td>The Sebadoh</td>\n",
              "      <td>7.4</td>\n",
              "      <td>/reviews/albums/7051-the-sebadoh/</td>\n",
              "      <td>1999</td>\n",
              "      <td>Sebadoh</td>\n",
              "      <td>The Sebadoh</td>\n",
              "      <td>7.4</td>\n",
              "      <td>/reviews/albums/7051-the-sebadoh/</td>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9996 rows × 877 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      pitchfork_id  ...  release_year_y\n",
              "0                2  ...            2021\n",
              "1                3  ...            2021\n",
              "2                5  ...            2021\n",
              "3                6  ...            2021\n",
              "4                7  ...            2021\n",
              "...            ...  ...             ...\n",
              "9991         22311  ...            1999\n",
              "9992         22314  ...            1999\n",
              "9993         22318  ...            1999\n",
              "9994         22321  ...            1999\n",
              "9995         22324  ...            1999\n",
              "\n",
              "[9996 rows x 877 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "F1osGv26S7S1",
        "outputId": "2ae50de3-774d-4209-9a0f-7cf5396637cf"
      },
      "source": [
        "scores = pd.read_csv('final_pitchfork_scrape.csv')\n",
        "scores = scores[['pitchfork_id', 'score']]\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a78cc5082a40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_pitchfork_scrape.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pitchfork_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'final_pitchfork_scrape.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "pe5vcym5TOIh",
        "outputId": "344b9da5-8a38-4503-cd50-8474610f0804"
      },
      "source": [
        "genius_scores = pd.merge(genius, scores, on='pitchfork_id', how='left')\n",
        "genius_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pitchfork_id</th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_pct_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_pct_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_pct_followers</th>\n",
              "      <th>track0_dur_pct</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness_pct</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_pct</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness_pct</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>...</th>\n",
              "      <th>track17_lyric_happy_score</th>\n",
              "      <th>track17_lyric_surprise_score</th>\n",
              "      <th>track17_lyric_sad_score</th>\n",
              "      <th>track17_lyric_angry_score</th>\n",
              "      <th>track17_lyric_fear_score</th>\n",
              "      <th>track18_genius_pageviews</th>\n",
              "      <th>track18_is_eng</th>\n",
              "      <th>track18_ttr_lexical_richness</th>\n",
              "      <th>track18_nltk_neg</th>\n",
              "      <th>track18_nltk_neu</th>\n",
              "      <th>track18_nltk_pos</th>\n",
              "      <th>track18_nltk_compound</th>\n",
              "      <th>track18_textblob_polarity</th>\n",
              "      <th>track18_textblob_subjectivity</th>\n",
              "      <th>track18_percent_unique_words</th>\n",
              "      <th>track18_percent_expletive_words</th>\n",
              "      <th>track18_percentile_total_words</th>\n",
              "      <th>track18_lyric_happy_score</th>\n",
              "      <th>track18_lyric_surprise_score</th>\n",
              "      <th>track18_lyric_sad_score</th>\n",
              "      <th>track18_lyric_angry_score</th>\n",
              "      <th>track18_lyric_fear_score</th>\n",
              "      <th>track19_genius_pageviews</th>\n",
              "      <th>track19_is_eng</th>\n",
              "      <th>track19_ttr_lexical_richness</th>\n",
              "      <th>track19_nltk_neg</th>\n",
              "      <th>track19_nltk_neu</th>\n",
              "      <th>track19_nltk_pos</th>\n",
              "      <th>track19_nltk_compound</th>\n",
              "      <th>track19_textblob_polarity</th>\n",
              "      <th>track19_textblob_subjectivity</th>\n",
              "      <th>track19_percent_unique_words</th>\n",
              "      <th>track19_percent_expletive_words</th>\n",
              "      <th>track19_percentile_total_words</th>\n",
              "      <th>track19_lyric_happy_score</th>\n",
              "      <th>track19_lyric_surprise_score</th>\n",
              "      <th>track19_lyric_sad_score</th>\n",
              "      <th>track19_lyric_angry_score</th>\n",
              "      <th>track19_lyric_fear_score</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>18</td>\n",
              "      <td>8.156342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.780297</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>11.10</td>\n",
              "      <td>19.191527</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>51.020574</td>\n",
              "      <td>60.0</td>\n",
              "      <td>14.90</td>\n",
              "      <td>78.776339</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>6.37</td>\n",
              "      <td>14.233384</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>57.351213</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>69</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>73.725664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.840512</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.54</td>\n",
              "      <td>55.104087</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>41.435255</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.80</td>\n",
              "      <td>83.937167</td>\n",
              "      <td>100</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>8.82</td>\n",
              "      <td>37.670224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>28.077624</td>\n",
              "      <td>60.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>99.677655</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>50</td>\n",
              "      <td>42.112094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.335592</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>66.70</td>\n",
              "      <td>9.573199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>51.196189</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.10</td>\n",
              "      <td>94.482624</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>45.454545</td>\n",
              "      <td>11.10</td>\n",
              "      <td>36.129761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>72.899161</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>43</td>\n",
              "      <td>64.511617</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>57</td>\n",
              "      <td>71.675516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.399671</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>5.37</td>\n",
              "      <td>31.657482</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>46.134125</td>\n",
              "      <td>80.0</td>\n",
              "      <td>44.30</td>\n",
              "      <td>74.196647</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>9.89</td>\n",
              "      <td>38.026507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>64.828019</td>\n",
              "      <td>80.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>60</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>98.461538</td>\n",
              "      <td>68</td>\n",
              "      <td>87.244838</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.345579</td>\n",
              "      <td>100</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.70</td>\n",
              "      <td>50.087619</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>70.518085</td>\n",
              "      <td>60.0</td>\n",
              "      <td>90.50</td>\n",
              "      <td>82.834537</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>34.30</td>\n",
              "      <td>36.432998</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>55.915407</td>\n",
              "      <td>80.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>22311</td>\n",
              "      <td>66</td>\n",
              "      <td>75.447026</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>73</td>\n",
              "      <td>93.678466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.129972</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>1.64</td>\n",
              "      <td>24.1</td>\n",
              "      <td>63.6</td>\n",
              "      <td>59.100000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>10.10</td>\n",
              "      <td>29.299943</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.79</td>\n",
              "      <td>41.004551</td>\n",
              "      <td>60.0</td>\n",
              "      <td>7.97</td>\n",
              "      <td>96.076926</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>47.00</td>\n",
              "      <td>58.7</td>\n",
              "      <td>56.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>6.44</td>\n",
              "      <td>34.015550</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.76</td>\n",
              "      <td>30.812300</td>\n",
              "      <td>80.0</td>\n",
              "      <td>52.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>22314</td>\n",
              "      <td>37</td>\n",
              "      <td>22.552001</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>50</td>\n",
              "      <td>66.253687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.036547</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>58.50</td>\n",
              "      <td>67.3</td>\n",
              "      <td>38.1</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>72.727273</td>\n",
              "      <td>8.18</td>\n",
              "      <td>37.243740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.10</td>\n",
              "      <td>52.891234</td>\n",
              "      <td>80.0</td>\n",
              "      <td>63.40</td>\n",
              "      <td>94.465206</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>93.30</td>\n",
              "      <td>35.9</td>\n",
              "      <td>13.3</td>\n",
              "      <td>3.810000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>11.30</td>\n",
              "      <td>21.650937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.53</td>\n",
              "      <td>27.781874</td>\n",
              "      <td>60.0</td>\n",
              "      <td>12.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>22318</td>\n",
              "      <td>12</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>29</td>\n",
              "      <td>25.174041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.597975</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>12.30</td>\n",
              "      <td>59.2</td>\n",
              "      <td>43.1</td>\n",
              "      <td>0.286000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>38.70</td>\n",
              "      <td>29.595262</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.10</td>\n",
              "      <td>45.191104</td>\n",
              "      <td>80.0</td>\n",
              "      <td>62.60</td>\n",
              "      <td>83.695423</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>73.5</td>\n",
              "      <td>63.2</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.80</td>\n",
              "      <td>32.301168</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.68</td>\n",
              "      <td>52.668638</td>\n",
              "      <td>80.0</td>\n",
              "      <td>23.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>22321</td>\n",
              "      <td>56</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>67</td>\n",
              "      <td>86.023599</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.260367</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>9.33</td>\n",
              "      <td>49.746379</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>40.016664</td>\n",
              "      <td>80.0</td>\n",
              "      <td>49.40</td>\n",
              "      <td>76.848450</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>10.70</td>\n",
              "      <td>72.104077</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>29.819714</td>\n",
              "      <td>80.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>22324</td>\n",
              "      <td>38</td>\n",
              "      <td>86.902445</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>44</td>\n",
              "      <td>64.873156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.767862</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>17.80</td>\n",
              "      <td>65.756693</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>55.692952</td>\n",
              "      <td>80.0</td>\n",
              "      <td>48.60</td>\n",
              "      <td>77.469703</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>13.60</td>\n",
              "      <td>24.095041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>44.692703</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9996 rows × 863 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      pitchfork_id  popularity  ...  track19_lyric_fear_score  score\n",
              "0                2          25  ...                       0.0    7.5\n",
              "1                3          69  ...                       0.0    7.7\n",
              "2                5          44  ...                       0.0    6.5\n",
              "3                6          43  ...                       0.0    7.6\n",
              "4                7          60  ...                       0.0    8.0\n",
              "...            ...         ...  ...                       ...    ...\n",
              "9991         22311          66  ...                       0.0    9.1\n",
              "9992         22314          37  ...                       0.0    8.0\n",
              "9993         22318          12  ...                       0.0    8.1\n",
              "9994         22321          56  ...                       0.0    9.4\n",
              "9995         22324          38  ...                       0.0    7.4\n",
              "\n",
              "[9996 rows x 863 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2ZKQHUl6uKE"
      },
      "source": [
        "the_real_one = scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc6bxnPvllsD"
      },
      "source": [
        "the_real_one['sextile_score'] = pd.cut(the_real_one['score'], bins=[-1, 6.1, 6.8, 7.3, 7.6, 8.0, 10.0])\n",
        "the_real_one['sextile_score'] = the_real_one['sextile_score'].astype(str)\n",
        "the_real_one = the_real_one.replace({'(-1.0, 6.1]': 0, '(6.1, 6.8]': 1, '(6.8, 7.3]': 2, '(7.3, 7.6]': 3, '(7.6, 8.0]': 4, '(8.0, 10.0]': 5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "Ta5BBJF3lTo-",
        "outputId": "c58caa0e-24dd-4ad3-85c2-0e34435bbc0e"
      },
      "source": [
        "genius_scores['sextile_score'] = pd.cut(genius_scores['score'], bins=[-1, 6.1, 6.8, 7.3, 7.6, 8.0, 10.0])\n",
        "genius_scores['sextile_score'] = genius_scores['sextile_score'].astype(str)\n",
        "genius_scores = genius_scores.replace({'(-1.0, 6.1]': 0, '(6.1, 6.8]': 1, '(6.8, 7.3]': 2, '(7.3, 7.6]': 3, '(7.6, 8.0]': 4, '(8.0, 10.0]': 5})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'score'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-200d8ca54666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenius_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sextile_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenius_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgenius_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sextile_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenius_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sextile_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgenius_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenius_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'(-1.0, 6.1]'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(6.1, 6.8]'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(6.8, 7.3]'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(7.3, 7.6]'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(7.6, 8.0]'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(8.0, 10.0]'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'score'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD_KjLpomenY"
      },
      "source": [
        "genius_scores['tripartite_score'] = pd.cut(genius_scores['score'], bins=[-1, 6.8, 7.6, 10.0])\n",
        "genius_scores['tripartite_score'] = genius_scores['tripartite_score'].astype(str)\n",
        "genius_scores = genius_scores.replace({'(-1.0, 6.8]': 0, '(6.8, 7.6]': 1, '(7.6, 10.0]': 2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvWTE2Meb6Wl"
      },
      "source": [
        "the_real_one['tripartite_score'] = pd.cut(the_real_one['score'], bins=[-1, 6.8, 7.6, 10.0])\n",
        "the_real_one['tripartite_score'] = the_real_one['tripartite_score'].astype(str)\n",
        "the_real_one = the_real_one.replace({'(-1.0, 6.8]': 0, '(6.8, 7.6]': 1, '(7.6, 10.0]': 2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "A0t4o76-tp_w",
        "outputId": "d3ffcfb1-558e-4621-e775-544237574b80"
      },
      "source": [
        "the_real_one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pitchfork_id</th>\n",
              "      <th>score</th>\n",
              "      <th>sextile_score</th>\n",
              "      <th>tripartite_score</th>\n",
              "      <th>rounded_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>7.7</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>6.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>7.6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>22319</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>22321</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>22322</td>\n",
              "      <td>9.3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>22323</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>22324</td>\n",
              "      <td>7.4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       pitchfork_id  score  sextile_score  tripartite_score  rounded_score\n",
              "0                 2    7.5              3                 1              7\n",
              "1                 3    7.7              4                 2              8\n",
              "2                 5    6.5              1                 0              6\n",
              "3                 6    7.6              3                 1              8\n",
              "4                 7    8.0              4                 2              8\n",
              "...             ...    ...            ...               ...            ...\n",
              "16437         22319    7.5              3                 1              7\n",
              "16438         22321    9.4              5                 2              9\n",
              "16439         22322    9.3              5                 2              9\n",
              "16440         22323    8.1              5                 2              8\n",
              "16441         22324    7.4              3                 1              7\n",
              "\n",
              "[16442 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMNs734-nSQh"
      },
      "source": [
        "the_real_one_y_classification_six = the_real_one['sextile_score']\n",
        "the_real_one_y_classification_six.to_csv('THE_REAL_ONE_Y_CLASSIFICATION_SIX.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tN75KqmeIgK"
      },
      "source": [
        "the_real_one_y_classification_tri = the_real_one['tripartite_score']\n",
        "the_real_one_y_classification_tri.to_csv('THE_REAL_ONE_Y_CLASSIFICATION_TRI.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG8nsneVc4oN"
      },
      "source": [
        "#the_real_one = the_real_one.replace({'nan': 0})\n",
        "#the_real_one = the_real_one.drop('Unnamed: 0', axis=1)\n",
        "the_real_one['rounded_score'] = pd.cut(the_real_one['score'], bins=[-1.0, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.0])\n",
        "#the_real_one = the_real_one.fillna(0)\n",
        "the_real_one['rounded_score'] = the_real_one['rounded_score'].astype(str)\n",
        "the_real_one = the_real_one.replace({'(-1.0, 0.5]': 0, '(0.5, 1.5]': 1, '(1.5, 2.5]': 2, '(2.5, 3.5]': 3, '(3.5, 4.5]': 4, '(4.5, 5.5]': 5, '(5.5, 6.5]': 6, '(6.5, 7.5]': 7, '(7.5, 8.5]': 8, '(8.5, 9.5]': 9, '(9.5, 10.0]': 10})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "qFcxS5gxm8op",
        "outputId": "b855124d-79da-40b4-b0e5-3c978b9e7993"
      },
      "source": [
        "genius_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pitchfork_id</th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_pct_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_pct_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_pct_followers</th>\n",
              "      <th>track0_dur_pct</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness_pct</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_pct</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness_pct</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>...</th>\n",
              "      <th>track17_lyric_angry_score</th>\n",
              "      <th>track17_lyric_fear_score</th>\n",
              "      <th>track18_genius_pageviews</th>\n",
              "      <th>track18_is_eng</th>\n",
              "      <th>track18_ttr_lexical_richness</th>\n",
              "      <th>track18_nltk_neg</th>\n",
              "      <th>track18_nltk_neu</th>\n",
              "      <th>track18_nltk_pos</th>\n",
              "      <th>track18_nltk_compound</th>\n",
              "      <th>track18_textblob_polarity</th>\n",
              "      <th>track18_textblob_subjectivity</th>\n",
              "      <th>track18_percent_unique_words</th>\n",
              "      <th>track18_percent_expletive_words</th>\n",
              "      <th>track18_percentile_total_words</th>\n",
              "      <th>track18_lyric_happy_score</th>\n",
              "      <th>track18_lyric_surprise_score</th>\n",
              "      <th>track18_lyric_sad_score</th>\n",
              "      <th>track18_lyric_angry_score</th>\n",
              "      <th>track18_lyric_fear_score</th>\n",
              "      <th>track19_genius_pageviews</th>\n",
              "      <th>track19_is_eng</th>\n",
              "      <th>track19_ttr_lexical_richness</th>\n",
              "      <th>track19_nltk_neg</th>\n",
              "      <th>track19_nltk_neu</th>\n",
              "      <th>track19_nltk_pos</th>\n",
              "      <th>track19_nltk_compound</th>\n",
              "      <th>track19_textblob_polarity</th>\n",
              "      <th>track19_textblob_subjectivity</th>\n",
              "      <th>track19_percent_unique_words</th>\n",
              "      <th>track19_percent_expletive_words</th>\n",
              "      <th>track19_percentile_total_words</th>\n",
              "      <th>track19_lyric_happy_score</th>\n",
              "      <th>track19_lyric_surprise_score</th>\n",
              "      <th>track19_lyric_sad_score</th>\n",
              "      <th>track19_lyric_angry_score</th>\n",
              "      <th>track19_lyric_fear_score</th>\n",
              "      <th>score</th>\n",
              "      <th>sextile_score</th>\n",
              "      <th>tripartite_score</th>\n",
              "      <th>rounded_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>18</td>\n",
              "      <td>8.156342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.780297</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>11.10</td>\n",
              "      <td>19.191527</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>51.020574</td>\n",
              "      <td>60.0</td>\n",
              "      <td>14.90</td>\n",
              "      <td>78.776339</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>6.37</td>\n",
              "      <td>14.233384</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>57.351213</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>69</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>73.725664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.840512</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.54</td>\n",
              "      <td>55.104087</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>41.435255</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.80</td>\n",
              "      <td>83.937167</td>\n",
              "      <td>100</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>8.82</td>\n",
              "      <td>37.670224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>28.077624</td>\n",
              "      <td>60.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>99.677655</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>50</td>\n",
              "      <td>42.112094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.335592</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>66.70</td>\n",
              "      <td>9.573199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>51.196189</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.10</td>\n",
              "      <td>94.482624</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>45.454545</td>\n",
              "      <td>11.10</td>\n",
              "      <td>36.129761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>72.899161</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>43</td>\n",
              "      <td>64.511617</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>57</td>\n",
              "      <td>71.675516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.399671</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>5.37</td>\n",
              "      <td>31.657482</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>46.134125</td>\n",
              "      <td>80.0</td>\n",
              "      <td>44.30</td>\n",
              "      <td>74.196647</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>9.89</td>\n",
              "      <td>38.026507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>64.828019</td>\n",
              "      <td>80.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>60</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>98.461538</td>\n",
              "      <td>68</td>\n",
              "      <td>87.244838</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.345579</td>\n",
              "      <td>100</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.70</td>\n",
              "      <td>50.087619</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>70.518085</td>\n",
              "      <td>60.0</td>\n",
              "      <td>90.50</td>\n",
              "      <td>82.834537</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>34.30</td>\n",
              "      <td>36.432998</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>55.915407</td>\n",
              "      <td>80.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>22311</td>\n",
              "      <td>66</td>\n",
              "      <td>75.447026</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>73</td>\n",
              "      <td>93.678466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.129972</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>1.64</td>\n",
              "      <td>24.1</td>\n",
              "      <td>63.6</td>\n",
              "      <td>59.100000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>10.10</td>\n",
              "      <td>29.299943</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.79</td>\n",
              "      <td>41.004551</td>\n",
              "      <td>60.0</td>\n",
              "      <td>7.97</td>\n",
              "      <td>96.076926</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>47.00</td>\n",
              "      <td>58.7</td>\n",
              "      <td>56.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>6.44</td>\n",
              "      <td>34.015550</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.76</td>\n",
              "      <td>30.812300</td>\n",
              "      <td>80.0</td>\n",
              "      <td>52.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>22314</td>\n",
              "      <td>37</td>\n",
              "      <td>22.552001</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>50</td>\n",
              "      <td>66.253687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.036547</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>58.50</td>\n",
              "      <td>67.3</td>\n",
              "      <td>38.1</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>72.727273</td>\n",
              "      <td>8.18</td>\n",
              "      <td>37.243740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.10</td>\n",
              "      <td>52.891234</td>\n",
              "      <td>80.0</td>\n",
              "      <td>63.40</td>\n",
              "      <td>94.465206</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>93.30</td>\n",
              "      <td>35.9</td>\n",
              "      <td>13.3</td>\n",
              "      <td>3.810000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>11.30</td>\n",
              "      <td>21.650937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.53</td>\n",
              "      <td>27.781874</td>\n",
              "      <td>60.0</td>\n",
              "      <td>12.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>22318</td>\n",
              "      <td>12</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>29</td>\n",
              "      <td>25.174041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.597975</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>12.30</td>\n",
              "      <td>59.2</td>\n",
              "      <td>43.1</td>\n",
              "      <td>0.286000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>38.70</td>\n",
              "      <td>29.595262</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.10</td>\n",
              "      <td>45.191104</td>\n",
              "      <td>80.0</td>\n",
              "      <td>62.60</td>\n",
              "      <td>83.695423</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>73.5</td>\n",
              "      <td>63.2</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.80</td>\n",
              "      <td>32.301168</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.68</td>\n",
              "      <td>52.668638</td>\n",
              "      <td>80.0</td>\n",
              "      <td>23.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>22321</td>\n",
              "      <td>56</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>67</td>\n",
              "      <td>86.023599</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.260367</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>9.33</td>\n",
              "      <td>49.746379</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>40.016664</td>\n",
              "      <td>80.0</td>\n",
              "      <td>49.40</td>\n",
              "      <td>76.848450</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>10.70</td>\n",
              "      <td>72.104077</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>29.819714</td>\n",
              "      <td>80.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>22324</td>\n",
              "      <td>38</td>\n",
              "      <td>86.902445</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>44</td>\n",
              "      <td>64.873156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.767862</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>17.80</td>\n",
              "      <td>65.756693</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>55.692952</td>\n",
              "      <td>80.0</td>\n",
              "      <td>48.60</td>\n",
              "      <td>77.469703</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>13.60</td>\n",
              "      <td>24.095041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>44.692703</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9996 rows × 866 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      pitchfork_id  popularity  ...  tripartite_score  rounded_score\n",
              "0                2          25  ...                 1              7\n",
              "1                3          69  ...                 2              8\n",
              "2                5          44  ...                 0              6\n",
              "3                6          43  ...                 1              8\n",
              "4                7          60  ...                 2              8\n",
              "...            ...         ...  ...               ...            ...\n",
              "9991         22311          66  ...                 2              9\n",
              "9992         22314          37  ...                 2              8\n",
              "9993         22318          12  ...                 2              8\n",
              "9994         22321          56  ...                 2              9\n",
              "9995         22324          38  ...                 1              7\n",
              "\n",
              "[9996 rows x 866 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX40OpRFmuCx"
      },
      "source": [
        "genius_scores['rounded_score'] = pd.cut(genius_scores['score'], bins=[-1, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.0])\n",
        "genius_scores['rounded_score'] = genius_scores['rounded_score'].astype(str)\n",
        "genius_scores = genius_scores.replace({'(-1.0, 0.5]': 0, '(0.5, 1.5]': 1, '(1.5, 2.5]': 2, '(2.5, 3.5]': 3, '(3.5, 4.5]': 4, '(4.5, 5.5]': 5, '(5.5, 6.5]': 6, '(6.5, 7.5]': 7, '(7.5, 8.5]': 8, '(8.5, 9.5]': 9, '(9.5, 10.0]': 10})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suBAZ46kc6Ne"
      },
      "source": [
        "the_real_one.to_csv('THE_REAL_ONE.csv', index=False)\n",
        "the_real_one['rounded_score'].to_csv('THE_REAL_ONE_Y_CLASSIFICATION.csv', index=False)\n",
        "the_real_one['score'].to_csv('THE_REAL_ONE_Y_REGRESSION.csv', index=False)\n",
        "the_real_one_x = the_real_one.drop(labels=['score', 'rounded_score'], axis=1)\n",
        "the_real_one_x.to_csv('THE_REAL_ONE_X.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlmF36PHmrdu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "21825b48-63cc-43b6-cdec-9204f1f7b574"
      },
      "source": [
        "the_real_one['rounded_score'].to_csv('FULL_ROUNDED_SCORE_Y.csv', index=False)\n",
        "the_real_one['sextile_score'].to_csv('FULL_SIX_SCORE_Y.csv', index=False)\n",
        "the_real_one['tripartite_score'].to_csv('FULL_TRI_SCORE_Y.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'rounded_score'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-673ffb97e776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mthe_real_one\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rounded_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FULL_ROUNDED_SCORE_Y.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mthe_real_one\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sextile_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FULL_SIX_SCORE_Y.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mthe_real_one\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tripartite_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FULL_TRI_SCORE_Y.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'rounded_score'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDZ-frxMFfWu"
      },
      "source": [
        "#the_real_one_y_regression = pd.read_csv('THE_REAL_ONE_Y_REGRESSION.csv')\n",
        "the_real_one_y_classification = pd.read_csv('THE_REAL_ONE_Y_CLASSIFICATION_TRI.csv')\n",
        "#the_real_one_x = pd.read_csv('THE_REAL_ONE_X.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nub41ndxFWlx"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(the_real_one_x, the_real_one_y_classification, test_size=0.25, random_state=22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oewAnWYfKOa6"
      },
      "source": [
        "X_train.to_csv('THE_REAL_ONE_SCALED_X_TRAIN.csv', index=False)\n",
        "X_test.to_csv('THE_REAL_ONE_SCALED_X_TEST.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICoLfB20J9aX"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one_y_classification, test_size=0.25, random_state=22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TtBBzued6Ya"
      },
      "source": [
        "X_train, X_test, y_train1, y_test1 = train_test_split(the_real_one_x, the_real_one_y_regression, test_size=0.25, random_state=22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-vHzTl-eYaQ"
      },
      "source": [
        "X_train, X_test, y_train2, y_test2 = train_test_split(the_real_one_x, the_real_one_y_classification_tri, test_size=0.25, random_state=22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80vuzf9aec9R"
      },
      "source": [
        "y_test2.to_csv('THE_REAL_ONE_Y_TEST_CLASSIFICATION_TRI.csv', index=False)\n",
        "y_train2.to_csv('THE_REAL_ONE_Y_TRAIN_CLASSIFICATION_TRI.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BshrOsDGM_e_"
      },
      "source": [
        "X_train.to_csv('THE_REAL_ONE_X_TRAIN.csv', index=False)\n",
        "X_test.to_csv('THE_REAL_ONE_X_TEST.csv', index=False)\n",
        "y_train1.to_csv('THE_REAL_ONE_Y_TRAIN_REGRESSION.csv', index=False)\n",
        "y_test1.to_csv('THE_REAL_ONE_Y_TEST_REGRESSION.csv', index=False)\n",
        "y_train.to_csv('THE_REAL_ONE_Y_TRAIN_CLASSIFICATION.csv', index=False)\n",
        "y_test.to_csv('THE_REAL_ONE_Y_TEST_CLASSIFICATION.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ7kGhVzneTl"
      },
      "source": [
        "X_train, X_test, y_train3, y_test3 = train_test_split(the_real_one_x, the_real_one_y_classification_six, test_size=0.25, random_state=22)\n",
        "y_train3.to_csv('THE_REAL_ONE_Y_TRAIN_CLASSIFICATION_SIX.csv', index=False)\n",
        "y_test3.to_csv('THE_REAL_ONE_Y_TEST_CLASSIFICATION_SIX.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh4xWjoxfpCO"
      },
      "source": [
        "da_big_man = pd.read_csv('DA_BIG_MAN.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nh7u_o3gWjJ"
      },
      "source": [
        "X_train_lol, X_test_lol, y_train2, y_test2 = train_test_split(da_big_man, the_real_one_y_classification_tri, test_size=0.25, random_state=22)\n",
        "X_train_lol.to_csv('DA_BIG_MAN_X_TRAIN.csv', index=False)\n",
        "X_test_lol.to_csv('DA_BIG_MAN_X_TEST.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxOmnm4_ah4l",
        "outputId": "bdea0c76-8491-4efa-a2e5-39d833a11fcb"
      },
      "source": [
        "the_real_one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>score</th>\n",
              "      <th>album_duration_minutes</th>\n",
              "      <th>year</th>\n",
              "      <th>min_loudness</th>\n",
              "      <th>max_loudness</th>\n",
              "      <th>mean_loudness</th>\n",
              "      <th>stddev_loudness</th>\n",
              "      <th>label_frequency</th>\n",
              "      <th>mean_duration</th>\n",
              "      <th>min_valence</th>\n",
              "      <th>max_valence</th>\n",
              "      <th>stddev_valence</th>\n",
              "      <th>mean_valence</th>\n",
              "      <th>weighted_avg_valence</th>\n",
              "      <th>weighted_avg_speechiness</th>\n",
              "      <th>med_liveness</th>\n",
              "      <th>stddev_liveness</th>\n",
              "      <th>stddev_instrumentalness</th>\n",
              "      <th>weighted_avg_instrumentalness</th>\n",
              "      <th>explicit</th>\n",
              "      <th>weighted_avg_energy</th>\n",
              "      <th>min_danceability</th>\n",
              "      <th>max_danceability</th>\n",
              "      <th>mean_danceability</th>\n",
              "      <th>stddev_danceability</th>\n",
              "      <th>mean_acousticness</th>\n",
              "      <th>stddev_acousticness</th>\n",
              "      <th>med_acousticness</th>\n",
              "      <th>min_popularity</th>\n",
              "      <th>max_popularity</th>\n",
              "      <th>mean_popularity</th>\n",
              "      <th>stddev_popularity</th>\n",
              "      <th>key_0_pct</th>\n",
              "      <th>key_1_pct</th>\n",
              "      <th>key_2_pct</th>\n",
              "      <th>key_3_pct</th>\n",
              "      <th>key_4_pct</th>\n",
              "      <th>key_5_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>artist_popularity_mean</th>\n",
              "      <th>artist_followers_mean</th>\n",
              "      <th>artist_popularity_min</th>\n",
              "      <th>artist_popularity_max</th>\n",
              "      <th>artist_followers_min</th>\n",
              "      <th>artist_followers_max</th>\n",
              "      <th>artist_popularity_stddev</th>\n",
              "      <th>artist_followers_stddev</th>\n",
              "      <th>mean_feat_artist_popularity</th>\n",
              "      <th>mean_feat_artist_followers</th>\n",
              "      <th>min_feat_artist_popularity</th>\n",
              "      <th>min_feat_artist_followers</th>\n",
              "      <th>max_feat_artist_popularity</th>\n",
              "      <th>max_feat_artist_followers</th>\n",
              "      <th>stddev_feat_artist_popularity</th>\n",
              "      <th>stddev_feat_artist_followers</th>\n",
              "      <th>genre_0_pct</th>\n",
              "      <th>genre_1_pct</th>\n",
              "      <th>genre_2_pct</th>\n",
              "      <th>genre_3_pct</th>\n",
              "      <th>genre_4_pct</th>\n",
              "      <th>genre_5_pct</th>\n",
              "      <th>genre_6_pct</th>\n",
              "      <th>genre_7_pct</th>\n",
              "      <th>genre_8_pct</th>\n",
              "      <th>genre_9_pct</th>\n",
              "      <th>genre_10_pct</th>\n",
              "      <th>genre_11_pct</th>\n",
              "      <th>genre_12_pct</th>\n",
              "      <th>genre_13_pct</th>\n",
              "      <th>genre_14_pct</th>\n",
              "      <th>genre_15_pct</th>\n",
              "      <th>genre_16_pct</th>\n",
              "      <th>genre_17_pct</th>\n",
              "      <th>genre_18_pct</th>\n",
              "      <th>genre_19_pct</th>\n",
              "      <th>genre_20_pct</th>\n",
              "      <th>rounded_score</th>\n",
              "      <th>sextile_score</th>\n",
              "      <th>tripartite_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "      <td>7.5</td>\n",
              "      <td>37.699950</td>\n",
              "      <td>2021</td>\n",
              "      <td>8.695784</td>\n",
              "      <td>77.746616</td>\n",
              "      <td>71.966860</td>\n",
              "      <td>2.468588</td>\n",
              "      <td>1</td>\n",
              "      <td>3.769995</td>\n",
              "      <td>52.09</td>\n",
              "      <td>55.6</td>\n",
              "      <td>15.025998</td>\n",
              "      <td>18.476000</td>\n",
              "      <td>16.069549</td>\n",
              "      <td>3.524631</td>\n",
              "      <td>9.575</td>\n",
              "      <td>5.812945</td>\n",
              "      <td>30.604008</td>\n",
              "      <td>22.075199</td>\n",
              "      <td>0</td>\n",
              "      <td>22.089854</td>\n",
              "      <td>39.40</td>\n",
              "      <td>63.3</td>\n",
              "      <td>45.330000</td>\n",
              "      <td>10.642582</td>\n",
              "      <td>76.730000</td>\n",
              "      <td>76.730000</td>\n",
              "      <td>81.6500</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>12.800000</td>\n",
              "      <td>2.699794</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>538.0</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>538</td>\n",
              "      <td>538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.776000e+03</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1776.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1776.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>17</td>\n",
              "      <td>7.7</td>\n",
              "      <td>53.442883</td>\n",
              "      <td>2021</td>\n",
              "      <td>5.087701</td>\n",
              "      <td>81.197035</td>\n",
              "      <td>78.453161</td>\n",
              "      <td>1.668215</td>\n",
              "      <td>2</td>\n",
              "      <td>3.143699</td>\n",
              "      <td>75.31</td>\n",
              "      <td>82.5</td>\n",
              "      <td>20.156995</td>\n",
              "      <td>43.517059</td>\n",
              "      <td>43.974797</td>\n",
              "      <td>26.145333</td>\n",
              "      <td>11.200</td>\n",
              "      <td>10.004012</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.000364</td>\n",
              "      <td>1</td>\n",
              "      <td>55.135105</td>\n",
              "      <td>45.40</td>\n",
              "      <td>87.3</td>\n",
              "      <td>75.317647</td>\n",
              "      <td>12.166976</td>\n",
              "      <td>12.456412</td>\n",
              "      <td>12.456412</td>\n",
              "      <td>6.9500</td>\n",
              "      <td>33</td>\n",
              "      <td>72</td>\n",
              "      <td>40.941176</td>\n",
              "      <td>8.989373</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>41.176471</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>69.0</td>\n",
              "      <td>161226.0</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>161226</td>\n",
              "      <td>161226</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.230769</td>\n",
              "      <td>4.329135e+06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>54616704.0</td>\n",
              "      <td>20.753128</td>\n",
              "      <td>1.511468e+07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.117647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>52</td>\n",
              "      <td>6.5</td>\n",
              "      <td>215.010783</td>\n",
              "      <td>2021</td>\n",
              "      <td>27.651865</td>\n",
              "      <td>77.851220</td>\n",
              "      <td>67.206191</td>\n",
              "      <td>7.829765</td>\n",
              "      <td>21</td>\n",
              "      <td>4.300216</td>\n",
              "      <td>83.92</td>\n",
              "      <td>87.1</td>\n",
              "      <td>21.225589</td>\n",
              "      <td>29.830000</td>\n",
              "      <td>28.973155</td>\n",
              "      <td>9.620623</td>\n",
              "      <td>11.250</td>\n",
              "      <td>13.873995</td>\n",
              "      <td>32.165156</td>\n",
              "      <td>68.565822</td>\n",
              "      <td>0</td>\n",
              "      <td>31.134999</td>\n",
              "      <td>72.37</td>\n",
              "      <td>81.6</td>\n",
              "      <td>44.774600</td>\n",
              "      <td>19.179167</td>\n",
              "      <td>84.409600</td>\n",
              "      <td>84.409600</td>\n",
              "      <td>93.0000</td>\n",
              "      <td>13</td>\n",
              "      <td>34</td>\n",
              "      <td>18.960000</td>\n",
              "      <td>4.936164</td>\n",
              "      <td>13.461538</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>...</td>\n",
              "      <td>50.0</td>\n",
              "      <td>16453.0</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>16453</td>\n",
              "      <td>16453</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>2.673500e+03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>849.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>4498.0</td>\n",
              "      <td>11.313708</td>\n",
              "      <td>2.580233e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>7.6</td>\n",
              "      <td>40.477500</td>\n",
              "      <td>2021</td>\n",
              "      <td>5.084669</td>\n",
              "      <td>79.579461</td>\n",
              "      <td>76.552764</td>\n",
              "      <td>1.577898</td>\n",
              "      <td>64</td>\n",
              "      <td>3.373125</td>\n",
              "      <td>73.80</td>\n",
              "      <td>96.7</td>\n",
              "      <td>23.668895</td>\n",
              "      <td>72.475000</td>\n",
              "      <td>74.175735</td>\n",
              "      <td>6.567317</td>\n",
              "      <td>9.125</td>\n",
              "      <td>13.549375</td>\n",
              "      <td>24.003436</td>\n",
              "      <td>18.619665</td>\n",
              "      <td>0</td>\n",
              "      <td>61.188227</td>\n",
              "      <td>51.50</td>\n",
              "      <td>87.9</td>\n",
              "      <td>69.800000</td>\n",
              "      <td>16.594961</td>\n",
              "      <td>28.157500</td>\n",
              "      <td>28.157500</td>\n",
              "      <td>16.4000</td>\n",
              "      <td>24</td>\n",
              "      <td>36</td>\n",
              "      <td>28.583333</td>\n",
              "      <td>3.824760</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>57.0</td>\n",
              "      <td>135966.0</td>\n",
              "      <td>57</td>\n",
              "      <td>57</td>\n",
              "      <td>135966</td>\n",
              "      <td>135966</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>8.0</td>\n",
              "      <td>41.823017</td>\n",
              "      <td>2020</td>\n",
              "      <td>16.084775</td>\n",
              "      <td>81.914103</td>\n",
              "      <td>78.010248</td>\n",
              "      <td>4.848596</td>\n",
              "      <td>1</td>\n",
              "      <td>4.182302</td>\n",
              "      <td>71.90</td>\n",
              "      <td>90.5</td>\n",
              "      <td>28.487900</td>\n",
              "      <td>58.760000</td>\n",
              "      <td>59.015377</td>\n",
              "      <td>6.562235</td>\n",
              "      <td>32.850</td>\n",
              "      <td>17.877847</td>\n",
              "      <td>33.922389</td>\n",
              "      <td>31.894178</td>\n",
              "      <td>1</td>\n",
              "      <td>74.673965</td>\n",
              "      <td>28.00</td>\n",
              "      <td>65.5</td>\n",
              "      <td>54.750000</td>\n",
              "      <td>9.336577</td>\n",
              "      <td>9.097215</td>\n",
              "      <td>9.097215</td>\n",
              "      <td>4.4200</td>\n",
              "      <td>41</td>\n",
              "      <td>53</td>\n",
              "      <td>46.500000</td>\n",
              "      <td>4.169999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>68.0</td>\n",
              "      <td>647390.0</td>\n",
              "      <td>68</td>\n",
              "      <td>68</td>\n",
              "      <td>647390</td>\n",
              "      <td>647390</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>7.5</td>\n",
              "      <td>30.473300</td>\n",
              "      <td>1999</td>\n",
              "      <td>7.487531</td>\n",
              "      <td>75.086033</td>\n",
              "      <td>71.995339</td>\n",
              "      <td>2.927091</td>\n",
              "      <td>204</td>\n",
              "      <td>4.353329</td>\n",
              "      <td>69.50</td>\n",
              "      <td>76.3</td>\n",
              "      <td>24.618199</td>\n",
              "      <td>41.728571</td>\n",
              "      <td>42.058227</td>\n",
              "      <td>6.142869</td>\n",
              "      <td>12.600</td>\n",
              "      <td>7.080754</td>\n",
              "      <td>30.172104</td>\n",
              "      <td>73.998741</td>\n",
              "      <td>0</td>\n",
              "      <td>70.294207</td>\n",
              "      <td>27.20</td>\n",
              "      <td>58.2</td>\n",
              "      <td>43.728571</td>\n",
              "      <td>9.774067</td>\n",
              "      <td>22.448286</td>\n",
              "      <td>22.448286</td>\n",
              "      <td>3.6000</td>\n",
              "      <td>8</td>\n",
              "      <td>35</td>\n",
              "      <td>12.571429</td>\n",
              "      <td>9.947481</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.857143</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>50.0</td>\n",
              "      <td>159367.0</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>159367</td>\n",
              "      <td>159367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>56</td>\n",
              "      <td>17</td>\n",
              "      <td>9.4</td>\n",
              "      <td>60.331483</td>\n",
              "      <td>1999</td>\n",
              "      <td>85.660143</td>\n",
              "      <td>85.660143</td>\n",
              "      <td>75.658814</td>\n",
              "      <td>19.957987</td>\n",
              "      <td>71</td>\n",
              "      <td>3.548911</td>\n",
              "      <td>83.90</td>\n",
              "      <td>83.9</td>\n",
              "      <td>24.398101</td>\n",
              "      <td>43.188235</td>\n",
              "      <td>46.731975</td>\n",
              "      <td>3.583291</td>\n",
              "      <td>10.700</td>\n",
              "      <td>11.592671</td>\n",
              "      <td>15.440686</td>\n",
              "      <td>6.035377</td>\n",
              "      <td>0</td>\n",
              "      <td>64.086232</td>\n",
              "      <td>69.20</td>\n",
              "      <td>69.2</td>\n",
              "      <td>47.223529</td>\n",
              "      <td>16.006777</td>\n",
              "      <td>23.552353</td>\n",
              "      <td>23.552353</td>\n",
              "      <td>7.0800</td>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>32.294118</td>\n",
              "      <td>10.941690</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>35.294118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>67.0</td>\n",
              "      <td>587819.0</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>587819</td>\n",
              "      <td>587819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>17.647059</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.411765</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>9.3</td>\n",
              "      <td>46.941517</td>\n",
              "      <td>1999</td>\n",
              "      <td>2.516562</td>\n",
              "      <td>82.393160</td>\n",
              "      <td>81.402908</td>\n",
              "      <td>0.907825</td>\n",
              "      <td>103</td>\n",
              "      <td>4.694152</td>\n",
              "      <td>72.40</td>\n",
              "      <td>93.3</td>\n",
              "      <td>20.468502</td>\n",
              "      <td>52.920000</td>\n",
              "      <td>50.707482</td>\n",
              "      <td>3.270570</td>\n",
              "      <td>18.100</td>\n",
              "      <td>8.463656</td>\n",
              "      <td>29.561014</td>\n",
              "      <td>40.199373</td>\n",
              "      <td>0</td>\n",
              "      <td>76.314037</td>\n",
              "      <td>32.60</td>\n",
              "      <td>50.6</td>\n",
              "      <td>32.270000</td>\n",
              "      <td>10.564095</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.0163</td>\n",
              "      <td>34</td>\n",
              "      <td>57</td>\n",
              "      <td>40.600000</td>\n",
              "      <td>6.736303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>56.0</td>\n",
              "      <td>215321.0</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>215321</td>\n",
              "      <td>215321</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>8.1</td>\n",
              "      <td>44.758833</td>\n",
              "      <td>1999</td>\n",
              "      <td>5.199885</td>\n",
              "      <td>79.112533</td>\n",
              "      <td>76.730010</td>\n",
              "      <td>1.729905</td>\n",
              "      <td>4</td>\n",
              "      <td>3.729903</td>\n",
              "      <td>67.50</td>\n",
              "      <td>97.2</td>\n",
              "      <td>24.716151</td>\n",
              "      <td>57.091667</td>\n",
              "      <td>55.815206</td>\n",
              "      <td>5.762615</td>\n",
              "      <td>20.800</td>\n",
              "      <td>14.893113</td>\n",
              "      <td>36.689485</td>\n",
              "      <td>28.698280</td>\n",
              "      <td>0</td>\n",
              "      <td>73.804939</td>\n",
              "      <td>43.10</td>\n",
              "      <td>60.4</td>\n",
              "      <td>44.516667</td>\n",
              "      <td>12.546411</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.0525</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.984732</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2489.0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>2489</td>\n",
              "      <td>2489</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>38</td>\n",
              "      <td>15</td>\n",
              "      <td>7.4</td>\n",
              "      <td>48.525733</td>\n",
              "      <td>1999</td>\n",
              "      <td>7.299547</td>\n",
              "      <td>80.878674</td>\n",
              "      <td>78.544538</td>\n",
              "      <td>1.980301</td>\n",
              "      <td>275</td>\n",
              "      <td>3.235049</td>\n",
              "      <td>78.16</td>\n",
              "      <td>85.7</td>\n",
              "      <td>20.413301</td>\n",
              "      <td>40.322667</td>\n",
              "      <td>39.695422</td>\n",
              "      <td>4.885491</td>\n",
              "      <td>10.800</td>\n",
              "      <td>4.095428</td>\n",
              "      <td>24.524718</td>\n",
              "      <td>8.230068</td>\n",
              "      <td>0</td>\n",
              "      <td>75.332988</td>\n",
              "      <td>32.70</td>\n",
              "      <td>56.2</td>\n",
              "      <td>39.920000</td>\n",
              "      <td>7.972381</td>\n",
              "      <td>3.075563</td>\n",
              "      <td>3.075563</td>\n",
              "      <td>0.1380</td>\n",
              "      <td>10</td>\n",
              "      <td>41</td>\n",
              "      <td>15.466667</td>\n",
              "      <td>7.670599</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>44.0</td>\n",
              "      <td>81574.0</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>81574</td>\n",
              "      <td>81574</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 94 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  total_tracks  ...  sextile_score  tripartite_score\n",
              "0              25            10  ...              3                 1\n",
              "1              69            17  ...              4                 2\n",
              "2              44            52  ...              1                 0\n",
              "3              43            12  ...              3                 1\n",
              "4              60            10  ...              4                 2\n",
              "...           ...           ...  ...            ...               ...\n",
              "16437          31             7  ...              3                 1\n",
              "16438          56            17  ...              5                 2\n",
              "16439          57            10  ...              5                 2\n",
              "16440           5            12  ...              5                 2\n",
              "16441          38            15  ...              3                 1\n",
              "\n",
              "[16442 rows x 94 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls8SHD7zhPN4"
      },
      "source": [
        "def graphMetrics(Y_test, Y_pred, X_test):\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.scatter(Y_pred, Y_test, edgecolors=(0, 0, 1))\n",
        "  Y_test = np.array(Y_test)\n",
        "  ax.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--', lw=3)\n",
        "  ax.set_xlabel('Predicted')\n",
        "  ax.set_ylabel('Actual')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOmnOoG7rgTa"
      },
      "source": [
        "def confusion_matrix_metric(y_true, y_pred, targetnames, plot = False) :\n",
        "  matrix = confusion_matrix(y_true, y_pred)\n",
        "  print(matrix)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=targetnames)\n",
        "  disp.plot() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FJgyfEQuJPl"
      },
      "source": [
        "def classification_scores(y_preds, y_true, target_names, plot = False) :\n",
        "  class_rep = classification_report(y_true, y_preds, target_names=target_names)\n",
        "  print(class_rep)    \n",
        "  return class_rep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHh0qboyuvyC"
      },
      "source": [
        "\n",
        "def multiclassROC(Y_test, Y_score, n_classes, plot = False) :\n",
        "  precision = dict()\n",
        "  recall = dict()\n",
        "  average_precision = dict()\n",
        "  for i in range(n_classes):\n",
        "    precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
        "                                                        y_score[:, i])\n",
        "    average_precision[i] = average_precision_score(Y_test[:, i], y_score[:, i])\n",
        "\n",
        "  # A \"micro-average\": quantifying score on all classes jointly\n",
        "  precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(Y_test.ravel(),\n",
        "      y_score.ravel())\n",
        "  average_precision[\"micro\"] = average_precision_score(Y_test, y_score,\n",
        "                                                     average=\"micro\")\n",
        "  print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
        "        .format(average_precision[\"micro\"]))\n",
        "  \n",
        "  if plot :\n",
        "      \n",
        "    colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal'])\n",
        "\n",
        "    plt.figure(figsize=(7, 8))\n",
        "    f_scores = np.linspace(0.2, 0.8, num=4)\n",
        "    lines = []\n",
        "    labels = []\n",
        "    for f_score in f_scores:\n",
        "      x = np.linspace(0.01, 1)\n",
        "      y = f_score * x / (2 * x - f_score)\n",
        "      l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
        "      plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n",
        "\n",
        "    lines.append(l)\n",
        "    labels.append('iso-f1 curves')\n",
        "    l, = plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2)\n",
        "    lines.append(l)\n",
        "    labels.append('micro-average Precision-recall (area = {0:0.2f})'\n",
        "              ''.format(average_precision[\"micro\"]))\n",
        "\n",
        "    for i, color in zip(range(n_classes), colors):\n",
        "      l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n",
        "      lines.append(l)\n",
        "      labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n",
        "                  ''.format(i, average_precision[i]))\n",
        "\n",
        "    fig = plt.gcf()\n",
        "    fig.subplots_adjust(bottom=0.25)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Extension of Precision-Recall curve to multi-class')\n",
        "    plt.legend(lines, labels, loc=(0, -.38), prop=dict(size=14))\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(2)\n",
        "    plt.step(recall['micro'], precision['micro'], where='post')\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.title(\n",
        "        'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
        "        .format(average_precision[\"micro\"]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0P8yvnXuwXp"
      },
      "source": [
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Add noisy features\n",
        "random_state = np.random.RandomState(0)\n",
        "n_samples, n_features = X.shape\n",
        "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
        "\n",
        "# Limit to the two first classes, and split into training and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X[y < 2], y[y < 2],\n",
        "                                                    test_size=.5,\n",
        "                                                    random_state=random_state)\n",
        "#print(Y_test)\n",
        "# Create a simple classifier\n",
        "classifier = svm.LinearSVC(random_state=random_state)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_score = classifier.decision_function(X_test)\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Use label_binarize to be multi-label like settings\n",
        "Y = label_binarize(y, classes=[0, 1, 2])\n",
        "n_classes = Y.shape[1]\n",
        "\n",
        "# Split into training and test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.5,\n",
        "                                                    random_state=random_state)\n",
        "\n",
        "# We use OneVsRestClassifier for multi-label prediction\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# Run classifier\n",
        "classifier = OneVsRestClassifier(svm.LinearSVC(random_state=random_state))\n",
        "classifier.fit(X_train, Y_train)\n",
        "y_score = classifier.decision_function(X_test)\n",
        "#print(Y_test)\n",
        "multiclassROC(Y_test, y_score, n_classes, plot = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGqbqQ9E3HqD"
      },
      "source": [
        "classification_dict = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bL_2c33m3v_"
      },
      "source": [
        "# GRAPHICS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIiFB6x0S42S"
      },
      "source": [
        "labels = [0, 1, 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "8f1eeee7b5e540bfbdf734c16043e07d",
            "d1dbd8d39a0b42b5833fb58ce596563d",
            "19128b56008748fca2b61805755b7ad4",
            "48129374b85d439fb540c236a7855b12",
            "e86c42d813e14029888f565201f982da",
            "2d94c123e3b04d7bb7a3d0630f00b38e",
            "df86252c504745d89a1e393a5ac41ee3",
            "2adbe73dc9f44f7887194cfd66e4ec7b"
          ]
        },
        "id": "hoaiU_pIw3_D",
        "outputId": "9ab4a774-5451-4829-ca6e-4113e41049d1"
      },
      "source": [
        "wandb.init(project=\"sklearn\")\n",
        "wandb.sklearn.plot_confusion_matrix(y_test84ka, predictions84ka, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:3uxf7kwo) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 3074<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f1eeee7b5e540bfbdf734c16043e07d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210603_003953-3uxf7kwo/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210603_003953-3uxf7kwo/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>2</td></tr><tr><td>_timestamp</td><td>1622680799</td></tr><tr><td>_step</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">copper-star-17</strong>: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/3uxf7kwo\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/3uxf7kwo</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:3uxf7kwo). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">valiant-fog-18</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/5gmtkgi5\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/5gmtkgi5</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210603_025049-5gmtkgi5</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "3a6b659a22914b82960c19ac5cd6a1a8",
            "9e4c7182df454c84887a08b1c35539f2",
            "5036e38dafdd4918b778510544022393",
            "f546fce7e8fd4f93b6954e7d00b62b19",
            "52a48de567444c5fbdc174c4dbc234c4",
            "2a6f654f092a458e81a63ea48ba94d75",
            "63948d0e8d24447d88c1d5def15b3569",
            "5f2c0c5f832f4d23af5a73546d84455b"
          ]
        },
        "id": "LQEpF2cdSHRR",
        "outputId": "dad2f242-7e8e-4ae4-c42e-bf742d3d3b07"
      },
      "source": [
        "\n",
        "wandb.sklearn.plot_precision_recall(Y_tests, sgbclf.predict_proba(X_tests), labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:bbyv1geu) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2788<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a6b659a22914b82960c19ac5cd6a1a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.19MB of 0.19MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210603_002710-bbyv1geu/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210603_002710-bbyv1geu/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>3</td></tr><tr><td>_timestamp</td><td>1622680037</td></tr><tr><td>_step</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">laced-bird-11</strong>: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/bbyv1geu\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/bbyv1geu</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:bbyv1geu). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">pleasant-hill-12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/2tq8sii0\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/2tq8sii0</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210603_003518-2tq8sii0</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "c599a644682b4a9cbf492168d3d17a25",
            "6ceb37a48d7940e9a4c7d3ada286a633",
            "06505e507b014867bb6fed4668f30b9d",
            "c60bb9e03eb746cf8cfaa355a5ac0ffc",
            "9b8a2eb1d4c14c09a9714e6339176afa",
            "0ffea6b840414361a6d59adceac8a4de",
            "96444408c1ee4d20857dadf06d11d993",
            "ceb77a8fb5cb4239a8b99fa81471b285"
          ]
        },
        "id": "NBQYLM9rTKT3",
        "outputId": "98797266-0e7c-44c2-d868-5be270df6908"
      },
      "source": [
        "wandb.init(project=\"sklearn\")\n",
        "wandb.sklearn.plot_precision_recall(Y_testg, ggbclf.predict_proba(X_testg), labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2tq8sii0) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2857<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c599a644682b4a9cbf492168d3d17a25",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210603_003518-2tq8sii0/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210603_003518-2tq8sii0/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>2</td></tr><tr><td>_timestamp</td><td>1622680523</td></tr><tr><td>_step</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">pleasant-hill-12</strong>: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/2tq8sii0\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/2tq8sii0</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:2tq8sii0). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">frosty-salad-13</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/2gz29z7v\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/2gz29z7v</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210603_003637-2gz29z7v</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuGfFcz7Q7uZ"
      },
      "source": [
        "wandb.init(project=\"sklearn\")\n",
        "wandb.sklearn.plot_roc(Y_testg, ggbclf.predict_proba(X_testg), [0, 1, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "beba87e9c07c47ee948ee657e66148c7",
            "31bbcfec2f59470ea10b85e42ad7ef71",
            "e6eb7c6cba58437aac5d0d18d0dd472a",
            "b85ef77bcdbc44a2a8b333a165b11c66",
            "07356664ee0f418c9108b69e4e98750a",
            "f6d9866ae62b4161925afe4376e14851",
            "c4628bb8d2e249d2b2d6419b3fcb65be",
            "c49671e2d1b642f7995141a2182dbdad"
          ]
        },
        "id": "RaTQnAZHTT9V",
        "outputId": "e58b8399-c597-4243-8ea0-3239b3ced328"
      },
      "source": [
        "wandb.init(project=\"sklearn\")\n",
        "wandb.sklearn.plot_precision_recall(Y_testbp, bpadaclf.predict_proba(X_testbp), labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2gz29z7v) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2902<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "beba87e9c07c47ee948ee657e66148c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210603_003637-2gz29z7v/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210603_003637-2gz29z7v/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>2</td></tr><tr><td>_timestamp</td><td>1622680603</td></tr><tr><td>_step</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">frosty-salad-13</strong>: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/2gz29z7v\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/2gz29z7v</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:2gz29z7v). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">crisp-shadow-14</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/hckanzax\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/hckanzax</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210603_003715-hckanzax</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "5228558a715c4064826364e40d9b6e97",
            "d585c222da8d482bbf55a860eec69bbb",
            "e64c5791a0e14519a0df184ca837e584",
            "b4e81d47fbd24ed49b67db4291c992de",
            "61139f87c77b4b29a86f94db948ca8eb",
            "3264703b613b4aa285b065b67ba9c4a2",
            "07d439f61ae742cdb49b5c5ee5a0254d",
            "736ddf88c6f8456ca49f840bd0a22b37"
          ]
        },
        "id": "XwN_BcjTQsEv",
        "outputId": "0da48f32-c1f6-4e23-bbf8-4923964b58fc"
      },
      "source": [
        "wandb.init(project=\"sklearn\")\n",
        "wandb.sklearn.plot_roc(Y_testbp, bpadaclf.predict_proba(X_testbp), [0, 1, 2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2gawgpgw) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2745<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5228558a715c4064826364e40d9b6e97",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.11MB of 0.11MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210603_002559-2gawgpgw/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210603_002559-2gawgpgw/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>3</td></tr><tr><td>_timestamp</td><td>1622679966</td></tr><tr><td>_step</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">still-dream-10</strong>: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/2gawgpgw\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/2gawgpgw</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:2gawgpgw). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">laced-bird-11</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/bbyv1geu\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/bbyv1geu</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210603_002710-bbyv1geu</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "2abf28ee14124ea1b80bd0ffc4c23cd5",
            "972a73e679414706a689234d11995bd3",
            "03d5d7d97d8f41069834353e81325313",
            "89ee3c829ed84894848551c4d4094c72",
            "2b05cce10447431c9cbf2c49e9de01fd",
            "4cac470f17304860aca892ce95e25db7",
            "67423c3a07514619aca225a6f2acfbe6",
            "45414ac66e8a46c4acdadc456278dd5c"
          ]
        },
        "id": "3RgmoqjDTe6t",
        "outputId": "ec3fbec8-9347-4db0-be6a-41e1f1acd46b"
      },
      "source": [
        "wandb.init(project=\"sklearn\")\n",
        "wandb.sklearn.plot_confusion_matrix(Y_tests, sgbpredictions, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:hckanzax) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2944<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2abf28ee14124ea1b80bd0ffc4c23cd5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210603_003715-hckanzax/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210603_003715-hckanzax/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>3</td></tr><tr><td>_timestamp</td><td>1622680641</td></tr><tr><td>_step</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">crisp-shadow-14</strong>: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/hckanzax\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/hckanzax</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:hckanzax). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">trim-voice-15</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/sgrypcyn\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/sgrypcyn</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210603_003831-sgrypcyn</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_qR1glguYD0"
      },
      "source": [
        "wandb.init(project=\"sklearn\")\n",
        "wandb.sklearn.plot_confusion_matrix(Y_tests, sgbpredictions, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "6a79a6283d194f7f9067ea504f508687",
            "a19a7be3cd144ce5bbe8c3c3cb5e4b41",
            "80d5cd65eace459483ff43217695aefd",
            "88738f1758a443c389c0ce3a4969fc36",
            "43a28980aa6a4616b02199ca1cde9654",
            "1f545e1623704e4ca6a7b7a1329f355a",
            "abb74f89dc334aecae3547b3f753a2de",
            "8274783bf8c741feaa15c3001a912067"
          ]
        },
        "id": "ZW_3ERrSTzuY",
        "outputId": "d9749d5f-495d-465c-bea3-f9561e00e43c"
      },
      "source": [
        "wandb.init(project=\"sklearn\")\n",
        "wandb.sklearn.plot_confusion_matrix(Y_testg, ggbpredictions, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:sgrypcyn) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2993<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a79a6283d194f7f9067ea504f508687",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210603_003831-sgrypcyn/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210603_003831-sgrypcyn/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>2</td></tr><tr><td>_timestamp</td><td>1622680716</td></tr><tr><td>_step</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">trim-voice-15</strong>: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/sgrypcyn\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/sgrypcyn</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:sgrypcyn). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">silvery-galaxy-16</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/2sc82zbk\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/2sc82zbk</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210603_003919-2sc82zbk</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "d8c143ed8dc847c68faf2b1cd54f7953",
            "94a0771e4f364627a34ead8b5e590e8f",
            "f5ab5fad565740529824fcd482c98c85",
            "40f69fa409fd46f683b491c296fe72a4",
            "754a30f60c7a46f6856fb44151fc5a24",
            "37669e9124c844939ae617bc3ad6096a",
            "0d02067f93764de7ab9447f86e4e8b69",
            "d07264cf1c4144e094fcc1083fea0ade"
          ]
        },
        "id": "L74OOHA5NLG7",
        "outputId": "6362b7c3-1929-4c60-99b7-24331e80ec44"
      },
      "source": [
        "wandb.init(project=\"sklearn\")\n",
        "wandb.sklearn.plot_roc(Y_tests, sgbclf.predict_proba(X_tests), [0, 1, 2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:1t5vlp8x) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2658<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8c143ed8dc847c68faf2b1cd54f7953",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.19MB of 0.19MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210603_002209-1t5vlp8x/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210603_002209-1t5vlp8x/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>3</td></tr><tr><td>_timestamp</td><td>1622679735</td></tr><tr><td>_step</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">volcanic-resonance-8</strong>: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/1t5vlp8x\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/1t5vlp8x</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:1t5vlp8x). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">twilight-forest-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/144k2ju7\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/144k2ju7</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210603_002246-144k2ju7</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568,
          "referenced_widgets": [
            "808a21cd4e1f407fb29c95915698a448",
            "b295c88ea3f9419b920abbc36e7d4cd5",
            "ade0e8fb0c0f475f819886244468b30f",
            "fa9dac23c4c64db1987b9ea4baca9c95",
            "f213e31a9c7f497188bb7009f90a480f",
            "639ab088891d420e9e824c058eb99629",
            "cc5c3838dc0c46ac9f705ee7975991fe",
            "5ef432af29cd4fb9a8ef5e177a885de7"
          ]
        },
        "id": "8MZJ6srhT7jC",
        "outputId": "0ea59f8d-1901-4ca5-edfe-3d176cc3320a"
      },
      "source": [
        "wandb.init(project=\"sklearn\")\n",
        "wandb.sklearn.plot_confusion_matrix(Y_testbp, bpadapredictions, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2sc82zbk) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 3035<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "808a21cd4e1f407fb29c95915698a448",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210603_003919-2sc82zbk/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210603_003919-2sc82zbk/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>2</td></tr><tr><td>_timestamp</td><td>1622680765</td></tr><tr><td>_step</td><td>0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">silvery-galaxy-16</strong>: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/2sc82zbk\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/2sc82zbk</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:2sc82zbk). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">copper-star-17</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/3uxf7kwo\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/3uxf7kwo</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210603_003953-3uxf7kwo</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRkOp0EyMvNW"
      },
      "source": [
        "wandb.sklearn.plot_regressor(search, X_train, X_test, y_train.squeeze(), y_test.squeeze())\n",
        "wandb.init(project=\"sklearn\")\n",
        "ica = FastICA(n_components=77)\n",
        "S_ica_ = ica.fit_transform(the_real_one)\n",
        "X_train, X_test, y_train, y_test = train_test_split(S_ica_, y_full, test_size=0.25, random_state=22)\n",
        "# Train model, get predictions\n",
        "rf = RandomForestRegressor()\n",
        "param_grid = {'n_estimators': [47],\n",
        "              \"max_depth\": [6],\n",
        "              \"max_features\" : ['auto'],\n",
        "              \"min_samples_split\" : [15],\n",
        "              \"min_samples_leaf\" : [13]}\n",
        "search = HalvingGridSearchCV(rf, param_grid, random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "y_pred = search.predict(X_test)\n",
        "#reg = NuSVR()\n",
        "#reg.fit(X_train, y_train)\n",
        "#y_pred = reg.predict(X_test)\n",
        "# Visualize all regression plots\n",
        "wandb.sklearn.plot_regressor(search, X_train, X_test, y_train.squeeze(), y_test.squeeze())\n",
        "wandb.init(project=\"sklearn\")\n",
        "pca = PCA(n_components=77)\n",
        "pca_ = pca.fit_transform(the_real_one)\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_, y_full, test_size=0.25, random_state=22)\n",
        "# Train model, get predictions\n",
        "rf = RandomForestRegressor()\n",
        "param_grid = {'n_estimators': [47],\n",
        "              \"max_depth\": [6],\n",
        "              \"max_features\" : ['auto'],\n",
        "              \"min_samples_split\" : [15],\n",
        "              \"min_samples_leaf\" : [13]}\n",
        "search = HalvingGridSearchCV(rf, param_grid, random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "y_pred = search.predict(X_test)\n",
        "#reg = NuSVR()\n",
        "#reg.fit(X_train, y_train)\n",
        "#y_pred = reg.predict(X_test)\n",
        "# Visualize all regression plots\n",
        "wandb.sklearn.plot_regressor(search, X_train, X_test, y_train.squeeze(), y_test.squeeze())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6IHDBh9nr5k"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "lkXvd9qIJVDV",
        "outputId": "14f8236d-a044-4918-8809-6dc59b757964"
      },
      "source": [
        "!pip install wandb -qq\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import wandb\n",
        "wandb.init(project='sklearn')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 27.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 44.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 56.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.3MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">zany-blaze-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/hc5vwi1v\" target=\"_blank\">https://wandb.ai/stream-nicki-minaj/sklearn/runs/hc5vwi1v</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210602_235347-hc5vwi1v</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fa2822d35d0>"
            ],
            "text/html": [
              "<h1>Run(hc5vwi1v)</h1><iframe src=\"https://wandb.ai/stream-nicki-minaj/sklearn/runs/hc5vwi1v\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "wi0PBZWMnIvS",
        "outputId": "69e855c8-9921-408a-a147-bb8b68f06e8e"
      },
      "source": [
        "# ACCURACY OF EACH \n",
        "\n",
        "# organize so data matrices are grouped together... \n",
        "accuracies = [0.43257302921168467,\n",
        "              0.4297719087635054,\n",
        "              0.4533813525410164,\n",
        "              0.4449039163220628,\n",
        "              0.43420092434930674,\n",
        "              0.4490391632206276,\n",
        "              0.4500121624908781,\n",
        "              0.4286061785453661,\n",
        "              0.4449039163220628,\n",
        "              0.4478229141328144,\n",
        "              0.46144490391632204,\n",
        "              0.45487715884213087,\n",
        "              0.4478229141328144,\n",
        "              0.45974215519338363,\n",
        "              0.4551204086596935]\n",
        "models = ['Genius ADA', \n",
        "          'Genius Ridge', \n",
        "          'Genius Gradient', \n",
        "          'Large ADA', \n",
        "          'Large Ridge', \n",
        "          'Large Gradient', \n",
        "          'Large Scaled ADA', \n",
        "          'Large Scaled Ridge', \n",
        "          'Large Scaled Gradient', \n",
        "          'Small ADA', \n",
        "          'Small Ridge', \n",
        "          'Small Gradient', \n",
        "          'Small Scaled ADA', \n",
        "          'Small Scaled Ridge', \n",
        "          'Small Scaled Gradient']\n",
        "#for key in classification_dict:\n",
        "  #models.append(key)\n",
        "  #accuracies.append(classification_dict[key]['accuracy'])\n",
        "  #print(key)\n",
        "  #print(classification_dict[key]['accuracy'])   \n",
        "\n",
        "  # ADA: blue, RIDGE: oranage, BAGGING: green, GRADIENT: purple, red\n",
        "\n",
        "\n",
        "#fig = plt.figure(figsize=(30, 10))\n",
        "#ax = fig.add_axes([0,0,1,1])\n",
        "#ax.bar(models, accuracies, color=['blue', 'orange', 'purple', 'blue', 'orange', 'purple', 'blue', 'orange', 'purple', 'blue', 'orange', 'purple', 'blue', 'orange', 'purple'])\n",
        "#ax.bar(models, accuracies, color=['firebrick', 'chartreuse', 'steelblue', 'indianred', 'orchid', 'chocolate', 'darkorange', 'mediumspringgreen', 'gold', 'mediumslateblue', 'olivedrab', 'yellowgreen', 'darkcyan', 'palegreen', 'goldenrod', 'deeppink'])\n",
        "#plt.show()\n",
        "\n",
        "              \n",
        "\n",
        "\n",
        "labels = ['Genius', 'Tracks', 'Scaled Tracks', 'Aggregated Tracks', 'Scaled Aggregated Tracks']\n",
        "ADA = [0.43257302921168467,\n",
        "       0.4449039163220628,\n",
        "       0.4500121624908781,\n",
        "       0.4478229141328144,\n",
        "       0.4478229141328144]\n",
        "ridge = [0.4297719087635054,\n",
        "         0.43420092434930674,\n",
        "         0.4286061785453661,\n",
        "         0.46144490391632204,\n",
        "         0.4551204086596935]\n",
        "gradient = [0.4533813525410164,\n",
        "            0.4490391632206276,\n",
        "            0.4449039163220628,\n",
        "            0.45487715884213087,\n",
        "            0.45974215519338363]\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.2  # the width of the bars\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(12, 4)\n",
        "rects1 = ax.bar(x - width, ADA, width, label='ADA', align='edge')\n",
        "rects2 = ax.bar(x, ridge, width, label='Ridge', align='edge')\n",
        "rects3 = ax.bar(x + width, gradient, width, label='Gradient Boosting', align='edge')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Accuracy by Data and Classifier')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "fig.figsize = (50, 10)\n",
        "\n",
        "plt.ylim([0.35, 0.5])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.35, 0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZee4aJq9s7-"
      },
      "source": [
        "genius_adaf1 = 0\n",
        "genius_adaf1 += classification_dict['genius_ada']['0']['f1-score']\n",
        "genius_adaf1 += classification_dict['genius_ada']['1']['f1-score']\n",
        "genius_adaf1 += classification_dict['genius_ada']['2']['f1-score']\n",
        "genius_adaf1 /= 3\n",
        "\n",
        "genius_rf1 = 0\n",
        "genius_rf1 += classification_dict['genius_ridge']['0']['f1-score']\n",
        "genius_rf1 += classification_dict['genius_ridge']['1']['f1-score']\n",
        "genius_rf1 += classification_dict['genius_ridge']['2']['f1-score']\n",
        "genius_rf1 /= 3\n",
        "\n",
        "genius_f1 = 0\n",
        "genius_f1 += classification_dict['genius_gradient']['0']['f1-score']\n",
        "genius_f1 += classification_dict['genius_gradient']['1']['f1-score']\n",
        "genius_f1 += classification_dict['genius_gradient']['2']['f1-score']\n",
        "genius_f1 /= 3\n",
        "\n",
        "tracks_f1 = 0\n",
        "tracks_f1 += classification_dict['large_ada']['0']['f1-score']\n",
        "tracks_f1 += classification_dict['large_ada']['1']['f1-score']\n",
        "tracks_f1 += classification_dict['large_ada']['2']['f1-score']\n",
        "tracks_f1 /= 3\n",
        "\n",
        "tracks_rf1 = 0\n",
        "tracks_rf1 += classification_dict['large_ridge']['0']['f1-score']\n",
        "tracks_rf1 += classification_dict['large_ridge']['1']['f1-score']\n",
        "tracks_rf1 += classification_dict['large_ridge']['2']['f1-score']\n",
        "tracks_rf1 /= 3\n",
        "\n",
        "tracks_gf1 = 0\n",
        "tracks_gf1 += classification_dict['large_gradient']['0']['f1-score']\n",
        "tracks_gf1 += classification_dict['large_gradient']['1']['f1-score']\n",
        "tracks_gf1 += classification_dict['large_gradient']['2']['f1-score']\n",
        "tracks_gf1 /= 3\n",
        "\n",
        "scaled_tracks_f1 = 0\n",
        "scaled_tracks_f1 += classification_dict['large_pct_scaled_ada']['0']['f1-score']\n",
        "scaled_tracks_f1 += classification_dict['large_pct_scaled_ada']['1']['f1-score']\n",
        "scaled_tracks_f1 += classification_dict['large_pct_scaled_ada']['2']['f1-score']\n",
        "scaled_tracks_f1 /= 3\n",
        "\n",
        "scaled_tracks_rf1 = 0\n",
        "scaled_tracks_rf1 += classification_dict['large_pct_scaled_ridge']['0']['f1-score']\n",
        "scaled_tracks_rf1 += classification_dict['large_pct_scaled_ridge']['1']['f1-score']\n",
        "scaled_tracks_rf1 += classification_dict['large_pct_scaled_ridge']['2']['f1-score']\n",
        "scaled_tracks_rf1 /= 3\n",
        "\n",
        "scaled_tracks_gf1 = 0\n",
        "scaled_tracks_gf1 += classification_dict['large_pct_scaled_gradient']['0']['f1-score']\n",
        "scaled_tracks_gf1 += classification_dict['large_pct_scaled_gradient']['1']['f1-score']\n",
        "scaled_tracks_gf1 += classification_dict['large_pct_scaled_gradient']['2']['f1-score']\n",
        "scaled_tracks_gf1 /= 3\n",
        "\n",
        "agg_tracks_f1 = 0\n",
        "agg_tracks_f1 += classification_dict['original_ada']['0']['f1-score']\n",
        "agg_tracks_f1 += classification_dict['original_ada']['1']['f1-score']\n",
        "agg_tracks_f1 += classification_dict['original_ada']['2']['f1-score']\n",
        "agg_tracks_f1 /= 3\n",
        "\n",
        "agg_tracks_rf1 = 0\n",
        "agg_tracks_rf1 += classification_dict['original_ridge']['0']['f1-score']\n",
        "agg_tracks_rf1 += classification_dict['original_ridge']['1']['f1-score']\n",
        "agg_tracks_rf1 += classification_dict['original_ridge']['2']['f1-score']\n",
        "agg_tracks_rf1 /= 3\n",
        "\n",
        "agg_tracks_gf1 = 0\n",
        "agg_tracks_gf1 += classification_dict['original_gradient']['0']['f1-score']\n",
        "agg_tracks_gf1 += classification_dict['original_gradient']['1']['f1-score']\n",
        "agg_tracks_gf1 += classification_dict['original_gradient']['2']['f1-score']\n",
        "agg_tracks_gf1 /= 3\n",
        "\n",
        "caled_tracks_f1 = 0\n",
        "caled_tracks_f1 += classification_dict['original_scaled_ada']['0']['f1-score']\n",
        "caled_tracks_f1 += classification_dict['original_scaled_ada']['1']['f1-score']\n",
        "caled_tracks_f1 += classification_dict['original_scaled_ada']['2']['f1-score']\n",
        "caled_tracks_f1 /= 3\n",
        "\n",
        "caled_tracks_rf1 = 0\n",
        "caled_tracks_rf1 += classification_dict['small_scaled_ridge']['0']['f1-score']\n",
        "caled_tracks_rf1 += classification_dict['small_scaled_ridge']['1']['f1-score']\n",
        "caled_tracks_rf1 += classification_dict['small_scaled_ridge']['2']['f1-score']\n",
        "caled_tracks_rf1 /= 3\n",
        "\n",
        "caled_tracks_gf1 = 0\n",
        "caled_tracks_gf1 += classification_dict['original_scaled_gradient']['0']['f1-score']\n",
        "caled_tracks_gf1 += classification_dict['original_scaled_gradient']['1']['f1-score']\n",
        "caled_tracks_gf1 += classification_dict['original_scaled_gradient']['2']['f1-score']\n",
        "caled_tracks_gf1 /= 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "-k3N-n3FA3qB",
        "outputId": "87f46753-34e8-423e-d18f-c287f55a255b"
      },
      "source": [
        "labels = ['Genius', 'Tracks', 'Scaled Tracks', 'Aggregated Tracks', 'Scaled Aggregated Tracks']\n",
        "ADA = [genius_adaf1, tracks_f1, scaled_tracks_f1, agg_tracks_f1, caled_tracks_f1]\n",
        "ridge = [genius_rf1, tracks_rf1, scaled_tracks_rf1, agg_tracks_rf1, caled_tracks_rf1]\n",
        "gradient = [genius_f1, tracks_gf1, scaled_tracks_gf1, agg_tracks_gf1, caled_tracks_gf1]\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.2  # the width of the bars\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(12, 4)\n",
        "rects1 = ax.bar(x - width, ADA, width, label='ADA', align='edge')\n",
        "rects2 = ax.bar(x, ridge, width, label='Ridge', align='edge')\n",
        "rects3 = ax.bar(x + width, gradient, width, label='Gradient Boosting', align='edge')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('F-1 Score')\n",
        "ax.set_title('F-1 Score by Data and Classifier')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "fig.figsize = (50, 10)\n",
        "\n",
        "plt.ylim([0.35, 0.5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.35, 0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jiBhpM1m6IL",
        "outputId": "dabf9bbd-bea9-4cb7-dc2a-66e00b78940c"
      },
      "source": [
        "classification_dict['large_pct_scaled_ada']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'f1-score': 0.48871181938911024,\n",
              "  'precision': 0.4730077120822622,\n",
              "  'recall': 0.5054945054945055,\n",
              "  'support': 1456},\n",
              " '1': {'f1-score': 0.4250997461008343,\n",
              "  'precision': 0.43247232472324726,\n",
              "  'recall': 0.41797432239657634,\n",
              "  'support': 1402},\n",
              " '2': {'f1-score': 0.4304932735426009,\n",
              "  'precision': 0.44,\n",
              "  'recall': 0.4213886671987231,\n",
              "  'support': 1253},\n",
              " 'accuracy': 0.4500121624908781,\n",
              " 'macro avg': {'f1-score': 0.44810161301084844,\n",
              "  'precision': 0.4484933456018365,\n",
              "  'recall': 0.44828583169660163,\n",
              "  'support': 4111},\n",
              " 'weighted avg': {'f1-score': 0.4492732485557755,\n",
              "  'precision': 0.44912318853168737,\n",
              "  'recall': 0.4500121624908781,\n",
              "  'support': 4111}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clNj-dIB-QPu"
      },
      "source": [
        "#   BUILDING DICT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSV0IuDv-Th_",
        "outputId": "b264bae4-aa0b-4180-ee70-492bd9eed664"
      },
      "source": [
        "list(classification_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['genius_ada',\n",
              " 'genius_ridge',\n",
              " 'large_ada',\n",
              " 'large_ridge',\n",
              " 'large_pct_scaled_ridge',\n",
              " 'original_ridge',\n",
              " 'genius_bagging',\n",
              " 'genius_gradient',\n",
              " 'large_gradient',\n",
              " 'large_pct_scaled_gradient',\n",
              " 'large_pct_scaled_ada',\n",
              " 'large_pct_scaled_tree',\n",
              " 'original_ada',\n",
              " 'original_gradient',\n",
              " 'original_scaled_ada',\n",
              " 'original_scaled_gradient']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "gPP5yZ55e-vN",
        "outputId": "226e869a-b68e-49a6-b9a8-129a66a80400"
      },
      "source": [
        "real"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>album_duration_minutes</th>\n",
              "      <th>year</th>\n",
              "      <th>min_loudness</th>\n",
              "      <th>max_loudness</th>\n",
              "      <th>mean_loudness</th>\n",
              "      <th>stddev_loudness</th>\n",
              "      <th>label_frequency</th>\n",
              "      <th>mean_duration</th>\n",
              "      <th>min_valence</th>\n",
              "      <th>max_valence</th>\n",
              "      <th>stddev_valence</th>\n",
              "      <th>mean_valence</th>\n",
              "      <th>weighted_avg_valence</th>\n",
              "      <th>weighted_avg_speechiness</th>\n",
              "      <th>med_liveness</th>\n",
              "      <th>stddev_liveness</th>\n",
              "      <th>stddev_instrumentalness</th>\n",
              "      <th>weighted_avg_instrumentalness</th>\n",
              "      <th>explicit</th>\n",
              "      <th>weighted_avg_energy</th>\n",
              "      <th>min_danceability</th>\n",
              "      <th>max_danceability</th>\n",
              "      <th>mean_danceability</th>\n",
              "      <th>stddev_danceability</th>\n",
              "      <th>mean_acousticness</th>\n",
              "      <th>stddev_acousticness</th>\n",
              "      <th>med_acousticness</th>\n",
              "      <th>min_popularity</th>\n",
              "      <th>max_popularity</th>\n",
              "      <th>mean_popularity</th>\n",
              "      <th>stddev_popularity</th>\n",
              "      <th>key_0_pct</th>\n",
              "      <th>key_1_pct</th>\n",
              "      <th>key_2_pct</th>\n",
              "      <th>key_3_pct</th>\n",
              "      <th>key_4_pct</th>\n",
              "      <th>key_5_pct</th>\n",
              "      <th>key_6_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>sig_5_pct</th>\n",
              "      <th>num_artists</th>\n",
              "      <th>num_features</th>\n",
              "      <th>artist_popularity_mean</th>\n",
              "      <th>artist_followers_mean</th>\n",
              "      <th>artist_popularity_min</th>\n",
              "      <th>artist_popularity_max</th>\n",
              "      <th>artist_followers_min</th>\n",
              "      <th>artist_followers_max</th>\n",
              "      <th>artist_popularity_stddev</th>\n",
              "      <th>artist_followers_stddev</th>\n",
              "      <th>mean_feat_artist_popularity</th>\n",
              "      <th>mean_feat_artist_followers</th>\n",
              "      <th>min_feat_artist_popularity</th>\n",
              "      <th>min_feat_artist_followers</th>\n",
              "      <th>max_feat_artist_popularity</th>\n",
              "      <th>max_feat_artist_followers</th>\n",
              "      <th>stddev_feat_artist_popularity</th>\n",
              "      <th>stddev_feat_artist_followers</th>\n",
              "      <th>genre_0_pct</th>\n",
              "      <th>genre_1_pct</th>\n",
              "      <th>genre_2_pct</th>\n",
              "      <th>genre_3_pct</th>\n",
              "      <th>genre_4_pct</th>\n",
              "      <th>genre_5_pct</th>\n",
              "      <th>genre_6_pct</th>\n",
              "      <th>genre_7_pct</th>\n",
              "      <th>genre_8_pct</th>\n",
              "      <th>genre_9_pct</th>\n",
              "      <th>genre_10_pct</th>\n",
              "      <th>genre_11_pct</th>\n",
              "      <th>genre_12_pct</th>\n",
              "      <th>genre_13_pct</th>\n",
              "      <th>genre_14_pct</th>\n",
              "      <th>genre_15_pct</th>\n",
              "      <th>genre_16_pct</th>\n",
              "      <th>genre_17_pct</th>\n",
              "      <th>genre_18_pct</th>\n",
              "      <th>genre_19_pct</th>\n",
              "      <th>genre_20_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "      <td>37.699950</td>\n",
              "      <td>2021</td>\n",
              "      <td>8.695784</td>\n",
              "      <td>77.746616</td>\n",
              "      <td>71.966860</td>\n",
              "      <td>2.468588</td>\n",
              "      <td>1</td>\n",
              "      <td>3.769995</td>\n",
              "      <td>52.09</td>\n",
              "      <td>55.6</td>\n",
              "      <td>15.025998</td>\n",
              "      <td>18.476000</td>\n",
              "      <td>16.069549</td>\n",
              "      <td>3.524631</td>\n",
              "      <td>9.575</td>\n",
              "      <td>5.812945</td>\n",
              "      <td>30.604008</td>\n",
              "      <td>22.075199</td>\n",
              "      <td>0</td>\n",
              "      <td>22.089854</td>\n",
              "      <td>39.40</td>\n",
              "      <td>63.3</td>\n",
              "      <td>45.330000</td>\n",
              "      <td>10.642582</td>\n",
              "      <td>76.730000</td>\n",
              "      <td>76.730000</td>\n",
              "      <td>81.6500</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>12.800000</td>\n",
              "      <td>2.699794</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18.0</td>\n",
              "      <td>538.0</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>538</td>\n",
              "      <td>538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.776000e+03</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1776.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1776.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>17</td>\n",
              "      <td>53.442883</td>\n",
              "      <td>2021</td>\n",
              "      <td>5.087701</td>\n",
              "      <td>81.197035</td>\n",
              "      <td>78.453161</td>\n",
              "      <td>1.668215</td>\n",
              "      <td>2</td>\n",
              "      <td>3.143699</td>\n",
              "      <td>75.31</td>\n",
              "      <td>82.5</td>\n",
              "      <td>20.156995</td>\n",
              "      <td>43.517059</td>\n",
              "      <td>43.974797</td>\n",
              "      <td>26.145333</td>\n",
              "      <td>11.200</td>\n",
              "      <td>10.004012</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.000364</td>\n",
              "      <td>1</td>\n",
              "      <td>55.135105</td>\n",
              "      <td>45.40</td>\n",
              "      <td>87.3</td>\n",
              "      <td>75.317647</td>\n",
              "      <td>12.166976</td>\n",
              "      <td>12.456412</td>\n",
              "      <td>12.456412</td>\n",
              "      <td>6.9500</td>\n",
              "      <td>33</td>\n",
              "      <td>72</td>\n",
              "      <td>40.941176</td>\n",
              "      <td>8.989373</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>41.176471</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>69.0</td>\n",
              "      <td>161226.0</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>161226</td>\n",
              "      <td>161226</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.230769</td>\n",
              "      <td>4.329135e+06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>54616704.0</td>\n",
              "      <td>20.753128</td>\n",
              "      <td>1.511468e+07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.117647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>52</td>\n",
              "      <td>215.010783</td>\n",
              "      <td>2021</td>\n",
              "      <td>27.651865</td>\n",
              "      <td>77.851220</td>\n",
              "      <td>67.206191</td>\n",
              "      <td>7.829765</td>\n",
              "      <td>21</td>\n",
              "      <td>4.300216</td>\n",
              "      <td>83.92</td>\n",
              "      <td>87.1</td>\n",
              "      <td>21.225589</td>\n",
              "      <td>29.830000</td>\n",
              "      <td>28.973155</td>\n",
              "      <td>9.620623</td>\n",
              "      <td>11.250</td>\n",
              "      <td>13.873995</td>\n",
              "      <td>32.165156</td>\n",
              "      <td>68.565822</td>\n",
              "      <td>0</td>\n",
              "      <td>31.134999</td>\n",
              "      <td>72.37</td>\n",
              "      <td>81.6</td>\n",
              "      <td>44.774600</td>\n",
              "      <td>19.179167</td>\n",
              "      <td>84.409600</td>\n",
              "      <td>84.409600</td>\n",
              "      <td>93.0000</td>\n",
              "      <td>13</td>\n",
              "      <td>34</td>\n",
              "      <td>18.960000</td>\n",
              "      <td>4.936164</td>\n",
              "      <td>13.461538</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>...</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>50.0</td>\n",
              "      <td>16453.0</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>16453</td>\n",
              "      <td>16453</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>2.673500e+03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>849.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>4498.0</td>\n",
              "      <td>11.313708</td>\n",
              "      <td>2.580233e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>9.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>40.477500</td>\n",
              "      <td>2021</td>\n",
              "      <td>5.084669</td>\n",
              "      <td>79.579461</td>\n",
              "      <td>76.552764</td>\n",
              "      <td>1.577898</td>\n",
              "      <td>64</td>\n",
              "      <td>3.373125</td>\n",
              "      <td>73.80</td>\n",
              "      <td>96.7</td>\n",
              "      <td>23.668895</td>\n",
              "      <td>72.475000</td>\n",
              "      <td>74.175735</td>\n",
              "      <td>6.567317</td>\n",
              "      <td>9.125</td>\n",
              "      <td>13.549375</td>\n",
              "      <td>24.003436</td>\n",
              "      <td>18.619665</td>\n",
              "      <td>0</td>\n",
              "      <td>61.188227</td>\n",
              "      <td>51.50</td>\n",
              "      <td>87.9</td>\n",
              "      <td>69.800000</td>\n",
              "      <td>16.594961</td>\n",
              "      <td>28.157500</td>\n",
              "      <td>28.157500</td>\n",
              "      <td>16.4000</td>\n",
              "      <td>24</td>\n",
              "      <td>36</td>\n",
              "      <td>28.583333</td>\n",
              "      <td>3.824760</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>135966.0</td>\n",
              "      <td>57</td>\n",
              "      <td>57</td>\n",
              "      <td>135966</td>\n",
              "      <td>135966</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>41.823017</td>\n",
              "      <td>2020</td>\n",
              "      <td>16.084775</td>\n",
              "      <td>81.914103</td>\n",
              "      <td>78.010248</td>\n",
              "      <td>4.848596</td>\n",
              "      <td>1</td>\n",
              "      <td>4.182302</td>\n",
              "      <td>71.90</td>\n",
              "      <td>90.5</td>\n",
              "      <td>28.487900</td>\n",
              "      <td>58.760000</td>\n",
              "      <td>59.015377</td>\n",
              "      <td>6.562235</td>\n",
              "      <td>32.850</td>\n",
              "      <td>17.877847</td>\n",
              "      <td>33.922389</td>\n",
              "      <td>31.894178</td>\n",
              "      <td>1</td>\n",
              "      <td>74.673965</td>\n",
              "      <td>28.00</td>\n",
              "      <td>65.5</td>\n",
              "      <td>54.750000</td>\n",
              "      <td>9.336577</td>\n",
              "      <td>9.097215</td>\n",
              "      <td>9.097215</td>\n",
              "      <td>4.4200</td>\n",
              "      <td>41</td>\n",
              "      <td>53</td>\n",
              "      <td>46.500000</td>\n",
              "      <td>4.169999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>647390.0</td>\n",
              "      <td>68</td>\n",
              "      <td>68</td>\n",
              "      <td>647390</td>\n",
              "      <td>647390</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>30.473300</td>\n",
              "      <td>1999</td>\n",
              "      <td>7.487531</td>\n",
              "      <td>75.086033</td>\n",
              "      <td>71.995339</td>\n",
              "      <td>2.927091</td>\n",
              "      <td>204</td>\n",
              "      <td>4.353329</td>\n",
              "      <td>69.50</td>\n",
              "      <td>76.3</td>\n",
              "      <td>24.618199</td>\n",
              "      <td>41.728571</td>\n",
              "      <td>42.058227</td>\n",
              "      <td>6.142869</td>\n",
              "      <td>12.600</td>\n",
              "      <td>7.080754</td>\n",
              "      <td>30.172104</td>\n",
              "      <td>73.998741</td>\n",
              "      <td>0</td>\n",
              "      <td>70.294207</td>\n",
              "      <td>27.20</td>\n",
              "      <td>58.2</td>\n",
              "      <td>43.728571</td>\n",
              "      <td>9.774067</td>\n",
              "      <td>22.448286</td>\n",
              "      <td>22.448286</td>\n",
              "      <td>3.6000</td>\n",
              "      <td>8</td>\n",
              "      <td>35</td>\n",
              "      <td>12.571429</td>\n",
              "      <td>9.947481</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.857143</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>159367.0</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>159367</td>\n",
              "      <td>159367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>56</td>\n",
              "      <td>17</td>\n",
              "      <td>60.331483</td>\n",
              "      <td>1999</td>\n",
              "      <td>85.660143</td>\n",
              "      <td>85.660143</td>\n",
              "      <td>75.658814</td>\n",
              "      <td>19.957987</td>\n",
              "      <td>71</td>\n",
              "      <td>3.548911</td>\n",
              "      <td>83.90</td>\n",
              "      <td>83.9</td>\n",
              "      <td>24.398101</td>\n",
              "      <td>43.188235</td>\n",
              "      <td>46.731975</td>\n",
              "      <td>3.583291</td>\n",
              "      <td>10.700</td>\n",
              "      <td>11.592671</td>\n",
              "      <td>15.440686</td>\n",
              "      <td>6.035377</td>\n",
              "      <td>0</td>\n",
              "      <td>64.086232</td>\n",
              "      <td>69.20</td>\n",
              "      <td>69.2</td>\n",
              "      <td>47.223529</td>\n",
              "      <td>16.006777</td>\n",
              "      <td>23.552353</td>\n",
              "      <td>23.552353</td>\n",
              "      <td>7.0800</td>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>32.294118</td>\n",
              "      <td>10.941690</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>35.294118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>587819.0</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>587819</td>\n",
              "      <td>587819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>17.647059</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.411765</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>46.941517</td>\n",
              "      <td>1999</td>\n",
              "      <td>2.516562</td>\n",
              "      <td>82.393160</td>\n",
              "      <td>81.402908</td>\n",
              "      <td>0.907825</td>\n",
              "      <td>103</td>\n",
              "      <td>4.694152</td>\n",
              "      <td>72.40</td>\n",
              "      <td>93.3</td>\n",
              "      <td>20.468502</td>\n",
              "      <td>52.920000</td>\n",
              "      <td>50.707482</td>\n",
              "      <td>3.270570</td>\n",
              "      <td>18.100</td>\n",
              "      <td>8.463656</td>\n",
              "      <td>29.561014</td>\n",
              "      <td>40.199373</td>\n",
              "      <td>0</td>\n",
              "      <td>76.314037</td>\n",
              "      <td>32.60</td>\n",
              "      <td>50.6</td>\n",
              "      <td>32.270000</td>\n",
              "      <td>10.564095</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.0163</td>\n",
              "      <td>34</td>\n",
              "      <td>57</td>\n",
              "      <td>40.600000</td>\n",
              "      <td>6.736303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>215321.0</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>215321</td>\n",
              "      <td>215321</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>44.758833</td>\n",
              "      <td>1999</td>\n",
              "      <td>5.199885</td>\n",
              "      <td>79.112533</td>\n",
              "      <td>76.730010</td>\n",
              "      <td>1.729905</td>\n",
              "      <td>4</td>\n",
              "      <td>3.729903</td>\n",
              "      <td>67.50</td>\n",
              "      <td>97.2</td>\n",
              "      <td>24.716151</td>\n",
              "      <td>57.091667</td>\n",
              "      <td>55.815206</td>\n",
              "      <td>5.762615</td>\n",
              "      <td>20.800</td>\n",
              "      <td>14.893113</td>\n",
              "      <td>36.689485</td>\n",
              "      <td>28.698280</td>\n",
              "      <td>0</td>\n",
              "      <td>73.804939</td>\n",
              "      <td>43.10</td>\n",
              "      <td>60.4</td>\n",
              "      <td>44.516667</td>\n",
              "      <td>12.546411</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.0525</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.984732</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2489.0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>2489</td>\n",
              "      <td>2489</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>38</td>\n",
              "      <td>15</td>\n",
              "      <td>48.525733</td>\n",
              "      <td>1999</td>\n",
              "      <td>7.299547</td>\n",
              "      <td>80.878674</td>\n",
              "      <td>78.544538</td>\n",
              "      <td>1.980301</td>\n",
              "      <td>275</td>\n",
              "      <td>3.235049</td>\n",
              "      <td>78.16</td>\n",
              "      <td>85.7</td>\n",
              "      <td>20.413301</td>\n",
              "      <td>40.322667</td>\n",
              "      <td>39.695422</td>\n",
              "      <td>4.885491</td>\n",
              "      <td>10.800</td>\n",
              "      <td>4.095428</td>\n",
              "      <td>24.524718</td>\n",
              "      <td>8.230068</td>\n",
              "      <td>0</td>\n",
              "      <td>75.332988</td>\n",
              "      <td>32.70</td>\n",
              "      <td>56.2</td>\n",
              "      <td>39.920000</td>\n",
              "      <td>7.972381</td>\n",
              "      <td>3.075563</td>\n",
              "      <td>3.075563</td>\n",
              "      <td>0.1380</td>\n",
              "      <td>10</td>\n",
              "      <td>41</td>\n",
              "      <td>15.466667</td>\n",
              "      <td>7.670599</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>81574.0</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>81574</td>\n",
              "      <td>81574</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 90 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  total_tracks  ...  genre_19_pct  genre_20_pct\n",
              "0              25            10  ...     10.000000      0.000000\n",
              "1              69            17  ...      0.000000      0.000000\n",
              "2              44            52  ...      1.923077      9.615385\n",
              "3              43            12  ...      0.000000      0.000000\n",
              "4              60            10  ...      0.000000      0.000000\n",
              "...           ...           ...  ...           ...           ...\n",
              "16437          31             7  ...     14.285714      0.000000\n",
              "16438          56            17  ...     11.764706      0.000000\n",
              "16439          57            10  ...      0.000000      0.000000\n",
              "16440           5            12  ...      0.000000      0.000000\n",
              "16441          38            15  ...      0.000000      0.000000\n",
              "\n",
              "[16442 rows x 90 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtNgQ3cZB8-z"
      },
      "source": [
        "X_traing, X_testg, Y_traing, Y_testg = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "X_trainb, X_testb, Y_trainb, Y_testb = train_test_split(big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "X_trainbp, X_testbp, Y_trainbp, Y_testbp = train_test_split(pct_scaled_big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "X_trainog, X_testog, Y_trainog, Y_testog = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdk4sUj5-WfA",
        "outputId": "5316cab3-44bb-4dab-822d-073119113678"
      },
      "source": [
        "# GENIUS BAGGING\n",
        "gbclf = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0)\n",
        "gbclf.fit(X_traing, Y_traing)\n",
        "gbclf.predict(X_testg)\n",
        "gb_predictions = gbclf.predict(X_testg)\n",
        "gbnum_score = gbclf.score(X_testg, Y_testg)\n",
        "gbnum_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45738295318127253"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "NnHiv1Mvu5T_",
        "outputId": "d786b161-bf58-4f0c-993a-b721883fe4d7"
      },
      "source": [
        "# LARGE BAGGING\n",
        "bbclf = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0)\n",
        "bbclf.fit(X_trainb, Y_trainb)\n",
        "bbclf.predict(X_testb)\n",
        "bb_predictions = bbclf.predict(X_testb)\n",
        "bbnum_score = bbclf.score(X_testb, Y_testb)\n",
        "bbnum_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-4f5530bd8e90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbbclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trainb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trainb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbbclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_testb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbb_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_testb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mbbnum_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_testb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_testb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbbnum_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \"\"\"\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0mpredicted_probabilitiy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         return self.classes_.take((np.argmax(predicted_probabilitiy, axis=1)),\n\u001b[1;32m    672\u001b[0m                                   axis=0)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m                 self.n_classes_)\n\u001b[0;32m--> 720\u001b[0;31m             for i in range(n_jobs))\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m# Reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m_parallel_predict_proba\u001b[0;34m(estimators, estimators_features, X, n_classes)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;31m# Resort to voting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jocPj2ayu55T"
      },
      "source": [
        "# LARGE SCALED BAGGING\n",
        "bsclf = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0)\n",
        "bsclf.fit(X_trainbp, Y_trainbp)\n",
        "bsclf.predict(X_testbp)\n",
        "bs_predictions = gbclf.predict(X_testbp)\n",
        "bsnum_score = gbclf.score(X_testbp, Y_testbp)\n",
        "bsnum_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D-3mt7Fu6Po"
      },
      "source": [
        "# SMALL BAGGING\n",
        "ogbclf = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0)\n",
        "ogbclf.fit(X_trainog, Y_trainog)\n",
        "ogbclf.predict(X_testog)\n",
        "ogb_predictions = ogbclf.predict(X_testog)\n",
        "ogbnum_score = ogbclf.score(X_testog, Y_testog)\n",
        "ogbnum_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0b2Depzu9TG"
      },
      "source": [
        "# SMALL SCALED BAGGING\n",
        "sbclf = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0)\n",
        "sbclf.fit(X_trains, Y_trains)\n",
        "sbclf.predict(X_tests)\n",
        "sb_predictions = sbclf.predict(X_tests)\n",
        "sbnum_score = sbclf.score(X_tests, Y_tests)\n",
        "sbnum_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqTMG9hGj-th"
      },
      "source": [
        "classification_dict['genius_bagging'] = classification_report(Y_testg, gb_predictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3XMjuU_-g_7",
        "outputId": "0c9246d2-cf46-450b-f7f8-95410901741d"
      },
      "source": [
        "# GENIUS GRADIENT BOOSTING \n",
        "ggbclf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
        "ggbclf.fit(X_traing, Y_traing)\n",
        "ggbpredictions = ggbclf.predict(X_testg)\n",
        "ggbnum_score = ggbclf.score(X_testg, Y_testg)\n",
        "ggbnum_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4533813525410164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBodXIXikIWK"
      },
      "source": [
        "classification_dict['genius_gradient'] = classification_report(Y_testg, ggbpredictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cS9ax-2-8Ib",
        "outputId": "72b200c5-a446-4a61-92e9-55929778bfc7"
      },
      "source": [
        "# DA BIG MAN GRADIENT BOOSTING \n",
        "bgbclf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
        "bgbclf.fit(X_trainb, Y_trainb)\n",
        "bgbpredictions = bgbclf.predict(X_testb)\n",
        "bgbnum_score = bgbclf.score(X_testb, Y_testb)\n",
        "bgbnum_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4490391632206276"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLP5QNk5kMOR"
      },
      "source": [
        "classification_dict['large_gradient'] = classification_report(Y_testb, bgbpredictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rIYKopt_Smc",
        "outputId": "9dca7186-91bf-43f5-cb8e-d183993186dd"
      },
      "source": [
        "# DA BIG MAN PCT SCALED GRADIENT BOOSTING \n",
        "bpgbclf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
        "bpgbclf.fit(X_trainbp, Y_trainbp)\n",
        "bpgbclf.predict(X_testbp)\n",
        "bpgbpredictions = bpgbclf.predict(X_testbp)\n",
        "bpgbnum_score = bpgbclf.score(X_testbp, Y_testbp)\n",
        "bpgbnum_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4449039163220628"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ygP2g4bkQVt"
      },
      "source": [
        "classification_dict['large_pct_scaled_gradient'] = classification_report(Y_testbp, bpgbpredictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqWzIDPA_UTf",
        "outputId": "fbd4da96-4fa7-447f-d436-ee73dd0f98f6"
      },
      "source": [
        "# DA BIG MAN PCT SCALED ADA \n",
        "bpadaclf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "bpadaclf.fit(X_trainbp, Y_trainbp)\n",
        "bpadaclf.predict(X_testbp)\n",
        "bpadapredictions = bpadaclf.predict(X_testbp)\n",
        "bpadanum_score = bpadaclf.score(X_testbp, Y_testbp)\n",
        "bpadanum_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4500121624908781"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDrK8sWZknp7"
      },
      "source": [
        "classification_dict['large_pct_scaled_ada'] = classification_report(Y_testbp, bpadapredictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htS5BuKC_gQA",
        "outputId": "81697587-e3c5-4851-b7c3-3053989d3f55"
      },
      "source": [
        "# DA BIG MAN PCT SCALED EXTRA TREE \n",
        "bpetclf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
        "bpetclf.fit(X_trainbp, Y_trainbp)\n",
        "bpetclf.predict(X_testbp)\n",
        "bpetpredictions = bpetclf.predict(X_testbp)\n",
        "bpetnum_score = bpetclf.score(X_testbp, Y_testbp)\n",
        "bpetnum_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44417416686937483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OyvQMiaktN7"
      },
      "source": [
        "classification_dict['large_pct_scaled_tree'] = classification_report(Y_testbp, bpetpredictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLBlyRhN_q2y",
        "outputId": "813dfbee-9896-43d6-c73e-8404513293cd"
      },
      "source": [
        "# ORIGINAL ADA\n",
        "ogadaclf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "ogadaclf.fit(X_trainog, Y_trainog)\n",
        "ogadaclf.predict(X_testog)\n",
        "ogadapredictions = ogadaclf.predict(X_testog)\n",
        "ogadanum_score = ogadaclf.score(X_testog, Y_testog)\n",
        "ogadanum_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4478229141328144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnCqwiTZky06"
      },
      "source": [
        "classification_dict['original_ada'] = classification_report(Y_testog, ogadapredictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1VgPREi_sKk",
        "outputId": "e666961e-baa4-425c-fb46-f761f2d18645"
      },
      "source": [
        "# ORIGINAL GRADIENT BOOSTING \n",
        "oggbclf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
        "oggbclf.fit(X_trainog, Y_trainog)\n",
        "oggbclf.predict(X_testog)\n",
        "oggbpredictions = oggbclf.predict(X_testog)\n",
        "oggbnum_score = oggbclf.score(X_testog, Y_testog)\n",
        "oggbnum_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45487715884213087"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVtTmgsJk9Yl"
      },
      "source": [
        "classification_dict['original_gradient'] = classification_report(Y_testog, oggbpredictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn2gBzpded4Y"
      },
      "source": [
        "X_trains, X_tests, Y_trains, Y_tests = train_test_split(scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-NBcgpOeZTg",
        "outputId": "2ff9a9ff-f7e9-46c2-9c17-90c8efbe8d03"
      },
      "source": [
        "# ORIGINAL SCALED ADA\n",
        "sadaclf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "sadaclf.fit(X_trains, Y_trains)\n",
        "sadaclf.predict(X_tests)\n",
        "sadapredictions = sadaclf.predict(X_tests)\n",
        "sadanum_score = sadaclf.score(X_tests, Y_tests)\n",
        "sadanum_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4478229141328144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ3IwujHlEJM"
      },
      "source": [
        "classification_dict['original_scaled_ada'] = classification_report(Y_tests, sadapredictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5TRxytEebs1",
        "outputId": "7e18826b-e588-4c89-efb7-8e281c6154e5"
      },
      "source": [
        "# ORIGINAL SCALED GRADIENT BOOSTING \n",
        "sgbclf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
        "sgbclf.fit(X_trains, Y_trains)\n",
        "sgbclf.predict(X_tests)\n",
        "sgbpredictions = sgbclf.predict(X_tests)\n",
        "sgbnum_score = sgbclf.score(X_tests, Y_tests)\n",
        "sgbnum_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4551204086596935"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "owmPiu0B9_vz",
        "outputId": "606571b9-5a26-4376-b79d-af641dec9b5c"
      },
      "source": [
        "genius"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_pct_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_pct_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_pct_followers</th>\n",
              "      <th>track0_dur_pct</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness_pct</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_pct</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness_pct</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>track2_dur_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>track17_percentile_total_words</th>\n",
              "      <th>track17_lyric_happy_score</th>\n",
              "      <th>track17_lyric_surprise_score</th>\n",
              "      <th>track17_lyric_sad_score</th>\n",
              "      <th>track17_lyric_angry_score</th>\n",
              "      <th>track17_lyric_fear_score</th>\n",
              "      <th>track18_genius_pageviews</th>\n",
              "      <th>track18_is_eng</th>\n",
              "      <th>track18_ttr_lexical_richness</th>\n",
              "      <th>track18_nltk_neg</th>\n",
              "      <th>track18_nltk_neu</th>\n",
              "      <th>track18_nltk_pos</th>\n",
              "      <th>track18_nltk_compound</th>\n",
              "      <th>track18_textblob_polarity</th>\n",
              "      <th>track18_textblob_subjectivity</th>\n",
              "      <th>track18_percent_unique_words</th>\n",
              "      <th>track18_percent_expletive_words</th>\n",
              "      <th>track18_percentile_total_words</th>\n",
              "      <th>track18_lyric_happy_score</th>\n",
              "      <th>track18_lyric_surprise_score</th>\n",
              "      <th>track18_lyric_sad_score</th>\n",
              "      <th>track18_lyric_angry_score</th>\n",
              "      <th>track18_lyric_fear_score</th>\n",
              "      <th>track19_genius_pageviews</th>\n",
              "      <th>track19_is_eng</th>\n",
              "      <th>track19_ttr_lexical_richness</th>\n",
              "      <th>track19_nltk_neg</th>\n",
              "      <th>track19_nltk_neu</th>\n",
              "      <th>track19_nltk_pos</th>\n",
              "      <th>track19_nltk_compound</th>\n",
              "      <th>track19_textblob_polarity</th>\n",
              "      <th>track19_textblob_subjectivity</th>\n",
              "      <th>track19_percent_unique_words</th>\n",
              "      <th>track19_percent_expletive_words</th>\n",
              "      <th>track19_percentile_total_words</th>\n",
              "      <th>track19_lyric_happy_score</th>\n",
              "      <th>track19_lyric_surprise_score</th>\n",
              "      <th>track19_lyric_sad_score</th>\n",
              "      <th>track19_lyric_angry_score</th>\n",
              "      <th>track19_lyric_fear_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>18</td>\n",
              "      <td>8.156342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.780297</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>11.10</td>\n",
              "      <td>19.191527</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>51.020574</td>\n",
              "      <td>60.0</td>\n",
              "      <td>14.90</td>\n",
              "      <td>78.776339</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>6.37</td>\n",
              "      <td>14.233384</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>57.351213</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>64.835107</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>73.725664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.840512</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.54</td>\n",
              "      <td>55.104087</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>41.435255</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.80</td>\n",
              "      <td>83.937167</td>\n",
              "      <td>100</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>8.82</td>\n",
              "      <td>37.670224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>28.077624</td>\n",
              "      <td>60.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>53.627227</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>99.677655</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>50</td>\n",
              "      <td>42.112094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.335592</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>66.70</td>\n",
              "      <td>9.573199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>51.196189</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.10</td>\n",
              "      <td>94.482624</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>45.454545</td>\n",
              "      <td>11.10</td>\n",
              "      <td>36.129761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>72.899161</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>94.272549</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>64.511617</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>57</td>\n",
              "      <td>71.675516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.399671</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>5.37</td>\n",
              "      <td>31.657482</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>46.134125</td>\n",
              "      <td>80.0</td>\n",
              "      <td>44.30</td>\n",
              "      <td>74.196647</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>9.89</td>\n",
              "      <td>38.026507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>64.828019</td>\n",
              "      <td>80.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>68.386855</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>98.461538</td>\n",
              "      <td>68</td>\n",
              "      <td>87.244838</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.345579</td>\n",
              "      <td>100</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.70</td>\n",
              "      <td>50.087619</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>70.518085</td>\n",
              "      <td>60.0</td>\n",
              "      <td>90.50</td>\n",
              "      <td>82.834537</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>34.30</td>\n",
              "      <td>36.432998</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>55.915407</td>\n",
              "      <td>80.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>80.586521</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>66</td>\n",
              "      <td>75.447026</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>73</td>\n",
              "      <td>93.678466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.129972</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>1.64</td>\n",
              "      <td>24.1</td>\n",
              "      <td>63.6</td>\n",
              "      <td>59.100000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>10.10</td>\n",
              "      <td>29.299943</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.79</td>\n",
              "      <td>41.004551</td>\n",
              "      <td>60.0</td>\n",
              "      <td>7.97</td>\n",
              "      <td>96.076926</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>47.00</td>\n",
              "      <td>58.7</td>\n",
              "      <td>56.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>6.44</td>\n",
              "      <td>34.015550</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.76</td>\n",
              "      <td>30.812300</td>\n",
              "      <td>80.0</td>\n",
              "      <td>52.90</td>\n",
              "      <td>95.969513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>37</td>\n",
              "      <td>22.552001</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>50</td>\n",
              "      <td>66.253687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.036547</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>58.50</td>\n",
              "      <td>67.3</td>\n",
              "      <td>38.1</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>72.727273</td>\n",
              "      <td>8.18</td>\n",
              "      <td>37.243740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.10</td>\n",
              "      <td>52.891234</td>\n",
              "      <td>80.0</td>\n",
              "      <td>63.40</td>\n",
              "      <td>94.465206</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>93.30</td>\n",
              "      <td>35.9</td>\n",
              "      <td>13.3</td>\n",
              "      <td>3.810000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>11.30</td>\n",
              "      <td>21.650937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.53</td>\n",
              "      <td>27.781874</td>\n",
              "      <td>60.0</td>\n",
              "      <td>12.10</td>\n",
              "      <td>90.061809</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>12</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>29</td>\n",
              "      <td>25.174041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.597975</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>12.30</td>\n",
              "      <td>59.2</td>\n",
              "      <td>43.1</td>\n",
              "      <td>0.286000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>38.70</td>\n",
              "      <td>29.595262</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.10</td>\n",
              "      <td>45.191104</td>\n",
              "      <td>80.0</td>\n",
              "      <td>62.60</td>\n",
              "      <td>83.695423</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>73.5</td>\n",
              "      <td>63.2</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.80</td>\n",
              "      <td>32.301168</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.68</td>\n",
              "      <td>52.668638</td>\n",
              "      <td>80.0</td>\n",
              "      <td>23.90</td>\n",
              "      <td>79.971867</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>56</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>67</td>\n",
              "      <td>86.023599</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.260367</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>9.33</td>\n",
              "      <td>49.746379</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>40.016664</td>\n",
              "      <td>80.0</td>\n",
              "      <td>49.40</td>\n",
              "      <td>76.848450</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>10.70</td>\n",
              "      <td>72.104077</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>29.819714</td>\n",
              "      <td>80.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>68.995967</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>38</td>\n",
              "      <td>86.902445</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>44</td>\n",
              "      <td>64.873156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.767862</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>17.80</td>\n",
              "      <td>65.756693</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>55.692952</td>\n",
              "      <td>80.0</td>\n",
              "      <td>48.60</td>\n",
              "      <td>77.469703</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>13.60</td>\n",
              "      <td>24.095041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>44.692703</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>68.040600</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9996 rows × 861 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      popularity  ...  track19_lyric_fear_score\n",
              "0             25  ...                       0.0\n",
              "1             69  ...                       0.0\n",
              "2             44  ...                       0.0\n",
              "3             43  ...                       0.0\n",
              "4             60  ...                       0.0\n",
              "...          ...  ...                       ...\n",
              "9991          66  ...                       0.0\n",
              "9992          37  ...                       0.0\n",
              "9993          12  ...                       0.0\n",
              "9994          56  ...                       0.0\n",
              "9995          38  ...                       0.0\n",
              "\n",
              "[9996 rows x 861 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE5HLRSQQdPH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "SnS1Na4XQdhP",
        "outputId": "684e7e6a-2f97-4fce-c429-20648e9908d3"
      },
      "source": [
        "plt.hist(the_real_one['score'], bins=100)\n",
        "plt.title('Distribution of Pitchfork Review Scores')\n",
        "plt.xlabel('Score')\n",
        "plt.ylabel('Count')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baRe0DcWlIV-"
      },
      "source": [
        "classification_dict['original_scaled_gradient'] = classification_report(Y_tests, sgbpredictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtxTCvAPDbIA",
        "outputId": "6de9f88b-8697-43e0-b411-0bef1c2e07cd"
      },
      "source": [
        "real['artist_followers_max'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1.644200e+04\n",
              "mean     7.212275e+05\n",
              "std      3.464546e+06\n",
              "min      0.000000e+00\n",
              "25%      4.363000e+03\n",
              "50%      3.027500e+04\n",
              "75%      1.850730e+05\n",
              "max      7.980963e+07\n",
              "Name: artist_followers_max, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVju69dJUe_T"
      },
      "source": [
        "**OPTIMIZING GRADIENT BOOST FOR SCALED TRACKS DATA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WySzcDO9Uql3"
      },
      "source": [
        "**PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1LsuggxUi7P",
        "outputId": "37a0bf4f-a19c-4624-ff9c-50eecddb023b"
      },
      "source": [
        "pca = PCA(n_components=.99)\n",
        "pca.fit(X_trains)\n",
        "train99 = pca.transform(X_trains)\n",
        "test99 = pca.transform(X_tests)\n",
        "clf99 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train99, Y_trains)\n",
        "predictions99 = clf99.predict(test99)\n",
        "clf99.score(test99, Y_tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43639017270737046"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeXIhbowVbFP",
        "outputId": "39c2dca8-c9ed-4ac1-d2c2-74fa4bc8ae4b"
      },
      "source": [
        "pca = PCA(n_components=85)\n",
        "pca.fit(X_trains)\n",
        "train85 = pca.transform(X_trains)\n",
        "test85 = pca.transform(X_tests)\n",
        "clf85 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train85, Y_trains)\n",
        "predictions85 = clf85.predict(test85)\n",
        "clf85.score(test85, Y_tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4339576745317441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz_4I_CXb8yE",
        "outputId": "208c6fa3-5dc7-468e-e201-689196f8afbd"
      },
      "source": [
        "pca = PCA(n_components=88)\n",
        "pca.fit(X_trains)\n",
        "train88 = pca.transform(X_trains)\n",
        "test88 = pca.transform(X_tests)\n",
        "clf88 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train88, Y_trains)\n",
        "predictions85 = clf88.predict(test88)\n",
        "clf88.score(test88, Y_tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43566042325468257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3Hy8KrYcEZK",
        "outputId": "0825dc37-ecf5-49e7-e212-bbda487cb58a"
      },
      "source": [
        "pca = PCA(n_components=87)\n",
        "pca.fit(X_trains)\n",
        "train87 = pca.transform(X_trains)\n",
        "test87 = pca.transform(X_tests)\n",
        "clf87 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train87, Y_trains)\n",
        "predictions87 = clf87.predict(test87)\n",
        "clf87.score(test87, Y_tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43566042325468257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm9jWQYRcEtu",
        "outputId": "8404d183-cd63-4f8a-b137-21f4e7fa6e2b"
      },
      "source": [
        "pca = PCA(n_components=86)\n",
        "pca.fit(X_trains)\n",
        "train86 = pca.transform(X_trains)\n",
        "test86 = pca.transform(X_tests)\n",
        "clf86 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train86, Y_trains)\n",
        "predictions86 = clf86.predict(test86)\n",
        "clf86.score(test86, Y_tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4327414254439309"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZTdC4c_cGbr",
        "outputId": "fbc179ec-2ef5-41a7-9a41-7a0f69c83031"
      },
      "source": [
        "pca = PCA(n_components=84)\n",
        "pca.fit(X_trains)\n",
        "train84 = pca.transform(X_trains)\n",
        "test84 = pca.transform(X_tests)\n",
        "clf84 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train84, Y_trains)\n",
        "predictions84 = clf84.predict(test84)\n",
        "clf84.score(test84, Y_tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43736317197762103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE6QGPv-cJ86",
        "outputId": "761f0e74-cd31-4cf2-c371-90e872861bd3"
      },
      "source": [
        "pca = PCA(n_components=83)\n",
        "pca.fit(X_trains)\n",
        "train83 = pca.transform(X_trains)\n",
        "test83 = pca.transform(X_tests)\n",
        "clf83 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train83, Y_trains)\n",
        "predictions83 = clf83.predict(test83)\n",
        "clf83.score(test83, Y_tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42909267818049135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDkyQEMbdv8p",
        "outputId": "cd585448-1486-4b5f-c9f0-82032bea6010"
      },
      "source": [
        "pca = PCA(n_components=81)\n",
        "pca.fit(X_trains)\n",
        "train81 = pca.transform(X_trains)\n",
        "test81 = pca.transform(X_tests)\n",
        "clf81 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train81, Y_trains)\n",
        "predictions81 = clf81.predict(test81)\n",
        "clf81.score(test81, Y_tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4378496716127463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhRUkQ7OdyeU",
        "outputId": "9b8f9188-96c9-4b97-c272-8b6a18de4297"
      },
      "source": [
        "pca = PCA(n_components=82)\n",
        "pca.fit(X_trains)\n",
        "train82 = pca.transform(X_trains)\n",
        "test82 = pca.transform(X_tests)\n",
        "clf82 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train82, Y_trains)\n",
        "predictions82 = clf82.predict(test82)\n",
        "clf82.score(test82, Y_tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43614692288980783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAyxmLPMnYt9",
        "outputId": "dc999d7a-e2f9-4e19-f448-affa98a1bebe"
      },
      "source": [
        "pca = PCA(n_components=80)\n",
        "pca.fit(X_trains)\n",
        "train82 = pca.transform(X_trains)\n",
        "test82 = pca.transform(X_tests)\n",
        "clf82 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train82, Y_trains)\n",
        "predictions82 = clf82.predict(test82)\n",
        "clf82.score(test82, Y_tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44368766723424957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMEuuLnuVzWO"
      },
      "source": [
        "**ICA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b-y6FWLV3SM",
        "outputId": "4d5029f4-4f5d-4f6d-c4f0-336b948a16c8"
      },
      "source": [
        "# TRANSFORMING TO 90 FEATURES: \n",
        "transformer = FastICA(n_components=90, random_state=0)\n",
        "X_transformed90 = transformer.fit_transform(scaled)\n",
        "X_transformed_train90, X_transformed_test90, y_train90, y_test90 = train_test_split(X_transformed90, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf90 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train90, y_train90)\n",
        "predictions90 = clf90.predict(X_transformed_test90)\n",
        "num_score = clf90.score(X_transformed_test90, y_test90)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4439309170518122"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvfi6v3Sc01y",
        "outputId": "53167589-dad1-4d25-8ec7-f7d198c50b1c"
      },
      "source": [
        "# TRANSFORMING TO 88 FEATURES: \n",
        "transformer = FastICA(n_components=88, random_state=0)\n",
        "X_transformed88i = transformer.fit_transform(scaled)\n",
        "X_transformed_train88i, X_transformed_test88i, y_train88i, y_test88i = train_test_split(X_transformed88i, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf88i = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train88i, y_train88i)\n",
        "predictions88i = clf88i.predict(X_transformed_test88i)\n",
        "num_score = clf88i.score(X_transformed_test88i, y_test88i)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4483094137679397"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0saGL8J7dLiN",
        "outputId": "9abc2b94-5e78-435e-afcd-6072fd371e81"
      },
      "source": [
        "# TRANSFORMING TO 87 FEATURES: \n",
        "transformer = FastICA(n_components=87, random_state=0)\n",
        "X_transformed87i = transformer.fit_transform(scaled)\n",
        "X_transformed_train87i, X_transformed_test87i, y_train87i, y_test87i = train_test_split(X_transformed87i, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf87i = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train87i, y_train87i)\n",
        "predictions87i = clf87i.predict(X_transformed_test87i)\n",
        "num_score = clf87i.score(X_transformed_test87i, y_test87i)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4531744101191924"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAA4T7XxdL2W",
        "outputId": "0c03afab-8856-40d3-eebb-99d67e576cf2"
      },
      "source": [
        "# TRANSFORMING TO 86 FEATURES: \n",
        "transformer = FastICA(n_components=86, random_state=0)\n",
        "X_transformed86i = transformer.fit_transform(scaled)\n",
        "X_transformed_train86i, X_transformed_test86i, y_train86i, y_test86i = train_test_split(X_transformed86i, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf86i = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train86i, y_train86i)\n",
        "predictions86i = clf86i.predict(X_transformed_test86i)\n",
        "num_score = clf86i.score(X_transformed_test86i, y_test86i)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44855266358550233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAArma54dMUI",
        "outputId": "3bb7a42a-0f5d-4877-ae2a-06190e8d3ab7"
      },
      "source": [
        "# TRANSFORMING TO 84 FEATURES: \n",
        "transformer = FastICA(n_components=84, random_state=0)\n",
        "X_transformed84i = transformer.fit_transform(scaled)\n",
        "X_transformed_train84i, X_transformed_test84i, y_train84i, y_test84i = train_test_split(X_transformed84i, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf84i = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train84i, y_train84i)\n",
        "predictions84i = clf84i.predict(X_transformed_test84i)\n",
        "num_score = clf84i.score(X_transformed_test84i, y_test84i)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4519581610313792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwWwLVkWW0EU",
        "outputId": "a6e90dff-7fa7-4cea-e0e7-4c6877c7ae61"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: \n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed85 = transformer.fit_transform(scaled)\n",
        "X_transformed_train85, X_transformed_test85, y_train85, y_test85 = train_test_split(X_transformed85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf85i = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train85, y_train85)\n",
        "predictions85i = clf85i.predict(X_transformed_test85)\n",
        "num_score = clf85i.score(X_transformed_test85, y_test85)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45147166139625394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AwNKWKGfE4Z",
        "outputId": "f8dfbdbc-36d5-4512-871a-f0601a3e439f"
      },
      "source": [
        "# TRANSFORMING TO 83 FEATURES: \n",
        "transformer = FastICA(n_components=83, random_state=0)\n",
        "X_transformed83i = transformer.fit_transform(scaled)\n",
        "X_transformed_train83i, X_transformed_test83i, y_train83i, y_test83i = train_test_split(X_transformed83i, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf83i = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train83i, y_train83i)\n",
        "predictions83i = clf83i.predict(X_transformed_test83i)\n",
        "num_score = clf83i.score(X_transformed_test83i, y_test83i)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4458769155923133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIaJUywqfQhU",
        "outputId": "44a9c7f8-f833-4f01-bca6-32b2c5e71511"
      },
      "source": [
        "# TRANSFORMING TO 82 FEATURES: \n",
        "transformer = FastICA(n_components=82, random_state=0)\n",
        "X_transformed82i = transformer.fit_transform(scaled)\n",
        "X_transformed_train84i, X_transformed_test84i, y_train84i, y_test84i = train_test_split(X_transformed82i, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf84i = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train84i, y_train84i)\n",
        "predictions84i = clf84i.predict(X_transformed_test84i)\n",
        "num_score = clf84i.score(X_transformed_test84i, y_test84i)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45803940647044517"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6kAjpTzmWi5",
        "outputId": "5a19c767-9a06-4ab6-cc9d-830b55397579"
      },
      "source": [
        "# TRANSFORMING TO 82 FEATURES: \n",
        "transformer = FastICA(n_components=81, random_state=0)\n",
        "X_transformed82i = transformer.fit_transform(scaled)\n",
        "X_transformed_train84i, X_transformed_test84i, y_train84i, y_test84i = train_test_split(X_transformed82i, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf84i = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train84i, y_train84i)\n",
        "predictions84i = clf84i.predict(X_transformed_test84i)\n",
        "num_score = clf84i.score(X_transformed_test84i, y_test84i)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45366090975431766"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a0TStzDXYtr",
        "outputId": "b4a60acb-55c5-4b55-99d0-66b977fb121d"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: \n",
        "transformer = FastICA(n_components=80, random_state=0)\n",
        "X_transformed80 = transformer.fit_transform(scaled)\n",
        "X_transformed_train80, X_transformed_test80, y_train80, y_test80 = train_test_split(X_transformed80, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf80i = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train80, y_train80)\n",
        "predictions80i = clf80i.predict(X_transformed_test80)\n",
        "num_score = clf80i.score(X_transformed_test80, y_test80)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4502554123084408"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyOlOrVCnD75",
        "outputId": "5041facb-04ea-4be6-f9c5-a40718b1a846"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: \n",
        "transformer = FastICA(n_components=79, random_state=0)\n",
        "X_transformed80 = transformer.fit_transform(scaled)\n",
        "X_transformed_train80, X_transformed_test80, y_train80, y_test80 = train_test_split(X_transformed80, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf80i = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train80, y_train80)\n",
        "predictions80i = clf80i.predict(X_transformed_test80)\n",
        "num_score = clf80i.score(X_transformed_test80, y_test80)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4432011675991243"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G1QR9QtV1jG"
      },
      "source": [
        "**K BEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfmix3NeX5Sg",
        "outputId": "0f114ac5-03b2-4d40-f340-09b48509cbc4"
      },
      "source": [
        "# K BEST 85 FEATURES\n",
        "X_new_scaled85 = SelectKBest(chi2, k=85).fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train85k, X_transformed_test85k, y_train85k, y_test85k = train_test_split(X_new_scaled85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf85k = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train85k, y_train85k)\n",
        "predictions85k = clf85k.predict(X_transformed_test85k)\n",
        "num_score = clf85k.score(X_transformed_test85k, y_test85k)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45463390902456824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBjYL2giYxe_",
        "outputId": "8ddbc8b0-d9a6-4c2a-9643-470b44e953bd"
      },
      "source": [
        "# K BEST 80 FEATURES\n",
        "X_new_scaled80 = SelectKBest(chi2, k=80).fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train80k, X_transformed_test80k, y_train80k, y_test80k = train_test_split(X_new_scaled80, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf80k = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train80k, y_train80k)\n",
        "predictions80k = clf80k.predict(X_transformed_test80k)\n",
        "num_score = clf80k.score(X_transformed_test80k, y_test80k)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45487715884213087"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz06QUFTZFhE",
        "outputId": "bd17f96e-7ec2-4f31-ba17-ea8d19af52c3"
      },
      "source": [
        "# K BEST 75 FEATURES\n",
        "X_new_scaled75 = SelectKBest(chi2, k=75).fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train75k, X_transformed_test75k, y_train75k, y_test75k = train_test_split(X_new_scaled75, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf75k = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train75k, y_train75k)\n",
        "predictions75k = clf75k.predict(X_transformed_test75k)\n",
        "num_score = clf75k.score(X_transformed_test75k, y_test75k)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4539041595718803"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bcydtBla_eM",
        "outputId": "a76e347b-7acd-46ab-c887-972b89b25f92"
      },
      "source": [
        "# K BEST 84 FEATURES no chi\n",
        "selector = SelectKBest(k=84)\n",
        "X_new_scaled84a = selector.fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train84ka, X_transformed_test84ka, y_train84ka, y_test84ka = train_test_split(X_new_scaled84a, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf84ka = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train84ka, y_train84ka)\n",
        "predictions84ka = clf84ka.predict(X_transformed_test84ka)\n",
        "num_score = clf84ka.score(X_transformed_test84ka, y_test84ka)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45949890537582094"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "qlxXyzyMs8hk",
        "outputId": "47448a2d-c099-4ead-865c-159720b173d5"
      },
      "source": [
        "scaled[['stddev_danceability', 'key_2_pct', 'key_4_pct', 'key_7_pct', 'mode_1_pct', 'genre_10_pct']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stddev_danceability</th>\n",
              "      <th>key_2_pct</th>\n",
              "      <th>key_4_pct</th>\n",
              "      <th>key_7_pct</th>\n",
              "      <th>mode_1_pct</th>\n",
              "      <th>genre_10_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.642582</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12.166976</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.352941</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.179167</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>40.384615</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.594961</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>58.333333</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.336577</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>9.774067</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.857143</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>16.006777</td>\n",
              "      <td>35.294118</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>23.529412</td>\n",
              "      <td>82.352941</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>10.564095</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>12.546411</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>91.666667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>7.972381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>86.666667</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       stddev_danceability  key_2_pct  ...  mode_1_pct  genre_10_pct\n",
              "0                10.642582  30.000000  ...   80.000000           0.0\n",
              "1                12.166976   5.882353  ...   82.352941           0.0\n",
              "2                19.179167   3.846154  ...   40.384615           0.0\n",
              "3                16.594961   8.333333  ...   58.333333           0.0\n",
              "4                 9.336577   0.000000  ...   70.000000           0.0\n",
              "...                    ...        ...  ...         ...           ...\n",
              "16437             9.774067  14.285714  ...   42.857143           0.0\n",
              "16438            16.006777  35.294118  ...   82.352941           0.0\n",
              "16439            10.564095  30.000000  ...   90.000000           0.0\n",
              "16440            12.546411   8.333333  ...   91.666667           0.0\n",
              "16441             7.972381   0.000000  ...   86.666667           0.0\n",
              "\n",
              "[16442 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC5hf48NrvA6",
        "outputId": "9f1c369e-5e5a-45f8-bd4c-b5af7841df4c"
      },
      "source": [
        "scaled.iloc[:, 79]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0.0\n",
              "1        0.0\n",
              "2        0.0\n",
              "3        0.0\n",
              "4        0.0\n",
              "        ... \n",
              "16437    0.0\n",
              "16438    0.0\n",
              "16439    0.0\n",
              "16440    0.0\n",
              "16441    0.0\n",
              "Name: genre_10_pct, Length: 16442, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abEEpHxeqs2y",
        "outputId": "def24423-f683-4a3d-e987-b97de4a078f3"
      },
      "source": [
        "selector.get_support(indices=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "       36, 38, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "       56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
              "       73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtOZKv1LbAyU",
        "outputId": "bc77ec74-a06a-4016-d04b-8f479285fa61"
      },
      "source": [
        "# K BEST 83 FEATURES no chi\n",
        "X_new_scaled83a = SelectKBest(k=83).fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train83ka, X_transformed_test83ka, y_train83ka, y_test83ka = train_test_split(X_new_scaled83a, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf83ka = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train83ka, y_train83ka)\n",
        "predictions83ka = clf83ka.predict(X_transformed_test83ka)\n",
        "num_score = clf83ka.score(X_transformed_test83ka, y_test83ka)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4582826562880078"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmGtNL8lbCFJ",
        "outputId": "f582db61-8356-4961-875f-2546fffbb2f5"
      },
      "source": [
        "# K BEST 82 FEATURES no chi\n",
        "X_new_scaled82a = SelectKBest(k=82).fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train82ka, X_transformed_test82ka, y_train82ka, y_test82ka = train_test_split(X_new_scaled82a, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf82ka = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train82ka, y_train82ka)\n",
        "predictions82ka = clf82ka.predict(X_transformed_test82ka)\n",
        "num_score = clf82ka.score(X_transformed_test82ka, y_test82ka)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4585259061055704"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1oV48DfbC5i",
        "outputId": "45755d3c-958e-4f00-ec63-6a7f0ba2392f"
      },
      "source": [
        "# K BEST 81 FEATURES no chi\n",
        "X_new_scaled81a = SelectKBest(k=81).fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train81ka, X_transformed_test81ka, y_train81ka, y_test81ka = train_test_split(X_new_scaled81a, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf81ka = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train81ka, y_train81ka)\n",
        "predictions81ka = clf81ka.predict(X_transformed_test81ka)\n",
        "num_score = clf81ka.score(X_transformed_test81ka, y_test81ka)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4539041595718803"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKvCf2P2Zbpi",
        "outputId": "60e95b13-e7b5-4de2-d94a-c3b0a33aeaea"
      },
      "source": [
        "# K BEST 85 FEATURES no chi\n",
        "X_new_scaled85a = SelectKBest(k=85).fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train85ka, X_transformed_test85ka, y_train85ka, y_test85ka = train_test_split(X_new_scaled85a, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf85ka = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train85ka, y_train85ka)\n",
        "predictions85ka = clf85ka.predict(X_transformed_test85ka)\n",
        "num_score = clf85ka.score(X_transformed_test85ka, y_test85ka)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4570664072001946"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTvhg-OUap8e",
        "outputId": "d4e37ebf-9c6b-44a1-dedc-9d33afca6dad"
      },
      "source": [
        "# K BEST 87 FEATURES no chi\n",
        "X_new_scaled87a = SelectKBest(k=87).fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train87ka, X_transformed_test87ka, y_train87ka, y_test87ka = train_test_split(X_new_scaled87a, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf87ka = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train87ka, y_train87ka)\n",
        "predictions87ka = clf87ka.predict(X_transformed_test87ka)\n",
        "num_score = clf87ka.score(X_transformed_test87ka, y_test87ka)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4543906592070056"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG8fyCpEaX_v",
        "outputId": "68d55d68-8e11-47f7-c5b4-08a0547796fe"
      },
      "source": [
        "# K BEST 88 FEATURES no chi\n",
        "X_new_scaled88a = SelectKBest(k=88).fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train88ka, X_transformed_test88ka, y_train88ka, y_test88ka = train_test_split(X_new_scaled88a, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf88ka = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train88ka, y_train88ka)\n",
        "predictions88ka = clf88ka.predict(X_transformed_test88ka)\n",
        "num_score = clf88ka.score(X_transformed_test88ka, y_test88ka)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45463390902456824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od088QDLmQcW",
        "outputId": "bd86a7ad-70e3-42a1-b7a5-5ab05ea7bef6"
      },
      "source": [
        "# K BEST 88 FEATURES no chi\n",
        "X_new_scaled88a = SelectKBest(k=86).fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train88ka, X_transformed_test88ka, y_train88ka, y_test88ka = train_test_split(X_new_scaled88a, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf88ka = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train88ka, y_train88ka)\n",
        "predictions88ka = clf88ka.predict(X_transformed_test88ka)\n",
        "num_score = clf88ka.score(X_transformed_test88ka, y_test88ka)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4517149112138166"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXlizOndZosA",
        "outputId": "a55cbca7-db25-4816-906a-bb15f5ade185"
      },
      "source": [
        "# K BEST 80 FEATURES no chi\n",
        "X_new_scaled80a = SelectKBest(k=80).fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train80ka, X_transformed_test80ka, y_train80ka, y_test80ka = train_test_split(X_new_scaled80a, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf80ka = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train80ka, y_train80ka)\n",
        "predictions80ka = clf80ka.predict(X_transformed_test80ka)\n",
        "num_score = clf80ka.score(X_transformed_test80ka, y_test80ka)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4539041595718803"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpSQ5B4daGXH"
      },
      "source": [
        "# K BEST 85 FEATURES no chi\n",
        "X_new_scaled85a = SelectKBest(chi2).fit_transform(scaled, the_real_one['tripartite_score'])\n",
        "X_transformed_train85ka, X_transformed_test85ka, y_train85ka, y_test85ka = train_test_split(X_new_scaled85a, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf85ka = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_transformed_train85ka, y_train85ka)\n",
        "predictions85ka = clf85ka.predict(X_transformed_test85ka)\n",
        "num_score = clf85ka.score(X_transformed_test85ka, y_test85ka)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlDEOkPKk00Q"
      },
      "source": [
        "# ICA GRAPH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-8-VzDbk2x5"
      },
      "source": [
        "# PCA GRAPH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFZVsAEyk31K"
      },
      "source": [
        "# K BEST GRAPH "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUilbSpoFOVl"
      },
      "source": [
        "# GENIUS SCALED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "cgAr7X8VbE5Z",
        "outputId": "b20cd3b2-035a-4aea-d39e-b815c3448ee5"
      },
      "source": [
        "genius_scores = pd.read_csv('GENIUS_SCORES.csv')\n",
        "genius_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pitchfork_id</th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_pct_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_pct_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_pct_followers</th>\n",
              "      <th>track0_dur_pct</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness_pct</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_pct</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness_pct</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>...</th>\n",
              "      <th>track17_lyric_angry_score</th>\n",
              "      <th>track17_lyric_fear_score</th>\n",
              "      <th>track18_genius_pageviews</th>\n",
              "      <th>track18_is_eng</th>\n",
              "      <th>track18_ttr_lexical_richness</th>\n",
              "      <th>track18_nltk_neg</th>\n",
              "      <th>track18_nltk_neu</th>\n",
              "      <th>track18_nltk_pos</th>\n",
              "      <th>track18_nltk_compound</th>\n",
              "      <th>track18_textblob_polarity</th>\n",
              "      <th>track18_textblob_subjectivity</th>\n",
              "      <th>track18_percent_unique_words</th>\n",
              "      <th>track18_percent_expletive_words</th>\n",
              "      <th>track18_percentile_total_words</th>\n",
              "      <th>track18_lyric_happy_score</th>\n",
              "      <th>track18_lyric_surprise_score</th>\n",
              "      <th>track18_lyric_sad_score</th>\n",
              "      <th>track18_lyric_angry_score</th>\n",
              "      <th>track18_lyric_fear_score</th>\n",
              "      <th>track19_genius_pageviews</th>\n",
              "      <th>track19_is_eng</th>\n",
              "      <th>track19_ttr_lexical_richness</th>\n",
              "      <th>track19_nltk_neg</th>\n",
              "      <th>track19_nltk_neu</th>\n",
              "      <th>track19_nltk_pos</th>\n",
              "      <th>track19_nltk_compound</th>\n",
              "      <th>track19_textblob_polarity</th>\n",
              "      <th>track19_textblob_subjectivity</th>\n",
              "      <th>track19_percent_unique_words</th>\n",
              "      <th>track19_percent_expletive_words</th>\n",
              "      <th>track19_percentile_total_words</th>\n",
              "      <th>track19_lyric_happy_score</th>\n",
              "      <th>track19_lyric_surprise_score</th>\n",
              "      <th>track19_lyric_sad_score</th>\n",
              "      <th>track19_lyric_angry_score</th>\n",
              "      <th>track19_lyric_fear_score</th>\n",
              "      <th>score</th>\n",
              "      <th>sextile_score</th>\n",
              "      <th>tripartite_score</th>\n",
              "      <th>rounded_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>18</td>\n",
              "      <td>8.156342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.780297</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>11.10</td>\n",
              "      <td>19.191527</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>51.020574</td>\n",
              "      <td>60.0</td>\n",
              "      <td>14.90</td>\n",
              "      <td>78.776339</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>6.37</td>\n",
              "      <td>14.233384</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>57.351213</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>69</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>73.725664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.840512</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.54</td>\n",
              "      <td>55.104087</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>41.435255</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.80</td>\n",
              "      <td>83.937167</td>\n",
              "      <td>100</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>8.82</td>\n",
              "      <td>37.670224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>28.077624</td>\n",
              "      <td>60.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>99.677655</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>50</td>\n",
              "      <td>42.112094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.335592</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>66.70</td>\n",
              "      <td>9.573199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>51.196189</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.10</td>\n",
              "      <td>94.482624</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>45.454545</td>\n",
              "      <td>11.10</td>\n",
              "      <td>36.129761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>72.899161</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>43</td>\n",
              "      <td>64.511617</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>57</td>\n",
              "      <td>71.675516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.399671</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>5.37</td>\n",
              "      <td>31.657482</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>46.134125</td>\n",
              "      <td>80.0</td>\n",
              "      <td>44.30</td>\n",
              "      <td>74.196647</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>9.89</td>\n",
              "      <td>38.026507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>64.828019</td>\n",
              "      <td>80.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>60</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>98.461538</td>\n",
              "      <td>68</td>\n",
              "      <td>87.244838</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.345579</td>\n",
              "      <td>100</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.70</td>\n",
              "      <td>50.087619</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>70.518085</td>\n",
              "      <td>60.0</td>\n",
              "      <td>90.50</td>\n",
              "      <td>82.834537</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>34.30</td>\n",
              "      <td>36.432998</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>55.915407</td>\n",
              "      <td>80.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>22311</td>\n",
              "      <td>66</td>\n",
              "      <td>75.447026</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>73</td>\n",
              "      <td>93.678466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.129972</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>1.64</td>\n",
              "      <td>24.1</td>\n",
              "      <td>63.6</td>\n",
              "      <td>59.100000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>10.10</td>\n",
              "      <td>29.299943</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.79</td>\n",
              "      <td>41.004551</td>\n",
              "      <td>60.0</td>\n",
              "      <td>7.97</td>\n",
              "      <td>96.076926</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>47.00</td>\n",
              "      <td>58.7</td>\n",
              "      <td>56.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>6.44</td>\n",
              "      <td>34.015550</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.76</td>\n",
              "      <td>30.812300</td>\n",
              "      <td>80.0</td>\n",
              "      <td>52.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>22314</td>\n",
              "      <td>37</td>\n",
              "      <td>22.552001</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>50</td>\n",
              "      <td>66.253687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.036547</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>58.50</td>\n",
              "      <td>67.3</td>\n",
              "      <td>38.1</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>72.727273</td>\n",
              "      <td>8.18</td>\n",
              "      <td>37.243740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.10</td>\n",
              "      <td>52.891234</td>\n",
              "      <td>80.0</td>\n",
              "      <td>63.40</td>\n",
              "      <td>94.465206</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>93.30</td>\n",
              "      <td>35.9</td>\n",
              "      <td>13.3</td>\n",
              "      <td>3.810000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>11.30</td>\n",
              "      <td>21.650937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.53</td>\n",
              "      <td>27.781874</td>\n",
              "      <td>60.0</td>\n",
              "      <td>12.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>22318</td>\n",
              "      <td>12</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>29</td>\n",
              "      <td>25.174041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.597975</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>12.30</td>\n",
              "      <td>59.2</td>\n",
              "      <td>43.1</td>\n",
              "      <td>0.286000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>38.70</td>\n",
              "      <td>29.595262</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.10</td>\n",
              "      <td>45.191104</td>\n",
              "      <td>80.0</td>\n",
              "      <td>62.60</td>\n",
              "      <td>83.695423</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>73.5</td>\n",
              "      <td>63.2</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.80</td>\n",
              "      <td>32.301168</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.68</td>\n",
              "      <td>52.668638</td>\n",
              "      <td>80.0</td>\n",
              "      <td>23.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>22321</td>\n",
              "      <td>56</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>67</td>\n",
              "      <td>86.023599</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.260367</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>9.33</td>\n",
              "      <td>49.746379</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>40.016664</td>\n",
              "      <td>80.0</td>\n",
              "      <td>49.40</td>\n",
              "      <td>76.848450</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>10.70</td>\n",
              "      <td>72.104077</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>29.819714</td>\n",
              "      <td>80.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>22324</td>\n",
              "      <td>38</td>\n",
              "      <td>86.902445</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>44</td>\n",
              "      <td>64.873156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.767862</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>17.80</td>\n",
              "      <td>65.756693</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>55.692952</td>\n",
              "      <td>80.0</td>\n",
              "      <td>48.60</td>\n",
              "      <td>77.469703</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>13.60</td>\n",
              "      <td>24.095041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>44.692703</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9996 rows × 866 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      pitchfork_id  popularity  ...  tripartite_score  rounded_score\n",
              "0                2          25  ...                 1              7\n",
              "1                3          69  ...                 2              8\n",
              "2                5          44  ...                 0              6\n",
              "3                6          43  ...                 1              8\n",
              "4                7          60  ...                 2              8\n",
              "...            ...         ...  ...               ...            ...\n",
              "9991         22311          66  ...                 2              9\n",
              "9992         22314          37  ...                 2              8\n",
              "9993         22318          12  ...                 2              8\n",
              "9994         22321          56  ...                 2              9\n",
              "9995         22324          38  ...                 1              7\n",
              "\n",
              "[9996 rows x 866 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "60YBVt87Lutt",
        "outputId": "014a053b-37c9-40a0-be28-84f06467b992"
      },
      "source": [
        "genius = pd.read_csv('DA_BIG_MAN_GENIUS_PCT_MINMAX.csv')\n",
        "genius = genius.drop('pitchfork_id', axis=1)\n",
        "genius"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_pct_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_pct_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_pct_followers</th>\n",
              "      <th>track0_dur_pct</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness_pct</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_pct</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness_pct</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>track2_dur_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>track17_percentile_total_words</th>\n",
              "      <th>track17_lyric_happy_score</th>\n",
              "      <th>track17_lyric_surprise_score</th>\n",
              "      <th>track17_lyric_sad_score</th>\n",
              "      <th>track17_lyric_angry_score</th>\n",
              "      <th>track17_lyric_fear_score</th>\n",
              "      <th>track18_genius_pageviews</th>\n",
              "      <th>track18_is_eng</th>\n",
              "      <th>track18_ttr_lexical_richness</th>\n",
              "      <th>track18_nltk_neg</th>\n",
              "      <th>track18_nltk_neu</th>\n",
              "      <th>track18_nltk_pos</th>\n",
              "      <th>track18_nltk_compound</th>\n",
              "      <th>track18_textblob_polarity</th>\n",
              "      <th>track18_textblob_subjectivity</th>\n",
              "      <th>track18_percent_unique_words</th>\n",
              "      <th>track18_percent_expletive_words</th>\n",
              "      <th>track18_percentile_total_words</th>\n",
              "      <th>track18_lyric_happy_score</th>\n",
              "      <th>track18_lyric_surprise_score</th>\n",
              "      <th>track18_lyric_sad_score</th>\n",
              "      <th>track18_lyric_angry_score</th>\n",
              "      <th>track18_lyric_fear_score</th>\n",
              "      <th>track19_genius_pageviews</th>\n",
              "      <th>track19_is_eng</th>\n",
              "      <th>track19_ttr_lexical_richness</th>\n",
              "      <th>track19_nltk_neg</th>\n",
              "      <th>track19_nltk_neu</th>\n",
              "      <th>track19_nltk_pos</th>\n",
              "      <th>track19_nltk_compound</th>\n",
              "      <th>track19_textblob_polarity</th>\n",
              "      <th>track19_textblob_subjectivity</th>\n",
              "      <th>track19_percent_unique_words</th>\n",
              "      <th>track19_percent_expletive_words</th>\n",
              "      <th>track19_percentile_total_words</th>\n",
              "      <th>track19_lyric_happy_score</th>\n",
              "      <th>track19_lyric_surprise_score</th>\n",
              "      <th>track19_lyric_sad_score</th>\n",
              "      <th>track19_lyric_angry_score</th>\n",
              "      <th>track19_lyric_fear_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>18</td>\n",
              "      <td>8.156342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.780297</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>11.10</td>\n",
              "      <td>19.191527</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>51.020574</td>\n",
              "      <td>60.0</td>\n",
              "      <td>14.90</td>\n",
              "      <td>78.776339</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>6.37</td>\n",
              "      <td>14.233384</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>57.351213</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>64.835107</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>73.725664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.840512</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.54</td>\n",
              "      <td>55.104087</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>41.435255</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.80</td>\n",
              "      <td>83.937167</td>\n",
              "      <td>100</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>8.82</td>\n",
              "      <td>37.670224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>28.077624</td>\n",
              "      <td>60.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>53.627227</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>99.677655</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>50</td>\n",
              "      <td>42.112094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.335592</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>66.70</td>\n",
              "      <td>9.573199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>51.196189</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.10</td>\n",
              "      <td>94.482624</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>45.454545</td>\n",
              "      <td>11.10</td>\n",
              "      <td>36.129761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>72.899161</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>94.272549</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>64.511617</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>57</td>\n",
              "      <td>71.675516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.399671</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>5.37</td>\n",
              "      <td>31.657482</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>46.134125</td>\n",
              "      <td>80.0</td>\n",
              "      <td>44.30</td>\n",
              "      <td>74.196647</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>9.89</td>\n",
              "      <td>38.026507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>64.828019</td>\n",
              "      <td>80.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>68.386855</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>98.461538</td>\n",
              "      <td>68</td>\n",
              "      <td>87.244838</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.345579</td>\n",
              "      <td>100</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.70</td>\n",
              "      <td>50.087619</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>70.518085</td>\n",
              "      <td>60.0</td>\n",
              "      <td>90.50</td>\n",
              "      <td>82.834537</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>34.30</td>\n",
              "      <td>36.432998</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>55.915407</td>\n",
              "      <td>80.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>80.586521</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>66</td>\n",
              "      <td>75.447026</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>73</td>\n",
              "      <td>93.678466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.129972</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>1.64</td>\n",
              "      <td>24.1</td>\n",
              "      <td>63.6</td>\n",
              "      <td>59.100000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>10.10</td>\n",
              "      <td>29.299943</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.79</td>\n",
              "      <td>41.004551</td>\n",
              "      <td>60.0</td>\n",
              "      <td>7.97</td>\n",
              "      <td>96.076926</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>47.00</td>\n",
              "      <td>58.7</td>\n",
              "      <td>56.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>6.44</td>\n",
              "      <td>34.015550</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.76</td>\n",
              "      <td>30.812300</td>\n",
              "      <td>80.0</td>\n",
              "      <td>52.90</td>\n",
              "      <td>95.969513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>37</td>\n",
              "      <td>22.552001</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>50</td>\n",
              "      <td>66.253687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.036547</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>58.50</td>\n",
              "      <td>67.3</td>\n",
              "      <td>38.1</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>72.727273</td>\n",
              "      <td>8.18</td>\n",
              "      <td>37.243740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.10</td>\n",
              "      <td>52.891234</td>\n",
              "      <td>80.0</td>\n",
              "      <td>63.40</td>\n",
              "      <td>94.465206</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>93.30</td>\n",
              "      <td>35.9</td>\n",
              "      <td>13.3</td>\n",
              "      <td>3.810000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>11.30</td>\n",
              "      <td>21.650937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.53</td>\n",
              "      <td>27.781874</td>\n",
              "      <td>60.0</td>\n",
              "      <td>12.10</td>\n",
              "      <td>90.061809</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>12</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>29</td>\n",
              "      <td>25.174041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.597975</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>12.30</td>\n",
              "      <td>59.2</td>\n",
              "      <td>43.1</td>\n",
              "      <td>0.286000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>38.70</td>\n",
              "      <td>29.595262</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.10</td>\n",
              "      <td>45.191104</td>\n",
              "      <td>80.0</td>\n",
              "      <td>62.60</td>\n",
              "      <td>83.695423</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>73.5</td>\n",
              "      <td>63.2</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.80</td>\n",
              "      <td>32.301168</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.68</td>\n",
              "      <td>52.668638</td>\n",
              "      <td>80.0</td>\n",
              "      <td>23.90</td>\n",
              "      <td>79.971867</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>56</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>67</td>\n",
              "      <td>86.023599</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.260367</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>9.33</td>\n",
              "      <td>49.746379</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>40.016664</td>\n",
              "      <td>80.0</td>\n",
              "      <td>49.40</td>\n",
              "      <td>76.848450</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>10.70</td>\n",
              "      <td>72.104077</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>29.819714</td>\n",
              "      <td>80.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>68.995967</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>38</td>\n",
              "      <td>86.902445</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>44</td>\n",
              "      <td>64.873156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.767862</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>17.80</td>\n",
              "      <td>65.756693</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>55.692952</td>\n",
              "      <td>80.0</td>\n",
              "      <td>48.60</td>\n",
              "      <td>77.469703</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>13.60</td>\n",
              "      <td>24.095041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>44.692703</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>68.040600</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9996 rows × 861 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      popularity  ...  track19_lyric_fear_score\n",
              "0             25  ...                       0.0\n",
              "1             69  ...                       0.0\n",
              "2             44  ...                       0.0\n",
              "3             43  ...                       0.0\n",
              "4             60  ...                       0.0\n",
              "...          ...  ...                       ...\n",
              "9991          66  ...                       0.0\n",
              "9992          37  ...                       0.0\n",
              "9993          12  ...                       0.0\n",
              "9994          56  ...                       0.0\n",
              "9995          38  ...                       0.0\n",
              "\n",
              "[9996 rows x 861 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "lNDeaRAMYQJt",
        "outputId": "79d1e78c-8dbf-4b98-d4c0-d04a0708f726"
      },
      "source": [
        "genius_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pitchfork_id</th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_pct_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_pct_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_pct_followers</th>\n",
              "      <th>track0_dur_pct</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness_pct</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_pct</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness_pct</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>...</th>\n",
              "      <th>track17_lyric_angry_score</th>\n",
              "      <th>track17_lyric_fear_score</th>\n",
              "      <th>track18_genius_pageviews</th>\n",
              "      <th>track18_is_eng</th>\n",
              "      <th>track18_ttr_lexical_richness</th>\n",
              "      <th>track18_nltk_neg</th>\n",
              "      <th>track18_nltk_neu</th>\n",
              "      <th>track18_nltk_pos</th>\n",
              "      <th>track18_nltk_compound</th>\n",
              "      <th>track18_textblob_polarity</th>\n",
              "      <th>track18_textblob_subjectivity</th>\n",
              "      <th>track18_percent_unique_words</th>\n",
              "      <th>track18_percent_expletive_words</th>\n",
              "      <th>track18_percentile_total_words</th>\n",
              "      <th>track18_lyric_happy_score</th>\n",
              "      <th>track18_lyric_surprise_score</th>\n",
              "      <th>track18_lyric_sad_score</th>\n",
              "      <th>track18_lyric_angry_score</th>\n",
              "      <th>track18_lyric_fear_score</th>\n",
              "      <th>track19_genius_pageviews</th>\n",
              "      <th>track19_is_eng</th>\n",
              "      <th>track19_ttr_lexical_richness</th>\n",
              "      <th>track19_nltk_neg</th>\n",
              "      <th>track19_nltk_neu</th>\n",
              "      <th>track19_nltk_pos</th>\n",
              "      <th>track19_nltk_compound</th>\n",
              "      <th>track19_textblob_polarity</th>\n",
              "      <th>track19_textblob_subjectivity</th>\n",
              "      <th>track19_percent_unique_words</th>\n",
              "      <th>track19_percent_expletive_words</th>\n",
              "      <th>track19_percentile_total_words</th>\n",
              "      <th>track19_lyric_happy_score</th>\n",
              "      <th>track19_lyric_surprise_score</th>\n",
              "      <th>track19_lyric_sad_score</th>\n",
              "      <th>track19_lyric_angry_score</th>\n",
              "      <th>track19_lyric_fear_score</th>\n",
              "      <th>score</th>\n",
              "      <th>sextile_score</th>\n",
              "      <th>tripartite_score</th>\n",
              "      <th>rounded_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>18</td>\n",
              "      <td>8.156342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.780297</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>11.10</td>\n",
              "      <td>19.191527</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>51.020574</td>\n",
              "      <td>60.0</td>\n",
              "      <td>14.90</td>\n",
              "      <td>78.776339</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>6.37</td>\n",
              "      <td>14.233384</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>57.351213</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>69</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>73.725664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.840512</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.54</td>\n",
              "      <td>55.104087</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>41.435255</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.80</td>\n",
              "      <td>83.937167</td>\n",
              "      <td>100</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>8.82</td>\n",
              "      <td>37.670224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>28.077624</td>\n",
              "      <td>60.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>99.677655</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>50</td>\n",
              "      <td>42.112094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.335592</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>66.70</td>\n",
              "      <td>9.573199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>51.196189</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.10</td>\n",
              "      <td>94.482624</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>45.454545</td>\n",
              "      <td>11.10</td>\n",
              "      <td>36.129761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>72.899161</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>43</td>\n",
              "      <td>64.511617</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>57</td>\n",
              "      <td>71.675516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.399671</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>5.37</td>\n",
              "      <td>31.657482</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>46.134125</td>\n",
              "      <td>80.0</td>\n",
              "      <td>44.30</td>\n",
              "      <td>74.196647</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>9.89</td>\n",
              "      <td>38.026507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>64.828019</td>\n",
              "      <td>80.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>60</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>98.461538</td>\n",
              "      <td>68</td>\n",
              "      <td>87.244838</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.345579</td>\n",
              "      <td>100</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.70</td>\n",
              "      <td>50.087619</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>70.518085</td>\n",
              "      <td>60.0</td>\n",
              "      <td>90.50</td>\n",
              "      <td>82.834537</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>34.30</td>\n",
              "      <td>36.432998</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>55.915407</td>\n",
              "      <td>80.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>22311</td>\n",
              "      <td>66</td>\n",
              "      <td>75.447026</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>73</td>\n",
              "      <td>93.678466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.129972</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>1.64</td>\n",
              "      <td>24.1</td>\n",
              "      <td>63.6</td>\n",
              "      <td>59.100000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>10.10</td>\n",
              "      <td>29.299943</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.79</td>\n",
              "      <td>41.004551</td>\n",
              "      <td>60.0</td>\n",
              "      <td>7.97</td>\n",
              "      <td>96.076926</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>47.00</td>\n",
              "      <td>58.7</td>\n",
              "      <td>56.6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>6.44</td>\n",
              "      <td>34.015550</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.76</td>\n",
              "      <td>30.812300</td>\n",
              "      <td>80.0</td>\n",
              "      <td>52.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>22314</td>\n",
              "      <td>37</td>\n",
              "      <td>22.552001</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>50</td>\n",
              "      <td>66.253687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.036547</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>58.50</td>\n",
              "      <td>67.3</td>\n",
              "      <td>38.1</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>72.727273</td>\n",
              "      <td>8.18</td>\n",
              "      <td>37.243740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.10</td>\n",
              "      <td>52.891234</td>\n",
              "      <td>80.0</td>\n",
              "      <td>63.40</td>\n",
              "      <td>94.465206</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>93.30</td>\n",
              "      <td>35.9</td>\n",
              "      <td>13.3</td>\n",
              "      <td>3.810000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>11.30</td>\n",
              "      <td>21.650937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.53</td>\n",
              "      <td>27.781874</td>\n",
              "      <td>60.0</td>\n",
              "      <td>12.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>22318</td>\n",
              "      <td>12</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>29</td>\n",
              "      <td>25.174041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.597975</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>12.30</td>\n",
              "      <td>59.2</td>\n",
              "      <td>43.1</td>\n",
              "      <td>0.286000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>38.70</td>\n",
              "      <td>29.595262</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.10</td>\n",
              "      <td>45.191104</td>\n",
              "      <td>80.0</td>\n",
              "      <td>62.60</td>\n",
              "      <td>83.695423</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11.00</td>\n",
              "      <td>73.5</td>\n",
              "      <td>63.2</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.80</td>\n",
              "      <td>32.301168</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.68</td>\n",
              "      <td>52.668638</td>\n",
              "      <td>80.0</td>\n",
              "      <td>23.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>22321</td>\n",
              "      <td>56</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>67</td>\n",
              "      <td>86.023599</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.260367</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>9.33</td>\n",
              "      <td>49.746379</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>40.016664</td>\n",
              "      <td>80.0</td>\n",
              "      <td>49.40</td>\n",
              "      <td>76.848450</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>10.70</td>\n",
              "      <td>72.104077</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>29.819714</td>\n",
              "      <td>80.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>22324</td>\n",
              "      <td>38</td>\n",
              "      <td>86.902445</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>44</td>\n",
              "      <td>64.873156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.767862</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>17.80</td>\n",
              "      <td>65.756693</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>55.692952</td>\n",
              "      <td>80.0</td>\n",
              "      <td>48.60</td>\n",
              "      <td>77.469703</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>13.60</td>\n",
              "      <td>24.095041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>44.692703</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9996 rows × 866 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      pitchfork_id  popularity  ...  tripartite_score  rounded_score\n",
              "0                2          25  ...                 1              7\n",
              "1                3          69  ...                 2              8\n",
              "2                5          44  ...                 0              6\n",
              "3                6          43  ...                 1              8\n",
              "4                7          60  ...                 2              8\n",
              "...            ...         ...  ...               ...            ...\n",
              "9991         22311          66  ...                 2              9\n",
              "9992         22314          37  ...                 2              8\n",
              "9993         22318          12  ...                 2              8\n",
              "9994         22321          56  ...                 2              9\n",
              "9995         22324          38  ...                 1              7\n",
              "\n",
              "[9996 rows x 866 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRKLaotSekb2"
      },
      "source": [
        "the_real_one.to_csv('SCORES_Y.csv', index=False)\n",
        "genius_scores.to_csv('GENIUS_SCORES.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "JXsJs0dFY9lz",
        "outputId": "62266f3c-40cf-4b3d-d87c-72230b33a6d6"
      },
      "source": [
        "# 3 buckets log reg \n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-227-b266de6920ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3 buckets log reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenius_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tripartite_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             w0, n_iter_i = _newton_cg(hess, func, grad, w0, args=args,\n\u001b[0;32m--> 945\u001b[0;31m                                       maxiter=max_iter, tol=tol)\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_newton_cg\u001b[0;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Inner loop: solve the Newton update by conjugate gradient, to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# avoid inverting the Hessian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mxsupi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfhess_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtermcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0malphak\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_cg\u001b[0;34m(fhess_p, fgrad, maxiter, tol)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mAp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfhess_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m# check curvature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mcurv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mhessp\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mhessProd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mhessProd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_yhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0mhessProd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxSHJYuGoG0j",
        "outputId": "065311cd-dca8-47df-f275-24b66da081fc"
      },
      "source": [
        "# ADA\n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "predictions_ada = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43257302921168467"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keFn9w153l9i",
        "outputId": "14853118-5bd8-4c1b-a345-95c092003808"
      },
      "source": [
        "classification_dict['genius_ada'] = classification_report(y_test, predictions_ada, output_dict=True)\n",
        "classification_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'genius_ada': {'0': {'f1-score': 0.48841893252769386,\n",
              "   'precision': 0.47224926971762415,\n",
              "   'recall': 0.5057351407716372,\n",
              "   'support': 959},\n",
              "  '1': {'f1-score': 0.35135135135135137,\n",
              "   'precision': 0.34805890227576974,\n",
              "   'recall': 0.35470668485675305,\n",
              "   'support': 733},\n",
              "  '2': {'f1-score': 0.4386422976501305,\n",
              "   'precision': 0.463448275862069,\n",
              "   'recall': 0.4163568773234201,\n",
              "   'support': 807},\n",
              "  'accuracy': 0.43257302921168467,\n",
              "  'macro avg': {'f1-score': 0.4261375271763919,\n",
              "   'precision': 0.42791881595182096,\n",
              "   'recall': 0.42559956765060347,\n",
              "   'support': 2499},\n",
              "  'weighted avg': {'f1-score': 0.4321403085387172,\n",
              "   'precision': 0.4329799854533935,\n",
              "   'recall': 0.43257302921168467,\n",
              "   'support': 2499}}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DE7vp5AY2au",
        "outputId": "45cec216-ac70-4828-90da-6e0430a1e468"
      },
      "source": [
        "# 3 buckets ridge classifier \n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "real_predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4293717486994798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucLI3cFGflXn",
        "outputId": "2942f0e7-a88b-4b9a-effe-cb67db98e26b"
      },
      "source": [
        "# 3 buckets ridge classifier \n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier(alpha=1.1)\n",
        "clf.fit(X_train, y_train)\n",
        "real_predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4297719087635054"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnKaC6yX23RY",
        "outputId": "001e8bcc-416f-4675-c67f-08d1f621fca1"
      },
      "source": [
        "classification_dict['genius_ridge'] = classification_report(y_test, real_predictions, output_dict=True)\n",
        "classification_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'genius_ada': {'0': {'f1-score': 0.48841893252769386,\n",
              "   'precision': 0.47224926971762415,\n",
              "   'recall': 0.5057351407716372,\n",
              "   'support': 959},\n",
              "  '1': {'f1-score': 0.35135135135135137,\n",
              "   'precision': 0.34805890227576974,\n",
              "   'recall': 0.35470668485675305,\n",
              "   'support': 733},\n",
              "  '2': {'f1-score': 0.4386422976501305,\n",
              "   'precision': 0.463448275862069,\n",
              "   'recall': 0.4163568773234201,\n",
              "   'support': 807},\n",
              "  'accuracy': 0.43257302921168467,\n",
              "  'macro avg': {'f1-score': 0.4261375271763919,\n",
              "   'precision': 0.42791881595182096,\n",
              "   'recall': 0.42559956765060347,\n",
              "   'support': 2499},\n",
              "  'weighted avg': {'f1-score': 0.4321403085387172,\n",
              "   'precision': 0.4329799854533935,\n",
              "   'recall': 0.43257302921168467,\n",
              "   'support': 2499}},\n",
              " 'genius_ridge': {'0': {'f1-score': 0.47082699137493655,\n",
              "   'precision': 0.45849802371541504,\n",
              "   'recall': 0.48383733055265904,\n",
              "   'support': 959},\n",
              "  '1': {'f1-score': 0.35855487389229723,\n",
              "   'precision': 0.3583106267029973,\n",
              "   'recall': 0.3587994542974079,\n",
              "   'support': 733},\n",
              "  '2': {'f1-score': 0.44487179487179485,\n",
              "   'precision': 0.46082337317397076,\n",
              "   'recall': 0.42998760842627015,\n",
              "   'support': 807},\n",
              "  'accuracy': 0.4297719087635054,\n",
              "  'macro avg': {'f1-score': 0.42475122004634286,\n",
              "   'precision': 0.425877341197461,\n",
              "   'recall': 0.42420813109211236,\n",
              "   'support': 2499},\n",
              "  'weighted avg': {'f1-score': 0.42951394387881414,\n",
              "   'precision': 0.4298622474060722,\n",
              "   'recall': 0.4297719087635054,\n",
              "   'support': 2499}}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JY9y7BPZBcm",
        "outputId": "ca110483-c5a6-4ced-f003-5696bc9835a8"
      },
      "source": [
        "# 3 buckets passive aggressive \n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3701480592236895"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovBTY0L4ZGem",
        "outputId": "21def114-efeb-495d-f96d-997c2f9e28a7"
      },
      "source": [
        "# 3 buckets perceptron \n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3673469387755102"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmfMMyYpZNTv",
        "outputId": "79b3090b-2210-4489-c187-2c7db2e0f300"
      },
      "source": [
        "# 3 buckets bernoulli \n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3637454981992797"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4bRbv2rZSBk",
        "outputId": "92a4d7f3-9172-46b6-d450-f01357fa447e"
      },
      "source": [
        "# 3 buckets gaussian \n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3133253301320528"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MOKAJCwft9l"
      },
      "source": [
        "**OPTIMIZING RIDGE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNypIbNykPO9",
        "outputId": "7bc0b8e9-2167-42f7-a10d-610747793d2e"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets PCA logreg\n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43937575030012005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GfkzLjsxUM9",
        "outputId": "d4d60236-5ad4-4a8f-8de9-9b097b6fe6bf"
      },
      "source": [
        "# TRANSFORMING TO 350 FEATURES: 3 buckets ICA ridge classifier\n",
        "transformer = FastICA(n_components=350, random_state=0)\n",
        "X_transformed350r = transformer.fit_transform(genius)\n",
        "X_transformed_train_350r, X_transformed_test_350r, y_train_350r, y_test_350r = train_test_split(X_transformed350r, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = RidgeClassifier().fit(X_transformed_train_350r, y_train_350r)\n",
        "predictions_350r = clf.predict(X_transformed_test_350r)\n",
        "num_score = clf.score(X_transformed_test_350r, y_test_350r)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4497799119647859"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk3KLCBaFQz9"
      },
      "source": [
        "# DA BIG MAN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "CHhCgSm_bza0",
        "outputId": "b5262fb1-ba83-4147-dd70-850780bdc1de"
      },
      "source": [
        "the_real_one = pd.read_csv('SCORES_Y.csv')\n",
        "the_real_one"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pitchfork_id</th>\n",
              "      <th>score</th>\n",
              "      <th>sextile_score</th>\n",
              "      <th>tripartite_score</th>\n",
              "      <th>rounded_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>7.7</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>6.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>7.6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>22319</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>22321</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>22322</td>\n",
              "      <td>9.3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>22323</td>\n",
              "      <td>8.1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>22324</td>\n",
              "      <td>7.4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       pitchfork_id  score  sextile_score  tripartite_score  rounded_score\n",
              "0                 2    7.5              3                 1              7\n",
              "1                 3    7.7              4                 2              8\n",
              "2                 5    6.5              1                 0              6\n",
              "3                 6    7.6              3                 1              8\n",
              "4                 7    8.0              4                 2              8\n",
              "...             ...    ...            ...               ...            ...\n",
              "16437         22319    7.5              3                 1              7\n",
              "16438         22321    9.4              5                 2              9\n",
              "16439         22322    9.3              5                 2              9\n",
              "16440         22323    8.1              5                 2              8\n",
              "16441         22324    7.4              3                 1              7\n",
              "\n",
              "[16442 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "Dalp89DGL8da",
        "outputId": "7fc62a57-5571-4a0c-c118-e37d92694aa6"
      },
      "source": [
        "big = pd.read_csv('DA_BIG_MAN.csv')\n",
        "big"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_followers</th>\n",
              "      <th>track0_dur_min</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_min</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>track2_dur_min</th>\n",
              "      <th>...</th>\n",
              "      <th>track13_feat_artist1_followers</th>\n",
              "      <th>track13_feat_artist2_popularity</th>\n",
              "      <th>track13_feat_artist2_followers</th>\n",
              "      <th>track14_feat_artist0_popularity</th>\n",
              "      <th>track14_feat_artist0_followers</th>\n",
              "      <th>track14_feat_artist1_popularity</th>\n",
              "      <th>track14_feat_artist1_followers</th>\n",
              "      <th>track14_feat_artist2_popularity</th>\n",
              "      <th>track14_feat_artist2_followers</th>\n",
              "      <th>track15_feat_artist0_popularity</th>\n",
              "      <th>track15_feat_artist0_followers</th>\n",
              "      <th>track15_feat_artist1_popularity</th>\n",
              "      <th>track15_feat_artist1_followers</th>\n",
              "      <th>track15_feat_artist2_popularity</th>\n",
              "      <th>track15_feat_artist2_followers</th>\n",
              "      <th>track16_feat_artist0_popularity</th>\n",
              "      <th>track16_feat_artist0_followers</th>\n",
              "      <th>track16_feat_artist1_popularity</th>\n",
              "      <th>track16_feat_artist1_followers</th>\n",
              "      <th>track16_feat_artist2_popularity</th>\n",
              "      <th>track16_feat_artist2_followers</th>\n",
              "      <th>track17_feat_artist0_popularity</th>\n",
              "      <th>track17_feat_artist0_followers</th>\n",
              "      <th>track17_feat_artist1_popularity</th>\n",
              "      <th>track17_feat_artist1_followers</th>\n",
              "      <th>track17_feat_artist2_popularity</th>\n",
              "      <th>track17_feat_artist2_followers</th>\n",
              "      <th>track18_feat_artist0_popularity</th>\n",
              "      <th>track18_feat_artist0_followers</th>\n",
              "      <th>track18_feat_artist1_popularity</th>\n",
              "      <th>track18_feat_artist1_followers</th>\n",
              "      <th>track18_feat_artist2_popularity</th>\n",
              "      <th>track18_feat_artist2_followers</th>\n",
              "      <th>track19_feat_artist0_popularity</th>\n",
              "      <th>track19_feat_artist0_followers</th>\n",
              "      <th>track19_feat_artist1_popularity</th>\n",
              "      <th>track19_feat_artist1_followers</th>\n",
              "      <th>track19_feat_artist2_popularity</th>\n",
              "      <th>track19_feat_artist2_followers</th>\n",
              "      <th>label_albums_reviewed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "      <td>2021</td>\n",
              "      <td>18</td>\n",
              "      <td>34.568080</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.833433</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90000</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.10</td>\n",
              "      <td>72.044934</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>119.406</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.9</td>\n",
              "      <td>4.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10000</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.37</td>\n",
              "      <td>70.090808</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>141.560</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>4.166667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>17</td>\n",
              "      <td>2021</td>\n",
              "      <td>69</td>\n",
              "      <td>65.899789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.402050</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34000</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.54</td>\n",
              "      <td>79.341449</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>96.973</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.8</td>\n",
              "      <td>5.224483</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30000</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.82</td>\n",
              "      <td>76.608098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>69.304</td>\n",
              "      <td>3.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>3.795200</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>52</td>\n",
              "      <td>2021</td>\n",
              "      <td>50</td>\n",
              "      <td>53.356644</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.316083</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60000</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>66.70</td>\n",
              "      <td>67.463578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>119.817</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.1</td>\n",
              "      <td>6.983333</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80000</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.10</td>\n",
              "      <td>76.315510</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>179.937</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>6.916183</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>2021</td>\n",
              "      <td>57</td>\n",
              "      <td>64.963270</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.945900</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00000</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.37</td>\n",
              "      <td>75.415005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>107.970</td>\n",
              "      <td>4.0</td>\n",
              "      <td>44.3</td>\n",
              "      <td>4.570550</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20000</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.89</td>\n",
              "      <td>76.674803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>160.015</td>\n",
              "      <td>4.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>4.305250</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>2020</td>\n",
              "      <td>68</td>\n",
              "      <td>73.539939</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.694367</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66000</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>41.70</td>\n",
              "      <td>78.628928</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>165.037</td>\n",
              "      <td>3.0</td>\n",
              "      <td>90.5</td>\n",
              "      <td>5.132817</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37000</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>34.30</td>\n",
              "      <td>76.370086</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>138.016</td>\n",
              "      <td>4.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>4.958417</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>1999</td>\n",
              "      <td>50</td>\n",
              "      <td>65.836051</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.524883</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>1.80000</td>\n",
              "      <td>44.5</td>\n",
              "      <td>53.7</td>\n",
              "      <td>88.400000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.60</td>\n",
              "      <td>73.841396</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.64</td>\n",
              "      <td>75.655</td>\n",
              "      <td>4.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>4.882883</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1.62000</td>\n",
              "      <td>58.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>75.900000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.50</td>\n",
              "      <td>73.175871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.17</td>\n",
              "      <td>154.323</td>\n",
              "      <td>4.0</td>\n",
              "      <td>67.10</td>\n",
              "      <td>4.816667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>56</td>\n",
              "      <td>17</td>\n",
              "      <td>1999</td>\n",
              "      <td>67</td>\n",
              "      <td>73.009415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.560000</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60000</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.33</td>\n",
              "      <td>78.580416</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>93.653</td>\n",
              "      <td>4.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>4.714667</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28000</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.70</td>\n",
              "      <td>81.556327</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>73.604</td>\n",
              "      <td>4.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>4.330000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>1999</td>\n",
              "      <td>56</td>\n",
              "      <td>67.489890</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.677333</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0.01470</td>\n",
              "      <td>20.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>24.200000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>29.10</td>\n",
              "      <td>82.331004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.89</td>\n",
              "      <td>84.700</td>\n",
              "      <td>4.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>5.731550</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>0.00135</td>\n",
              "      <td>26.4</td>\n",
              "      <td>81.2</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.62</td>\n",
              "      <td>82.393160</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>94.095</td>\n",
              "      <td>4.0</td>\n",
              "      <td>45.80</td>\n",
              "      <td>5.373333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1999</td>\n",
              "      <td>17</td>\n",
              "      <td>42.978684</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.004217</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00678</td>\n",
              "      <td>56.7</td>\n",
              "      <td>72.2</td>\n",
              "      <td>4.740000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.00</td>\n",
              "      <td>75.048133</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.47</td>\n",
              "      <td>116.134</td>\n",
              "      <td>4.0</td>\n",
              "      <td>37.4</td>\n",
              "      <td>4.580433</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.08220</td>\n",
              "      <td>39.0</td>\n",
              "      <td>83.5</td>\n",
              "      <td>1.370000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>79.112533</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.40</td>\n",
              "      <td>157.071</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.20</td>\n",
              "      <td>4.470000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>38</td>\n",
              "      <td>15</td>\n",
              "      <td>1999</td>\n",
              "      <td>44</td>\n",
              "      <td>62.155438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97000</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.80</td>\n",
              "      <td>80.746782</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>130.341</td>\n",
              "      <td>4.0</td>\n",
              "      <td>48.6</td>\n",
              "      <td>4.751550</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20000</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.60</td>\n",
              "      <td>73.579128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>110.315</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>4.290667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 520 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  ...  label_albums_reviewed\n",
              "0              25  ...                      1\n",
              "1              69  ...                      2\n",
              "2              44  ...                     21\n",
              "3              43  ...                     64\n",
              "4              60  ...                      1\n",
              "...           ...  ...                    ...\n",
              "16437          31  ...                    204\n",
              "16438          56  ...                     71\n",
              "16439          57  ...                    103\n",
              "16440           5  ...                      4\n",
              "16441          38  ...                    275\n",
              "\n",
              "[16442 rows x 520 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypejEkCd4mFw",
        "outputId": "a543fb0c-0862-4e41-f30c-49b25fee6966"
      },
      "source": [
        "# ADA\n",
        "X_train, X_test, y_train, y_test = train_test_split(big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4449039163220628"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GntA5uKFdqv6"
      },
      "source": [
        "adabigpredictions = predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwuzaAF245RA"
      },
      "source": [
        "classification_dict['large_ada'] = classification_report(y_test, predictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "RXNw8pgR5OW-",
        "outputId": "3ea81da4-9ced-4308-a32f-18dc627cf9e9"
      },
      "source": [
        "clf = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "predictions_bagging = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-39aaa3bfd8fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions_bagging\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \"\"\"\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0mtotal_n_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 verbose=self.verbose)\n\u001b[0;32m--> 380\u001b[0;31m             for i in range(n_jobs))\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[0;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnot_indices_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grKVBxS5aDeq"
      },
      "source": [
        "# 3 buckets log reg \n",
        "X_train, X_test, y_train, y_test = train_test_split(big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o6ghvFFaIGR",
        "outputId": "ced71370-d875-4a41-e989-248515ac38db"
      },
      "source": [
        "# 3 buckets ridge classifier \n",
        "X_train, X_test, y_train, y_test = train_test_split(big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "real_predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43420092434930674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54pFzaeW4NR4"
      },
      "source": [
        "classification_dict['large_ridge'] = classification_report(y_test, real_predictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpR2Ui0qaKs3",
        "outputId": "43079fff-e868-47e6-9997-86476580c429"
      },
      "source": [
        "# 3 buckets passive aggressive \n",
        "X_train, X_test, y_train, y_test = train_test_split(big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3981999513500365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRFpm_gvaRyL",
        "outputId": "51affb46-4efb-49c7-eb7b-dfd83367efd0"
      },
      "source": [
        "# 3 buckets perceptron \n",
        "X_train, X_test, y_train, y_test = train_test_split(big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4033081975188519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcUSIlZE4Yw_"
      },
      "source": [
        "classification_dict['genius_ridge'] = classification_report(y_test, real_predictions, output_dict=True)\n",
        "classification_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zndOv0B1aVMs",
        "outputId": "bfb13414-7b86-4cb1-b964-bd40ec41ad87"
      },
      "source": [
        "# 3 buckets bernoulli \n",
        "X_train, X_test, y_train, y_test = train_test_split(big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39771345171491124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43LcqVDkaXs-",
        "outputId": "82dc538b-7673-4aef-8724-1366ab448fff"
      },
      "source": [
        "# 3 buckets gaussian \n",
        "X_train, X_test, y_train, y_test = train_test_split(big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3673072245195816"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb3GwxT6klbb"
      },
      "source": [
        "**OPTIMIZING RIDGE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQz4HjXEkqw7",
        "outputId": "64667aa3-a328-4f84-f41c-b53a971d1947"
      },
      "source": [
        "#TRANSFORMING TO 500 FEATURES: the real one 3 buckets ICA ridge classifier\n",
        "transformer = FastICA(n_components=500, random_state=0)\n",
        "X_transformed500rg = transformer.fit_transform(big)\n",
        "X_transformed_train_500rg, X_transformed_test_500rg, y_train_500rg, y_test_500rg = train_test_split(X_transformed500rg, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = RidgeClassifier().fit(X_transformed_train_500rg, y_train_500rg)\n",
        "predictions_500rg = clf.predict(X_transformed_test_500rg)\n",
        "num_score500rg = clf.score(X_transformed_test_500rg, y_test_500rg)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4254439309170518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbUK1NB4vGiu",
        "outputId": "e210a109-52de-4ae2-aa01-5551dd6eb376"
      },
      "source": [
        "#TRANSFORMING TO 500 FEATURES: the real one 3 buckets ICA ridge classifier\n",
        "transformer = FastICA(n_components=400, random_state=0)\n",
        "X_transformed400rg = transformer.fit_transform(big)\n",
        "X_transformed_train_400rg, X_transformed_test_400rg, y_train_400rg, y_test_400rg = train_test_split(X_transformed400rg, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = RidgeClassifier().fit(X_transformed_train_400rg, y_train_400rg)\n",
        "predictions_400rg = clf.predict(X_transformed_test_400rg)\n",
        "num_score400rg = clf.score(X_transformed_test_400rg, y_test_400rg)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4254439309170518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hgOTztJvQgG",
        "outputId": "6b331d47-9b22-4eb8-8bdb-4d58ecb971c8"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets PCA logreg\n",
        "X_train, X_test, y_train, y_test = train_test_split(big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = BernoulliNB(alpha=2).fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4461201654098759"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25y0KXDewW5X",
        "outputId": "ce96fae1-9f15-4815-dc9c-f471687be08c"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets PCA logreg\n",
        "X_train, X_test, y_train, y_test = train_test_split(big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44636341522743855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr8GkLKqwCcm",
        "outputId": "2ed101dd-ce39-44ec-d999-48cbd699b829"
      },
      "source": [
        "# TRANSFORMING TO 500 FEATURES: genius 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=500).fit_transform(big, the_real_one['tripartite_score'])\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4359036730722452"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_9WDBkBFWpq"
      },
      "source": [
        "# DA BIG MAN SCALED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "hOmPBQ2SL-NG",
        "outputId": "f75b1046-db30-4a63-c044-3a2348eb5d25"
      },
      "source": [
        "big_scaled = pd.read_csv('DA_BIG_MAN_MINMAXED.csv')\n",
        "big_scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_followers</th>\n",
              "      <th>track0_dur_min</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_min</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>track2_dur_min</th>\n",
              "      <th>...</th>\n",
              "      <th>track13_feat_artist1_followers</th>\n",
              "      <th>track13_feat_artist2_popularity</th>\n",
              "      <th>track13_feat_artist2_followers</th>\n",
              "      <th>track14_feat_artist0_popularity</th>\n",
              "      <th>track14_feat_artist0_followers</th>\n",
              "      <th>track14_feat_artist1_popularity</th>\n",
              "      <th>track14_feat_artist1_followers</th>\n",
              "      <th>track14_feat_artist2_popularity</th>\n",
              "      <th>track14_feat_artist2_followers</th>\n",
              "      <th>track15_feat_artist0_popularity</th>\n",
              "      <th>track15_feat_artist0_followers</th>\n",
              "      <th>track15_feat_artist1_popularity</th>\n",
              "      <th>track15_feat_artist1_followers</th>\n",
              "      <th>track15_feat_artist2_popularity</th>\n",
              "      <th>track15_feat_artist2_followers</th>\n",
              "      <th>track16_feat_artist0_popularity</th>\n",
              "      <th>track16_feat_artist0_followers</th>\n",
              "      <th>track16_feat_artist1_popularity</th>\n",
              "      <th>track16_feat_artist1_followers</th>\n",
              "      <th>track16_feat_artist2_popularity</th>\n",
              "      <th>track16_feat_artist2_followers</th>\n",
              "      <th>track17_feat_artist0_popularity</th>\n",
              "      <th>track17_feat_artist0_followers</th>\n",
              "      <th>track17_feat_artist1_popularity</th>\n",
              "      <th>track17_feat_artist1_followers</th>\n",
              "      <th>track17_feat_artist2_popularity</th>\n",
              "      <th>track17_feat_artist2_followers</th>\n",
              "      <th>track18_feat_artist0_popularity</th>\n",
              "      <th>track18_feat_artist0_followers</th>\n",
              "      <th>track18_feat_artist1_popularity</th>\n",
              "      <th>track18_feat_artist1_followers</th>\n",
              "      <th>track18_feat_artist2_popularity</th>\n",
              "      <th>track18_feat_artist2_followers</th>\n",
              "      <th>track19_feat_artist0_popularity</th>\n",
              "      <th>track19_feat_artist0_followers</th>\n",
              "      <th>track19_feat_artist1_popularity</th>\n",
              "      <th>track19_feat_artist1_followers</th>\n",
              "      <th>track19_feat_artist2_popularity</th>\n",
              "      <th>track19_feat_artist2_followers</th>\n",
              "      <th>label_albums_reviewed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>3.738318</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>18</td>\n",
              "      <td>34.568080</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.334333</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90000</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>11.10</td>\n",
              "      <td>72.044934</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>51.020574</td>\n",
              "      <td>60.0</td>\n",
              "      <td>14.9</td>\n",
              "      <td>48.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10000</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>6.37</td>\n",
              "      <td>70.090808</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>57.351213</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>41.666667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>7.009346</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>65.899789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.020500</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34000</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.54</td>\n",
              "      <td>79.341449</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>41.435255</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.8</td>\n",
              "      <td>52.244833</td>\n",
              "      <td>100</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30000</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>8.82</td>\n",
              "      <td>76.608098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>28.077624</td>\n",
              "      <td>60.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>37.952000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.364964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>23.364486</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>50</td>\n",
              "      <td>53.356644</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.160833</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60000</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>66.70</td>\n",
              "      <td>67.463578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>51.196189</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.1</td>\n",
              "      <td>69.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80000</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>45.454545</td>\n",
              "      <td>11.10</td>\n",
              "      <td>76.315510</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>72.899161</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>69.161833</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.299270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>4.672897</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>57</td>\n",
              "      <td>64.963270</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.459000</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00000</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>5.37</td>\n",
              "      <td>75.415005</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>46.134125</td>\n",
              "      <td>80.0</td>\n",
              "      <td>44.3</td>\n",
              "      <td>45.705500</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20000</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>9.89</td>\n",
              "      <td>76.674803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>64.828019</td>\n",
              "      <td>80.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>43.052500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.992701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>3.738318</td>\n",
              "      <td>98.461538</td>\n",
              "      <td>68</td>\n",
              "      <td>73.539939</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.943667</td>\n",
              "      <td>100</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66000</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.70</td>\n",
              "      <td>78.628928</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>70.518085</td>\n",
              "      <td>60.0</td>\n",
              "      <td>90.5</td>\n",
              "      <td>51.328167</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37000</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>34.30</td>\n",
              "      <td>76.370086</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>55.915407</td>\n",
              "      <td>80.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>49.584167</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>31</td>\n",
              "      <td>2.336449</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>50</td>\n",
              "      <td>65.836051</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.248833</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>1.80000</td>\n",
              "      <td>44.5</td>\n",
              "      <td>53.7</td>\n",
              "      <td>88.400000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>12.60</td>\n",
              "      <td>73.841396</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.64</td>\n",
              "      <td>32.326361</td>\n",
              "      <td>80.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>48.828833</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1.62000</td>\n",
              "      <td>58.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>75.900000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>12.50</td>\n",
              "      <td>73.175871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.17</td>\n",
              "      <td>62.521979</td>\n",
              "      <td>80.0</td>\n",
              "      <td>67.10</td>\n",
              "      <td>48.166667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.087591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>56</td>\n",
              "      <td>7.009346</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>67</td>\n",
              "      <td>73.009415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.600000</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60000</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>9.33</td>\n",
              "      <td>78.580416</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>40.016664</td>\n",
              "      <td>80.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>47.146667</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28000</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>10.70</td>\n",
              "      <td>81.556327</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>29.819714</td>\n",
              "      <td>80.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>43.300000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.547445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>57</td>\n",
              "      <td>3.738318</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>56</td>\n",
              "      <td>67.489890</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>86.773333</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0.01470</td>\n",
              "      <td>20.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>24.200000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>29.10</td>\n",
              "      <td>82.331004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.89</td>\n",
              "      <td>36.191168</td>\n",
              "      <td>80.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>57.315500</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>0.00135</td>\n",
              "      <td>26.4</td>\n",
              "      <td>81.2</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>9.62</td>\n",
              "      <td>82.393160</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>38.121379</td>\n",
              "      <td>80.0</td>\n",
              "      <td>45.80</td>\n",
              "      <td>53.733333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.226277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>5</td>\n",
              "      <td>4.672897</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>17</td>\n",
              "      <td>42.978684</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.042167</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00678</td>\n",
              "      <td>56.7</td>\n",
              "      <td>72.2</td>\n",
              "      <td>4.740000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>19.00</td>\n",
              "      <td>75.048133</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.47</td>\n",
              "      <td>49.622492</td>\n",
              "      <td>80.0</td>\n",
              "      <td>37.4</td>\n",
              "      <td>45.804333</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.08220</td>\n",
              "      <td>39.0</td>\n",
              "      <td>83.5</td>\n",
              "      <td>1.370000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>13.00</td>\n",
              "      <td>79.112533</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.40</td>\n",
              "      <td>63.635296</td>\n",
              "      <td>20.0</td>\n",
              "      <td>89.20</td>\n",
              "      <td>44.700000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.094891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>38</td>\n",
              "      <td>6.074766</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>44</td>\n",
              "      <td>62.155438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97000</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>17.80</td>\n",
              "      <td>80.746782</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>55.692952</td>\n",
              "      <td>80.0</td>\n",
              "      <td>48.6</td>\n",
              "      <td>47.515500</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20000</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>13.60</td>\n",
              "      <td>73.579128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>44.692703</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>42.906667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 520 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  ...  label_albums_reviewed\n",
              "0              25  ...               0.000000\n",
              "1              69  ...               0.364964\n",
              "2              44  ...               7.299270\n",
              "3              43  ...              22.992701\n",
              "4              60  ...               0.000000\n",
              "...           ...  ...                    ...\n",
              "16437          31  ...              74.087591\n",
              "16438          56  ...              25.547445\n",
              "16439          57  ...              37.226277\n",
              "16440           5  ...               1.094891\n",
              "16441          38  ...             100.000000\n",
              "\n",
              "[16442 rows x 520 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvINYWjvMUPY"
      },
      "source": [
        "# 3 buckets log reg \n",
        "X_train, X_test, y_train, y_test = train_test_split(big_scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvMUiE6LQsiZ",
        "outputId": "3ea922ce-640e-448a-ed5c-ed0ad67f8dca"
      },
      "source": [
        "# 3 buckets ridge classifier \n",
        "X_train, X_test, y_train, y_test = train_test_split(big_scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "real_predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.4963e-83): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43420092434930674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nmnr7x46Qmw"
      },
      "source": [
        "classification_dict['large_scaled_ridge'] = classification_report(y_test, real_predictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYIdRHWOQvuP",
        "outputId": "5c4f4ed3-5fda-4562-e5d3-2fafd264a53d"
      },
      "source": [
        "# 3 buckets passive aggressive \n",
        "X_train, X_test, y_train, y_test = train_test_split(big_scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.383118462661153"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NrwKlDQ3QF",
        "outputId": "098cf1a8-2e9e-4415-9512-b3f0a50ff97e"
      },
      "source": [
        "# 3 buckets perceptron \n",
        "X_train, X_test, y_train, y_test = train_test_split(big_scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3619557285332036"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8drQQuSQ5xq",
        "outputId": "37e07288-4163-42f1-d8d9-242abbc26996"
      },
      "source": [
        "# 3 buckets bernoulli \n",
        "X_train, X_test, y_train, y_test = train_test_split(big_scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39674045244466066"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi92IJ8CQ9BJ",
        "outputId": "50a97606-99ac-4811-d2b7-20e349e6e31b"
      },
      "source": [
        "# 3 buckets gaussian \n",
        "X_train, X_test, y_train, y_test = train_test_split(big_scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3626854779858915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPUXoluaRw2u"
      },
      "source": [
        "**OPTIMIZING RIDGE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI0hH7tJRzs3",
        "outputId": "3757b547-43e3-4e2f-dc2d-1ee05a24873c"
      },
      "source": [
        "# TRANSFORMING TO 500 FEATURES: the real one 3 buckets ICA ridge classifier\n",
        "transformer = FastICA(n_components=500, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(big_scaled)\n",
        "X_transformed_train_85, X_transformed_test_85, y_train_85, y_test_85 = train_test_split(X_transformed55, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = RidgeClassifier().fit(X_transformed_train_85, y_train_85)\n",
        "predictions_500 = clf.predict(X_transformed_test_85)\n",
        "num_score = clf.score(X_transformed_test_85, y_test_85)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3493067380199465"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYF-RqoWTGhL",
        "outputId": "44b49d1d-db81-43d1-f63b-da1a376a6fcc"
      },
      "source": [
        "# TRANSFORMING TO 400 FEATURES: the real one 3 buckets ICA ridge classifier\n",
        "transformer = FastICA(n_components=400, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(big_scaled)\n",
        "X_transformed_train_400, X_transformed_test_400, y_train_400, y_test_400 = train_test_split(X_transformed55, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = RidgeClassifier().fit(X_transformed_train_400, y_train_400)\n",
        "predictions_400 = clf.predict(X_transformed_test_400)\n",
        "num_score400 = clf.score(X_transformed_test_400, y_test_400)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3493067380199465"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNcESAxww0Ie",
        "outputId": "a8763034-5d7f-4f68-c951-fd23abaa0aa0"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets PCA logreg\n",
        "X_train, X_test, y_train, y_test = train_test_split(big_scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34906348820238386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLR9VZsUFZon"
      },
      "source": [
        "# DA BIG MAN PCT SCALED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "OAKgW9WqSM0s",
        "outputId": "191b7ee7-6502-4c70-a314-afed8b6879cb"
      },
      "source": [
        "pct_scaled_big = pd.read_csv('DA_BIG_MAN_MINMAXED_PCT.csv')\n",
        "pct_scaled_big = pct_scaled_big.drop('pitchfork_id', axis=1)\n",
        "pct_scaled_big"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_pct_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_pct_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_pct_followers</th>\n",
              "      <th>track0_dur_pct</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness_pct</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_pct</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness_pct</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>track2_dur_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>track13_feat_artist1_pct_followers</th>\n",
              "      <th>track13_feat_artist2_popularity</th>\n",
              "      <th>track13_feat_artist2_pct_followers</th>\n",
              "      <th>track14_feat_artist0_popularity</th>\n",
              "      <th>track14_feat_artist0_pct_followers</th>\n",
              "      <th>track14_feat_artist1_popularity</th>\n",
              "      <th>track14_feat_artist1_pct_followers</th>\n",
              "      <th>track14_feat_artist2_popularity</th>\n",
              "      <th>track14_feat_artist2_pct_followers</th>\n",
              "      <th>track15_feat_artist0_popularity</th>\n",
              "      <th>track15_feat_artist0_pct_followers</th>\n",
              "      <th>track15_feat_artist1_popularity</th>\n",
              "      <th>track15_feat_artist1_pct_followers</th>\n",
              "      <th>track15_feat_artist2_popularity</th>\n",
              "      <th>track15_feat_artist2_pct_followers</th>\n",
              "      <th>track16_feat_artist0_popularity</th>\n",
              "      <th>track16_feat_artist0_pct_followers</th>\n",
              "      <th>track16_feat_artist1_popularity</th>\n",
              "      <th>track16_feat_artist1_pct_followers</th>\n",
              "      <th>track16_feat_artist2_popularity</th>\n",
              "      <th>track16_feat_artist2_pct_followers</th>\n",
              "      <th>track17_feat_artist0_popularity</th>\n",
              "      <th>track17_feat_artist0_pct_followers</th>\n",
              "      <th>track17_feat_artist1_popularity</th>\n",
              "      <th>track17_feat_artist1_pct_followers</th>\n",
              "      <th>track17_feat_artist2_popularity</th>\n",
              "      <th>track17_feat_artist2_pct_followers</th>\n",
              "      <th>track18_feat_artist0_popularity</th>\n",
              "      <th>track18_feat_artist0_pct_followers</th>\n",
              "      <th>track18_feat_artist1_popularity</th>\n",
              "      <th>track18_feat_artist1_pct_followers</th>\n",
              "      <th>track18_feat_artist2_popularity</th>\n",
              "      <th>track18_feat_artist2_pct_followers</th>\n",
              "      <th>track19_feat_artist0_popularity</th>\n",
              "      <th>track19_feat_artist0_pct_followers</th>\n",
              "      <th>track19_feat_artist1_popularity</th>\n",
              "      <th>track19_feat_artist1_pct_followers</th>\n",
              "      <th>track19_feat_artist2_popularity</th>\n",
              "      <th>track19_feat_artist2_pct_followers</th>\n",
              "      <th>label_albums_reviewed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>18</td>\n",
              "      <td>8.156342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.780297</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90000</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>11.10</td>\n",
              "      <td>19.191527</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>51.020574</td>\n",
              "      <td>60.0</td>\n",
              "      <td>14.9</td>\n",
              "      <td>78.776339</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10000</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>6.37</td>\n",
              "      <td>14.233384</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>57.351213</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>64.835107</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.426104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>69</td>\n",
              "      <td>73.725664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.840512</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34000</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.54</td>\n",
              "      <td>55.104087</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>41.435255</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.8</td>\n",
              "      <td>83.937167</td>\n",
              "      <td>100</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30000</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>8.82</td>\n",
              "      <td>37.670224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>28.077624</td>\n",
              "      <td>60.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>53.627227</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.382800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>99.677655</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>50</td>\n",
              "      <td>42.112094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.335592</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60000</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>66.70</td>\n",
              "      <td>9.573199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>51.196189</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.1</td>\n",
              "      <td>94.482624</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80000</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>45.454545</td>\n",
              "      <td>11.10</td>\n",
              "      <td>36.129761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>72.899161</td>\n",
              "      <td>80.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>94.272549</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.938572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>64.511617</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>57</td>\n",
              "      <td>71.675516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.399671</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00000</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>5.37</td>\n",
              "      <td>31.657482</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>46.134125</td>\n",
              "      <td>80.0</td>\n",
              "      <td>44.3</td>\n",
              "      <td>74.196647</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20000</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>9.89</td>\n",
              "      <td>38.026507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>64.828019</td>\n",
              "      <td>80.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>68.386855</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.635081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>98.461538</td>\n",
              "      <td>68</td>\n",
              "      <td>87.244838</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.345579</td>\n",
              "      <td>100</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66000</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.70</td>\n",
              "      <td>50.087619</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>70.518085</td>\n",
              "      <td>60.0</td>\n",
              "      <td>90.5</td>\n",
              "      <td>82.834537</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37000</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>34.30</td>\n",
              "      <td>36.432998</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>55.915407</td>\n",
              "      <td>80.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>80.586521</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.426104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>31</td>\n",
              "      <td>11.455419</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>50</td>\n",
              "      <td>73.628319</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>86.957658</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>1.80000</td>\n",
              "      <td>44.5</td>\n",
              "      <td>53.7</td>\n",
              "      <td>88.400000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>12.60</td>\n",
              "      <td>25.022960</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.64</td>\n",
              "      <td>32.326361</td>\n",
              "      <td>80.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>79.512129</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1.62000</td>\n",
              "      <td>58.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>75.900000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>12.50</td>\n",
              "      <td>22.710814</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.17</td>\n",
              "      <td>62.521979</td>\n",
              "      <td>80.0</td>\n",
              "      <td>67.10</td>\n",
              "      <td>78.516120</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>92.169444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>56</td>\n",
              "      <td>92.543486</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>67</td>\n",
              "      <td>86.023599</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.260367</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60000</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>9.33</td>\n",
              "      <td>49.746379</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>40.016664</td>\n",
              "      <td>80.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>76.848450</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28000</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>10.70</td>\n",
              "      <td>72.104077</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>29.819714</td>\n",
              "      <td>80.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>68.995967</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>77.904148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>57</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>56</td>\n",
              "      <td>77.182891</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.380394</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0.01470</td>\n",
              "      <td>20.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>24.200000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>29.10</td>\n",
              "      <td>78.050840</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.89</td>\n",
              "      <td>36.191168</td>\n",
              "      <td>80.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>88.609229</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>0.00135</td>\n",
              "      <td>26.4</td>\n",
              "      <td>81.2</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>9.62</td>\n",
              "      <td>78.519287</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>38.121379</td>\n",
              "      <td>80.0</td>\n",
              "      <td>45.80</td>\n",
              "      <td>85.545193</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84.828488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>5</td>\n",
              "      <td>64.511617</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>17</td>\n",
              "      <td>19.584071</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.238652</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00678</td>\n",
              "      <td>56.7</td>\n",
              "      <td>72.2</td>\n",
              "      <td>4.740000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>19.00</td>\n",
              "      <td>29.949170</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.47</td>\n",
              "      <td>49.622492</td>\n",
              "      <td>80.0</td>\n",
              "      <td>37.4</td>\n",
              "      <td>74.391152</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.08220</td>\n",
              "      <td>39.0</td>\n",
              "      <td>83.5</td>\n",
              "      <td>1.370000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>13.00</td>\n",
              "      <td>53.451989</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.40</td>\n",
              "      <td>63.635296</td>\n",
              "      <td>20.0</td>\n",
              "      <td>89.20</td>\n",
              "      <td>72.127037</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28.819487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>38</td>\n",
              "      <td>86.902445</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>44</td>\n",
              "      <td>64.873156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.767862</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97000</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>17.80</td>\n",
              "      <td>65.756693</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>55.692952</td>\n",
              "      <td>80.0</td>\n",
              "      <td>48.6</td>\n",
              "      <td>77.469703</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20000</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>13.60</td>\n",
              "      <td>24.095041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>44.692703</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>68.040600</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.166768</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 521 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  ...  label_albums_reviewed\n",
              "0              25  ...               7.426104\n",
              "1              69  ...              18.382800\n",
              "2              44  ...              54.938572\n",
              "3              43  ...              74.635081\n",
              "4              60  ...               7.426104\n",
              "...           ...  ...                    ...\n",
              "16437          31  ...              92.169444\n",
              "16438          56  ...              77.904148\n",
              "16439          57  ...              84.828488\n",
              "16440           5  ...              28.819487\n",
              "16441          38  ...              99.166768\n",
              "\n",
              "[16442 rows x 521 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "zeDRIh4dSTEl",
        "outputId": "8e3e62f3-cca1-4498-e84b-1a83edd800a9"
      },
      "source": [
        "# 3 buckets log reg \n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-196-022cbd00647e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3 buckets log reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct_scaled_big\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe_real_one\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tripartite_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             w0, n_iter_i = _newton_cg(hess, func, grad, w0, args=args,\n\u001b[0;32m--> 945\u001b[0;31m                                       maxiter=max_iter, tol=tol)\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_newton_cg\u001b[0;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Inner loop: solve the Newton update by conjugate gradient, to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# avoid inverting the Hessian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mxsupi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfhess_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtermcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0malphak\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_cg\u001b[0;34m(fhess_p, fgrad, maxiter, tol)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mAp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfhess_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m# check curvature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mcurv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mhessp\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# r_yhat holds the result of applying the R-operator on the multinomial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# estimator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minter_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mr_yhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ5PzbKmSXdR",
        "outputId": "f3779258-7a98-4122-f768-932989482659"
      },
      "source": [
        "# 3 buckets ridge classifier \n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "real_predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4286061785453661"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdvwWt4j6WVy"
      },
      "source": [
        "classification_dict['large_pct_scaled_ridge'] = classification_report(y_test, real_predictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk5G1Na6SeJb",
        "outputId": "faf766a0-0681-42ee-c47b-108ff39323dc"
      },
      "source": [
        "# 3 buckets passive aggressive \n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34687423984432014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LNVbbaMSiSq",
        "outputId": "68d51a10-88e9-4f4d-c8de-1f3e0d8afd6d"
      },
      "source": [
        "# 3 buckets perceptron \n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39528095353928483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnzG9A9lSloW",
        "outputId": "7052f10e-e368-43e8-a054-5a210bf5c06d"
      },
      "source": [
        "# 3 buckets bernoulli \n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39747020189734855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRi1zN2OSqMo",
        "outputId": "a8d30f2d-b87c-4ca3-d4b3-76f4304b942a"
      },
      "source": [
        "# 3 buckets gaussian \n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36682072488445633"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK8Z1MZqd6Y0"
      },
      "source": [
        "**OPTIMIZING RIDGE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw4qFdYZd9sV",
        "outputId": "9aa132d9-55f5-4a7f-f3dd-e6bf7bfd23cc"
      },
      "source": [
        "# TRANSFORMING TO 500 FEATURES: 3 buckets ICA ridge classifier\n",
        "transformer = FastICA(n_components=500, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(pct_scaled_big)\n",
        "X_transformed_train_85, X_transformed_test_85, y_train_85, y_test_85 = train_test_split(X_transformed55, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = RidgeClassifier().fit(X_transformed_train_85, y_train_85)\n",
        "predictions_85 = clf.predict(X_transformed_test_85)\n",
        "num_score = clf.score(X_transformed_test_85, y_test_85)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43444417416686937"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oicpF6IhCEL",
        "outputId": "44750c64-a9f4-4d3d-c0d5-1cfa1e730088"
      },
      "source": [
        "# TRANSFORMING TO 400 FEATURES: 3 buckets ICA ridge classifier\n",
        "transformer = FastICA(n_components=400, random_state=0)\n",
        "X_transformed400r = transformer.fit_transform(pct_scaled_big)\n",
        "X_transformed_train_400r, X_transformed_test_400r, y_train_400r, y_test_400r = train_test_split(X_transformed400r, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = RidgeClassifier().fit(X_transformed_train_400r, y_train_400r)\n",
        "predictions_400r = clf.predict(X_transformed_test_400r)\n",
        "num_score = clf.score(X_transformed_test_400r, y_test_400r)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4359036730722452"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "558iPCBChw6F",
        "outputId": "db86f258-73b6-4b3a-8280-d7fdcc26da04"
      },
      "source": [
        "# TRANSFORMING TO 350 FEATURES: 3 buckets ICA ridge classifier\n",
        "transformer = FastICA(n_components=350, random_state=0)\n",
        "X_transformed350r = transformer.fit_transform(pct_scaled_big)\n",
        "X_transformed_train_350r, X_transformed_test_350r, y_train_350r, y_test_350r = train_test_split(X_transformed350r, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = RidgeClassifier().fit(X_transformed_train_350r, y_train_350r)\n",
        "predictions_350r = clf.predict(X_transformed_test_350r)\n",
        "num_score = clf.score(X_transformed_test_350r, y_test_350r)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44028216978837265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDXMf9QPjggG",
        "outputId": "564c626a-cb31-49a6-9314-35d9af785814"
      },
      "source": [
        "# TRANSFORMING TO 375 FEATURES: 3 buckets ICA ridge classifier\n",
        "transformer = FastICA(n_components=375, random_state=0)\n",
        "X_transformed375r = transformer.fit_transform(pct_scaled_big)\n",
        "X_transformed_train_375r, X_transformed_test_375r, y_train_375r, y_test_375r = train_test_split(X_transformed375r, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = RidgeClassifier().fit(X_transformed_train_375r, y_train_375r)\n",
        "predictions_375r = clf.predict(X_transformed_test_375r)\n",
        "num_score = clf.score(X_transformed_test_375r, y_test_375r)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44247141814643637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlwwSooLxATA",
        "outputId": "fd7d184d-85c2-47db-e49f-d865fd4c8cf6"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets PCA logreg\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4429579177815617"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0jZIvp2yz4Q",
        "outputId": "e78e1f59-b8da-4d3e-9166-7c97119f97df"
      },
      "source": [
        "# TRANSFORMING TO 500 FEATURES: genius 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=400).fit_transform(pct_scaled_big, the_real_one['tripartite_score'])\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4337144247141815"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RZTatenUl_z"
      },
      "source": [
        "**OPTIMIZING BERNOULLI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukGxW0UJUrJ5",
        "outputId": "4937bea0-a496-401c-ae67-7f366a1c5dc3"
      },
      "source": [
        "# TRANSFORMING TO 500 FEATURES: 3 buckets ICA ridge classifier\n",
        "transformer = FastICA(n_components=500, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(pct_scaled_big)\n",
        "X_transformed_train_85, X_transformed_test_85, y_train_85, y_test_85 = train_test_split(X_transformed55, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = BernoulliNB(alpha=2).fit(X_transformed_train_85, y_train_85)\n",
        "predictions_85 = clf.predict(X_transformed_test_85)\n",
        "num_score = clf.score(X_transformed_test_85, y_test_85)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37411821941133544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwOBJaUmVPM2",
        "outputId": "8558d830-7234-4fe4-fe37-c67b169c8d64"
      },
      "source": [
        "# TRANSFORMING TO 400 FEATURES: 3 buckets ICA ridge classifier\n",
        "transformer = FastICA(n_components=400, random_state=0)\n",
        "X_transformed400 = transformer.fit_transform(pct_scaled_big)\n",
        "X_transformed_train_400, X_transformed_test_400, y_train_400, y_test_400 = train_test_split(X_transformed400, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = BernoulliNB(alpha=2).fit(X_transformed_train_400, y_train_400)\n",
        "predictions_85 = clf.predict(X_transformed_test_400)\n",
        "num_score = clf.score(X_transformed_test_400, y_test_400)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37533446849914864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw6PmxQ0XR9l",
        "outputId": "fa6e8705-85db-4331-8e10-6d6efac5266b"
      },
      "source": [
        "# TRANSFORMING TO 325 FEATURES: 3 buckets ICA ridge classifier\n",
        "#transformer = FastICA(n_components=325, random_state=0)\n",
        "#X_transformed = transformer.fit_transform(pct_scaled_big)\n",
        "X_transformed_train_325, X_transformed_test_325, y_train_325, y_test_325 = train_test_split(X_transformed400, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = BernoulliNB(alpha=2).fit(X_transformed_train_325, y_train_325)\n",
        "predictions_85 = clf.predict(X_transformed_test_325)\n",
        "num_score = clf.score(X_transformed_test_325, y_test_325)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38214546339090244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-8AF8YJX4l7",
        "outputId": "3bcdb80c-17c7-4da8-fcb1-88275835525e"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets PCA logreg\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = BernoulliNB(alpha=2).fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4181464363901727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLEdcGlcFiu-"
      },
      "source": [
        "# THE REAL ONE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "81YFg0UCGDhD",
        "outputId": "8ca9e338-8ee9-4702-f24c-daea53b1d613"
      },
      "source": [
        "real = pd.read_csv('THE_REAL_ONE.csv')\n",
        "real = real.drop(['score', 'pitchfork_id', 'rounded_score'], axis=1)\n",
        "real"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>album_duration_minutes</th>\n",
              "      <th>year</th>\n",
              "      <th>min_loudness</th>\n",
              "      <th>max_loudness</th>\n",
              "      <th>mean_loudness</th>\n",
              "      <th>stddev_loudness</th>\n",
              "      <th>label_frequency</th>\n",
              "      <th>mean_duration</th>\n",
              "      <th>min_valence</th>\n",
              "      <th>max_valence</th>\n",
              "      <th>stddev_valence</th>\n",
              "      <th>mean_valence</th>\n",
              "      <th>weighted_avg_valence</th>\n",
              "      <th>weighted_avg_speechiness</th>\n",
              "      <th>med_liveness</th>\n",
              "      <th>stddev_liveness</th>\n",
              "      <th>stddev_instrumentalness</th>\n",
              "      <th>weighted_avg_instrumentalness</th>\n",
              "      <th>explicit</th>\n",
              "      <th>weighted_avg_energy</th>\n",
              "      <th>min_danceability</th>\n",
              "      <th>max_danceability</th>\n",
              "      <th>mean_danceability</th>\n",
              "      <th>stddev_danceability</th>\n",
              "      <th>mean_acousticness</th>\n",
              "      <th>stddev_acousticness</th>\n",
              "      <th>med_acousticness</th>\n",
              "      <th>min_popularity</th>\n",
              "      <th>max_popularity</th>\n",
              "      <th>mean_popularity</th>\n",
              "      <th>stddev_popularity</th>\n",
              "      <th>key_0_pct</th>\n",
              "      <th>key_1_pct</th>\n",
              "      <th>key_2_pct</th>\n",
              "      <th>key_3_pct</th>\n",
              "      <th>key_4_pct</th>\n",
              "      <th>key_5_pct</th>\n",
              "      <th>key_6_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>sig_5_pct</th>\n",
              "      <th>num_artists</th>\n",
              "      <th>num_features</th>\n",
              "      <th>artist_popularity_mean</th>\n",
              "      <th>artist_followers_mean</th>\n",
              "      <th>artist_popularity_min</th>\n",
              "      <th>artist_popularity_max</th>\n",
              "      <th>artist_followers_min</th>\n",
              "      <th>artist_followers_max</th>\n",
              "      <th>artist_popularity_stddev</th>\n",
              "      <th>artist_followers_stddev</th>\n",
              "      <th>mean_feat_artist_popularity</th>\n",
              "      <th>mean_feat_artist_followers</th>\n",
              "      <th>min_feat_artist_popularity</th>\n",
              "      <th>min_feat_artist_followers</th>\n",
              "      <th>max_feat_artist_popularity</th>\n",
              "      <th>max_feat_artist_followers</th>\n",
              "      <th>stddev_feat_artist_popularity</th>\n",
              "      <th>stddev_feat_artist_followers</th>\n",
              "      <th>genre_0_pct</th>\n",
              "      <th>genre_1_pct</th>\n",
              "      <th>genre_2_pct</th>\n",
              "      <th>genre_3_pct</th>\n",
              "      <th>genre_4_pct</th>\n",
              "      <th>genre_5_pct</th>\n",
              "      <th>genre_6_pct</th>\n",
              "      <th>genre_7_pct</th>\n",
              "      <th>genre_8_pct</th>\n",
              "      <th>genre_9_pct</th>\n",
              "      <th>genre_10_pct</th>\n",
              "      <th>genre_11_pct</th>\n",
              "      <th>genre_12_pct</th>\n",
              "      <th>genre_13_pct</th>\n",
              "      <th>genre_14_pct</th>\n",
              "      <th>genre_15_pct</th>\n",
              "      <th>genre_16_pct</th>\n",
              "      <th>genre_17_pct</th>\n",
              "      <th>genre_18_pct</th>\n",
              "      <th>genre_19_pct</th>\n",
              "      <th>genre_20_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "      <td>37.699950</td>\n",
              "      <td>2021</td>\n",
              "      <td>8.695784</td>\n",
              "      <td>77.746616</td>\n",
              "      <td>71.966860</td>\n",
              "      <td>2.468588</td>\n",
              "      <td>1</td>\n",
              "      <td>3.769995</td>\n",
              "      <td>52.09</td>\n",
              "      <td>55.6</td>\n",
              "      <td>15.025998</td>\n",
              "      <td>18.476000</td>\n",
              "      <td>16.069549</td>\n",
              "      <td>3.524631</td>\n",
              "      <td>9.575</td>\n",
              "      <td>5.812945</td>\n",
              "      <td>30.604008</td>\n",
              "      <td>22.075199</td>\n",
              "      <td>0</td>\n",
              "      <td>22.089854</td>\n",
              "      <td>39.40</td>\n",
              "      <td>63.3</td>\n",
              "      <td>45.330000</td>\n",
              "      <td>10.642582</td>\n",
              "      <td>76.730000</td>\n",
              "      <td>76.730000</td>\n",
              "      <td>81.6500</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>12.800000</td>\n",
              "      <td>2.699794</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18.0</td>\n",
              "      <td>538.0</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>538</td>\n",
              "      <td>538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.776000e+03</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1776.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1776.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>17</td>\n",
              "      <td>53.442883</td>\n",
              "      <td>2021</td>\n",
              "      <td>5.087701</td>\n",
              "      <td>81.197035</td>\n",
              "      <td>78.453161</td>\n",
              "      <td>1.668215</td>\n",
              "      <td>2</td>\n",
              "      <td>3.143699</td>\n",
              "      <td>75.31</td>\n",
              "      <td>82.5</td>\n",
              "      <td>20.156995</td>\n",
              "      <td>43.517059</td>\n",
              "      <td>43.974797</td>\n",
              "      <td>26.145333</td>\n",
              "      <td>11.200</td>\n",
              "      <td>10.004012</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.000364</td>\n",
              "      <td>1</td>\n",
              "      <td>55.135105</td>\n",
              "      <td>45.40</td>\n",
              "      <td>87.3</td>\n",
              "      <td>75.317647</td>\n",
              "      <td>12.166976</td>\n",
              "      <td>12.456412</td>\n",
              "      <td>12.456412</td>\n",
              "      <td>6.9500</td>\n",
              "      <td>33</td>\n",
              "      <td>72</td>\n",
              "      <td>40.941176</td>\n",
              "      <td>8.989373</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>41.176471</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>69.0</td>\n",
              "      <td>161226.0</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>161226</td>\n",
              "      <td>161226</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.230769</td>\n",
              "      <td>4.329135e+06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>54616704.0</td>\n",
              "      <td>20.753128</td>\n",
              "      <td>1.511468e+07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.117647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>52</td>\n",
              "      <td>215.010783</td>\n",
              "      <td>2021</td>\n",
              "      <td>27.651865</td>\n",
              "      <td>77.851220</td>\n",
              "      <td>67.206191</td>\n",
              "      <td>7.829765</td>\n",
              "      <td>21</td>\n",
              "      <td>4.300216</td>\n",
              "      <td>83.92</td>\n",
              "      <td>87.1</td>\n",
              "      <td>21.225589</td>\n",
              "      <td>29.830000</td>\n",
              "      <td>28.973155</td>\n",
              "      <td>9.620623</td>\n",
              "      <td>11.250</td>\n",
              "      <td>13.873995</td>\n",
              "      <td>32.165156</td>\n",
              "      <td>68.565822</td>\n",
              "      <td>0</td>\n",
              "      <td>31.134999</td>\n",
              "      <td>72.37</td>\n",
              "      <td>81.6</td>\n",
              "      <td>44.774600</td>\n",
              "      <td>19.179167</td>\n",
              "      <td>84.409600</td>\n",
              "      <td>84.409600</td>\n",
              "      <td>93.0000</td>\n",
              "      <td>13</td>\n",
              "      <td>34</td>\n",
              "      <td>18.960000</td>\n",
              "      <td>4.936164</td>\n",
              "      <td>13.461538</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>...</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>50.0</td>\n",
              "      <td>16453.0</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>16453</td>\n",
              "      <td>16453</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>2.673500e+03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>849.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>4498.0</td>\n",
              "      <td>11.313708</td>\n",
              "      <td>2.580233e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>9.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>40.477500</td>\n",
              "      <td>2021</td>\n",
              "      <td>5.084669</td>\n",
              "      <td>79.579461</td>\n",
              "      <td>76.552764</td>\n",
              "      <td>1.577898</td>\n",
              "      <td>64</td>\n",
              "      <td>3.373125</td>\n",
              "      <td>73.80</td>\n",
              "      <td>96.7</td>\n",
              "      <td>23.668895</td>\n",
              "      <td>72.475000</td>\n",
              "      <td>74.175735</td>\n",
              "      <td>6.567317</td>\n",
              "      <td>9.125</td>\n",
              "      <td>13.549375</td>\n",
              "      <td>24.003436</td>\n",
              "      <td>18.619665</td>\n",
              "      <td>0</td>\n",
              "      <td>61.188227</td>\n",
              "      <td>51.50</td>\n",
              "      <td>87.9</td>\n",
              "      <td>69.800000</td>\n",
              "      <td>16.594961</td>\n",
              "      <td>28.157500</td>\n",
              "      <td>28.157500</td>\n",
              "      <td>16.4000</td>\n",
              "      <td>24</td>\n",
              "      <td>36</td>\n",
              "      <td>28.583333</td>\n",
              "      <td>3.824760</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>135966.0</td>\n",
              "      <td>57</td>\n",
              "      <td>57</td>\n",
              "      <td>135966</td>\n",
              "      <td>135966</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>41.823017</td>\n",
              "      <td>2020</td>\n",
              "      <td>16.084775</td>\n",
              "      <td>81.914103</td>\n",
              "      <td>78.010248</td>\n",
              "      <td>4.848596</td>\n",
              "      <td>1</td>\n",
              "      <td>4.182302</td>\n",
              "      <td>71.90</td>\n",
              "      <td>90.5</td>\n",
              "      <td>28.487900</td>\n",
              "      <td>58.760000</td>\n",
              "      <td>59.015377</td>\n",
              "      <td>6.562235</td>\n",
              "      <td>32.850</td>\n",
              "      <td>17.877847</td>\n",
              "      <td>33.922389</td>\n",
              "      <td>31.894178</td>\n",
              "      <td>1</td>\n",
              "      <td>74.673965</td>\n",
              "      <td>28.00</td>\n",
              "      <td>65.5</td>\n",
              "      <td>54.750000</td>\n",
              "      <td>9.336577</td>\n",
              "      <td>9.097215</td>\n",
              "      <td>9.097215</td>\n",
              "      <td>4.4200</td>\n",
              "      <td>41</td>\n",
              "      <td>53</td>\n",
              "      <td>46.500000</td>\n",
              "      <td>4.169999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>647390.0</td>\n",
              "      <td>68</td>\n",
              "      <td>68</td>\n",
              "      <td>647390</td>\n",
              "      <td>647390</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>30.473300</td>\n",
              "      <td>1999</td>\n",
              "      <td>7.487531</td>\n",
              "      <td>75.086033</td>\n",
              "      <td>71.995339</td>\n",
              "      <td>2.927091</td>\n",
              "      <td>204</td>\n",
              "      <td>4.353329</td>\n",
              "      <td>69.50</td>\n",
              "      <td>76.3</td>\n",
              "      <td>24.618199</td>\n",
              "      <td>41.728571</td>\n",
              "      <td>42.058227</td>\n",
              "      <td>6.142869</td>\n",
              "      <td>12.600</td>\n",
              "      <td>7.080754</td>\n",
              "      <td>30.172104</td>\n",
              "      <td>73.998741</td>\n",
              "      <td>0</td>\n",
              "      <td>70.294207</td>\n",
              "      <td>27.20</td>\n",
              "      <td>58.2</td>\n",
              "      <td>43.728571</td>\n",
              "      <td>9.774067</td>\n",
              "      <td>22.448286</td>\n",
              "      <td>22.448286</td>\n",
              "      <td>3.6000</td>\n",
              "      <td>8</td>\n",
              "      <td>35</td>\n",
              "      <td>12.571429</td>\n",
              "      <td>9.947481</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.857143</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>159367.0</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>159367</td>\n",
              "      <td>159367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>56</td>\n",
              "      <td>17</td>\n",
              "      <td>60.331483</td>\n",
              "      <td>1999</td>\n",
              "      <td>85.660143</td>\n",
              "      <td>85.660143</td>\n",
              "      <td>75.658814</td>\n",
              "      <td>19.957987</td>\n",
              "      <td>71</td>\n",
              "      <td>3.548911</td>\n",
              "      <td>83.90</td>\n",
              "      <td>83.9</td>\n",
              "      <td>24.398101</td>\n",
              "      <td>43.188235</td>\n",
              "      <td>46.731975</td>\n",
              "      <td>3.583291</td>\n",
              "      <td>10.700</td>\n",
              "      <td>11.592671</td>\n",
              "      <td>15.440686</td>\n",
              "      <td>6.035377</td>\n",
              "      <td>0</td>\n",
              "      <td>64.086232</td>\n",
              "      <td>69.20</td>\n",
              "      <td>69.2</td>\n",
              "      <td>47.223529</td>\n",
              "      <td>16.006777</td>\n",
              "      <td>23.552353</td>\n",
              "      <td>23.552353</td>\n",
              "      <td>7.0800</td>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>32.294118</td>\n",
              "      <td>10.941690</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>35.294118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>587819.0</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>587819</td>\n",
              "      <td>587819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>17.647059</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.411765</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>46.941517</td>\n",
              "      <td>1999</td>\n",
              "      <td>2.516562</td>\n",
              "      <td>82.393160</td>\n",
              "      <td>81.402908</td>\n",
              "      <td>0.907825</td>\n",
              "      <td>103</td>\n",
              "      <td>4.694152</td>\n",
              "      <td>72.40</td>\n",
              "      <td>93.3</td>\n",
              "      <td>20.468502</td>\n",
              "      <td>52.920000</td>\n",
              "      <td>50.707482</td>\n",
              "      <td>3.270570</td>\n",
              "      <td>18.100</td>\n",
              "      <td>8.463656</td>\n",
              "      <td>29.561014</td>\n",
              "      <td>40.199373</td>\n",
              "      <td>0</td>\n",
              "      <td>76.314037</td>\n",
              "      <td>32.60</td>\n",
              "      <td>50.6</td>\n",
              "      <td>32.270000</td>\n",
              "      <td>10.564095</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.0163</td>\n",
              "      <td>34</td>\n",
              "      <td>57</td>\n",
              "      <td>40.600000</td>\n",
              "      <td>6.736303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>215321.0</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>215321</td>\n",
              "      <td>215321</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>44.758833</td>\n",
              "      <td>1999</td>\n",
              "      <td>5.199885</td>\n",
              "      <td>79.112533</td>\n",
              "      <td>76.730010</td>\n",
              "      <td>1.729905</td>\n",
              "      <td>4</td>\n",
              "      <td>3.729903</td>\n",
              "      <td>67.50</td>\n",
              "      <td>97.2</td>\n",
              "      <td>24.716151</td>\n",
              "      <td>57.091667</td>\n",
              "      <td>55.815206</td>\n",
              "      <td>5.762615</td>\n",
              "      <td>20.800</td>\n",
              "      <td>14.893113</td>\n",
              "      <td>36.689485</td>\n",
              "      <td>28.698280</td>\n",
              "      <td>0</td>\n",
              "      <td>73.804939</td>\n",
              "      <td>43.10</td>\n",
              "      <td>60.4</td>\n",
              "      <td>44.516667</td>\n",
              "      <td>12.546411</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.0525</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.984732</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2489.0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>2489</td>\n",
              "      <td>2489</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>38</td>\n",
              "      <td>15</td>\n",
              "      <td>48.525733</td>\n",
              "      <td>1999</td>\n",
              "      <td>7.299547</td>\n",
              "      <td>80.878674</td>\n",
              "      <td>78.544538</td>\n",
              "      <td>1.980301</td>\n",
              "      <td>275</td>\n",
              "      <td>3.235049</td>\n",
              "      <td>78.16</td>\n",
              "      <td>85.7</td>\n",
              "      <td>20.413301</td>\n",
              "      <td>40.322667</td>\n",
              "      <td>39.695422</td>\n",
              "      <td>4.885491</td>\n",
              "      <td>10.800</td>\n",
              "      <td>4.095428</td>\n",
              "      <td>24.524718</td>\n",
              "      <td>8.230068</td>\n",
              "      <td>0</td>\n",
              "      <td>75.332988</td>\n",
              "      <td>32.70</td>\n",
              "      <td>56.2</td>\n",
              "      <td>39.920000</td>\n",
              "      <td>7.972381</td>\n",
              "      <td>3.075563</td>\n",
              "      <td>3.075563</td>\n",
              "      <td>0.1380</td>\n",
              "      <td>10</td>\n",
              "      <td>41</td>\n",
              "      <td>15.466667</td>\n",
              "      <td>7.670599</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>81574.0</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>81574</td>\n",
              "      <td>81574</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 90 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  total_tracks  ...  genre_19_pct  genre_20_pct\n",
              "0              25            10  ...     10.000000      0.000000\n",
              "1              69            17  ...      0.000000      0.000000\n",
              "2              44            52  ...      1.923077      9.615385\n",
              "3              43            12  ...      0.000000      0.000000\n",
              "4              60            10  ...      0.000000      0.000000\n",
              "...           ...           ...  ...           ...           ...\n",
              "16437          31             7  ...     14.285714      0.000000\n",
              "16438          56            17  ...     11.764706      0.000000\n",
              "16439          57            10  ...      0.000000      0.000000\n",
              "16440           5            12  ...      0.000000      0.000000\n",
              "16441          38            15  ...      0.000000      0.000000\n",
              "\n",
              "[16442 rows x 90 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ds3iYt-GLR5",
        "outputId": "1bbce793-12b9-45dc-aa6e-4ba133c4efba"
      },
      "source": [
        "# 3 buckets log reg \n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44003891997081"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9WfHygs82M_"
      },
      "source": [
        "logregpredictions = predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "OF3UulLZ8DJe",
        "outputId": "ce0ac296-e373-4b8e-f57e-b9eb2b1b0341"
      },
      "source": [
        "multiclassROC(y_test, clf.decision_function(X_test), 3, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-327-be91a888423b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmulticlassROC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-325-9b95e0dbeb4e>\u001b[0m in \u001b[0;36mmulticlassROC\u001b[0;34m(Y_test, Y_score, n_classes, plot)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0maverage_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i],\n\u001b[0m\u001b[1;32m      8\u001b[0m                                                         y_score[:, i])\n\u001b[1;32m      9\u001b[0m     \u001b[0maverage_precision\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    919\u001b[0m             )\n\u001b[1;32m    920\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"key of type tuple not found and not a MultiIndex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;31m# If key is contained, would have returned by now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'key of type tuple not found and not a MultiIndex'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLU4UoHU7lEn"
      },
      "source": [
        "probs = clf.predict_proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pggG1LO-7VIA"
      },
      "source": [
        "metrics.roc_curve(y_test, probs, pos_label=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYl0y6G-6k6v"
      },
      "source": [
        "classification_dict['original_logreg'] = classification_report(y_test, logregpredictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjH8W2bWGOyH",
        "outputId": "4a801f92-1947-49f9-a962-b0998b7d11a6"
      },
      "source": [
        "# 3 buckets ridge classifier \n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "real_predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.44971e-19): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46144490391632204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HVW6FlG9IKZ"
      },
      "source": [
        "classification_dict['original_ridge'] = classification_report(y_test, real_predictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "kQVym7QxGmmg",
        "outputId": "abf0064d-03d9-49ff-fb83-eb90bac83558"
      },
      "source": [
        "confusion_matrix_metric(y_test, predictions, ['0', '1', '2'], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[661 427 368]\n",
            " [467 571 364]\n",
            " [354 346 553]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuGPBwDUGn__",
        "outputId": "ac9dfd0e-f845-4eae-8bac-ffd173ae6671"
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.45      0.45      1456\n",
            "           1       0.42      0.41      0.42      1402\n",
            "           2       0.43      0.44      0.44      1253\n",
            "\n",
            "    accuracy                           0.43      4111\n",
            "   macro avg       0.43      0.43      0.43      4111\n",
            "weighted avg       0.43      0.43      0.43      4111\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np7XtFTLGQj-",
        "outputId": "0dcf78e9-0fb0-45ad-ec40-ce8bf67eb13d"
      },
      "source": [
        "# 3 buckets passive aggressive \n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33957674531744103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmtrhc_LGSuh",
        "outputId": "893a1f57-e705-4d31-84e8-ff9be930ace8"
      },
      "source": [
        "# 3 buckets perceptron \n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3410362442228168"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36SPXsFTGTto",
        "outputId": "cf191de4-f749-42c5-8b8b-d527f4559f15"
      },
      "source": [
        "# 3 buckets bernoulli \n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB(alpha=2)\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3758209681342739"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrxGX6yfGVx8",
        "outputId": "a4c899b7-eb85-4d24-d7ca-9543ea0a2598"
      },
      "source": [
        "# 3 buckets gaussian \n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31598151301386523"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWGD92J6mrVb",
        "outputId": "79c5a433-e90f-4c3f-a47b-00db090ef9e0"
      },
      "source": [
        "# 3 buckets perceptron \n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31865726100705427"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbFvmIoMmut2",
        "outputId": "9daadb83-ea3c-449a-e5c4-c3ca52dc8142"
      },
      "source": [
        "# 3 buckets bernoulli \n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB(alpha=2)\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3799562150328387"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK2Yx1gDmwuY",
        "outputId": "d5c1240d-11bd-47a8-b758-0c68e4e226be"
      },
      "source": [
        "# 3 buckets gaussian \n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4254439309170518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4LXwZtMHMP7"
      },
      "source": [
        "**OPTIMIZING RIDGE WITH ICA, PCAM KBEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9HYbsk_HRkY",
        "outputId": "4f9c78fd-966f-43a0-8ec2-1ba4b98590d3"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets ICA ridge classifier\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(real)\n",
        "X_transformed_train_85, X_transformed_test_85, y_train_85, y_test_85 = train_test_split(X_transformed55, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = RidgeClassifier().fit(X_transformed_train_85, y_train_85)\n",
        "predictions_85 = clf.predict(X_transformed_test_85)\n",
        "num_score = clf.score(X_transformed_test_85, y_test_85)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46266115300413524"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl22Uf1xIRNt",
        "outputId": "742e9e73-fdc5-45ea-8dff-400601c95e60"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets PCA ridge classifier \n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=85)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46144490391632204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdoB9uJrMmyb"
      },
      "source": [
        "**OPTIMIZING LOGREG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEiKfieWMqQ-",
        "outputId": "377bca56-02ad-48e4-c840-a7b0102da72d"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets ICA logreg\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed55, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions_85 = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4519581610313792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWXrBjCMOAg3",
        "outputId": "fc37b077-c038-4662-bbbb-15c7e905a9d2"
      },
      "source": [
        "# TRANSFORMING TO 90 FEATURES: the real one 3 buckets ICA logreg\n",
        "transformer = FastICA(n_components=90, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed55, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions_85 = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45463390902456824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4pJ0COtOi_t",
        "outputId": "eef16d5f-8ec2-4ff0-d84c-e0eb39b67711"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets PCA logreg\n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=85)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-175-4e0c175f4b6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             w0, n_iter_i = _newton_cg(hess, func, grad, w0, args=args,\n\u001b[0;32m--> 945\u001b[0;31m                                       maxiter=max_iter, tol=tol)\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_newton_cg\u001b[0;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0malphak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     _line_search_wolfe12(func, grad, xk, xsupi, fgrad,\n\u001b[0;32m--> 202\u001b[0;31m                                          old_fval, old_old_fval, args=args)\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Line Search failed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[1;32m     42\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[1;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'FG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mderphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mphi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mhess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multinomial_grad_hess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msquared_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/special/_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# suppress warnings about log of zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_sign\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0msgn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2242\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[1;32m     72\u001b[0m                   if v is not np._NoValue}\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "Zg6h4GmnRF2L",
        "outputId": "b72323fa-ba3e-412a-e5b6-8dc88014696e"
      },
      "source": [
        "confusion_matrix_metric(y_test, predictions, ['0', '1', '2'], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[688 441 327]\n",
            " [461 603 338]\n",
            " [315 340 598]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcu4qxA0RMDx",
        "outputId": "04fb9c3c-b8c5-48b9-b144-5ef5320c2127"
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.47      0.47      1456\n",
            "           1       0.44      0.43      0.43      1402\n",
            "           2       0.47      0.48      0.48      1253\n",
            "\n",
            "    accuracy                           0.46      4111\n",
            "   macro avg       0.46      0.46      0.46      4111\n",
            "weighted avg       0.46      0.46      0.46      4111\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIzcUso8RSYO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KGTmaE_KPkf"
      },
      "source": [
        "**OPTIMIZING BERNOULLI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UrhcfLFKO0G",
        "outputId": "b9863da7-457a-458e-8776-856967ffdf03"
      },
      "source": [
        "# TRANSFORMING TO 500 FEATURES: bernoulli ica \n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed500b = transformer.fit_transform(real)\n",
        "X_transformed_train_500b, X_transformed_test_500b, y_train_500b, y_test_500b = train_test_split(X_transformed500b, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "#clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "clf = BernoulliNB(alpha=2).fit(X_transformed_train_500b, y_train_500b)\n",
        "predictions_85 = clf.predict(X_transformed_test_500b)\n",
        "num_score = clf.score(X_transformed_test_500b, y_test_500b)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42325468255898807"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0YgVJQgKtcf",
        "outputId": "71258b30-d85d-4e7e-e64d-6868e3219b35"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets PCA ridge classifier \n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=85)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = BernoulliNB(alpha=2).fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42957917781561666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vBmhjmsFnuL"
      },
      "source": [
        "# THE REAL ONE SCALED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "uny3njLhfyL7",
        "outputId": "648d3f10-17bd-4c56-93d7-ebef653ce340"
      },
      "source": [
        "scaled = pd.read_csv('THE_REAL_ONE_SCALED.csv')\n",
        "scaled = scaled.drop('score', axis=1)\n",
        "scaled['album_duration_minutes'] *= 100\n",
        "scaled['year'] *= 100\n",
        "scaled['label_frequency'] *= 100\n",
        "scaled['mean_duration'] *= 100\n",
        "scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>album_duration_minutes</th>\n",
              "      <th>year</th>\n",
              "      <th>min_loudness</th>\n",
              "      <th>max_loudness</th>\n",
              "      <th>mean_loudness</th>\n",
              "      <th>stddev_loudness</th>\n",
              "      <th>label_frequency</th>\n",
              "      <th>mean_duration</th>\n",
              "      <th>min_valence</th>\n",
              "      <th>max_valence</th>\n",
              "      <th>stddev_valence</th>\n",
              "      <th>mean_valence</th>\n",
              "      <th>weighted_avg_valence</th>\n",
              "      <th>weighted_avg_speechiness</th>\n",
              "      <th>med_liveness</th>\n",
              "      <th>stddev_liveness</th>\n",
              "      <th>stddev_instrumentalness</th>\n",
              "      <th>weighted_avg_instrumentalness</th>\n",
              "      <th>explicit</th>\n",
              "      <th>weighted_avg_energy</th>\n",
              "      <th>min_danceability</th>\n",
              "      <th>max_danceability</th>\n",
              "      <th>mean_danceability</th>\n",
              "      <th>stddev_danceability</th>\n",
              "      <th>mean_acousticness</th>\n",
              "      <th>stddev_acousticness</th>\n",
              "      <th>med_acousticness</th>\n",
              "      <th>min_popularity</th>\n",
              "      <th>max_popularity</th>\n",
              "      <th>mean_popularity</th>\n",
              "      <th>stddev_popularity</th>\n",
              "      <th>key_0_pct</th>\n",
              "      <th>key_1_pct</th>\n",
              "      <th>key_2_pct</th>\n",
              "      <th>key_3_pct</th>\n",
              "      <th>key_4_pct</th>\n",
              "      <th>key_5_pct</th>\n",
              "      <th>key_6_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>artist_popularity_mean</th>\n",
              "      <th>artist_followers_mean</th>\n",
              "      <th>artist_popularity_min</th>\n",
              "      <th>artist_popularity_max</th>\n",
              "      <th>artist_followers_min</th>\n",
              "      <th>artist_followers_max</th>\n",
              "      <th>artist_popularity_stddev</th>\n",
              "      <th>artist_followers_stddev</th>\n",
              "      <th>mean_feat_artist_popularity</th>\n",
              "      <th>mean_feat_artist_followers</th>\n",
              "      <th>min_feat_artist_popularity</th>\n",
              "      <th>min_feat_artist_followers</th>\n",
              "      <th>max_feat_artist_popularity</th>\n",
              "      <th>max_feat_artist_followers</th>\n",
              "      <th>stddev_feat_artist_popularity</th>\n",
              "      <th>stddev_feat_artist_followers</th>\n",
              "      <th>genre_0_pct</th>\n",
              "      <th>genre_1_pct</th>\n",
              "      <th>genre_2_pct</th>\n",
              "      <th>genre_3_pct</th>\n",
              "      <th>genre_4_pct</th>\n",
              "      <th>genre_5_pct</th>\n",
              "      <th>genre_6_pct</th>\n",
              "      <th>genre_7_pct</th>\n",
              "      <th>genre_8_pct</th>\n",
              "      <th>genre_9_pct</th>\n",
              "      <th>genre_10_pct</th>\n",
              "      <th>genre_11_pct</th>\n",
              "      <th>genre_12_pct</th>\n",
              "      <th>genre_13_pct</th>\n",
              "      <th>genre_14_pct</th>\n",
              "      <th>genre_15_pct</th>\n",
              "      <th>genre_16_pct</th>\n",
              "      <th>genre_17_pct</th>\n",
              "      <th>genre_18_pct</th>\n",
              "      <th>genre_19_pct</th>\n",
              "      <th>genre_20_pct</th>\n",
              "      <th>rounded_score</th>\n",
              "      <th>sextile_score</th>\n",
              "      <th>tripartite_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>0.037383</td>\n",
              "      <td>5.044812</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>8.695784</td>\n",
              "      <td>77.746616</td>\n",
              "      <td>71.966860</td>\n",
              "      <td>2.468588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.787188</td>\n",
              "      <td>52.09</td>\n",
              "      <td>55.6</td>\n",
              "      <td>15.025998</td>\n",
              "      <td>18.476000</td>\n",
              "      <td>16.069549</td>\n",
              "      <td>3.524631</td>\n",
              "      <td>9.575</td>\n",
              "      <td>5.812945</td>\n",
              "      <td>30.604008</td>\n",
              "      <td>22.075199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.089854</td>\n",
              "      <td>39.40</td>\n",
              "      <td>63.3</td>\n",
              "      <td>45.330000</td>\n",
              "      <td>10.642582</td>\n",
              "      <td>76.730000</td>\n",
              "      <td>76.730000</td>\n",
              "      <td>81.6500</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>12.800000</td>\n",
              "      <td>2.699794</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.289716</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>6.289716</td>\n",
              "      <td>6.289716</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>7.482682</td>\n",
              "      <td>24.0</td>\n",
              "      <td>7.482682</td>\n",
              "      <td>24.0</td>\n",
              "      <td>7.482682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>0.070093</td>\n",
              "      <td>7.350411</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>5.087701</td>\n",
              "      <td>81.197035</td>\n",
              "      <td>78.453161</td>\n",
              "      <td>1.668215</td>\n",
              "      <td>0.364964</td>\n",
              "      <td>4.709538</td>\n",
              "      <td>75.31</td>\n",
              "      <td>82.5</td>\n",
              "      <td>20.156995</td>\n",
              "      <td>43.517059</td>\n",
              "      <td>43.974797</td>\n",
              "      <td>26.145333</td>\n",
              "      <td>11.200</td>\n",
              "      <td>10.004012</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.000364</td>\n",
              "      <td>100.0</td>\n",
              "      <td>55.135105</td>\n",
              "      <td>45.40</td>\n",
              "      <td>87.3</td>\n",
              "      <td>75.317647</td>\n",
              "      <td>12.166976</td>\n",
              "      <td>12.456412</td>\n",
              "      <td>12.456412</td>\n",
              "      <td>6.9500</td>\n",
              "      <td>33</td>\n",
              "      <td>72</td>\n",
              "      <td>40.941176</td>\n",
              "      <td>8.989373</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>41.176471</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>...</td>\n",
              "      <td>69.0</td>\n",
              "      <td>11.990569</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>11.990569</td>\n",
              "      <td>11.990569</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.230769</td>\n",
              "      <td>15.280879</td>\n",
              "      <td>25.0</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>99.0</td>\n",
              "      <td>17.815850</td>\n",
              "      <td>20.753128</td>\n",
              "      <td>2.863981</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.117647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>0.233645</td>\n",
              "      <td>31.012511</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27.651865</td>\n",
              "      <td>77.851220</td>\n",
              "      <td>67.206191</td>\n",
              "      <td>7.829765</td>\n",
              "      <td>7.299270</td>\n",
              "      <td>6.699524</td>\n",
              "      <td>83.92</td>\n",
              "      <td>87.1</td>\n",
              "      <td>21.225589</td>\n",
              "      <td>29.830000</td>\n",
              "      <td>28.973155</td>\n",
              "      <td>9.620623</td>\n",
              "      <td>11.250</td>\n",
              "      <td>13.873995</td>\n",
              "      <td>32.165156</td>\n",
              "      <td>68.565822</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.134999</td>\n",
              "      <td>72.37</td>\n",
              "      <td>81.6</td>\n",
              "      <td>44.774600</td>\n",
              "      <td>19.179167</td>\n",
              "      <td>84.409600</td>\n",
              "      <td>84.409600</td>\n",
              "      <td>93.0000</td>\n",
              "      <td>13</td>\n",
              "      <td>34</td>\n",
              "      <td>18.960000</td>\n",
              "      <td>4.936164</td>\n",
              "      <td>13.461538</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>...</td>\n",
              "      <td>50.0</td>\n",
              "      <td>9.708324</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>9.708324</td>\n",
              "      <td>9.708324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>7.891518</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6.745236</td>\n",
              "      <td>41.0</td>\n",
              "      <td>8.411610</td>\n",
              "      <td>11.313708</td>\n",
              "      <td>2.181098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>0.046729</td>\n",
              "      <td>5.451592</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>5.084669</td>\n",
              "      <td>79.579461</td>\n",
              "      <td>76.552764</td>\n",
              "      <td>1.577898</td>\n",
              "      <td>22.992701</td>\n",
              "      <td>5.104305</td>\n",
              "      <td>73.80</td>\n",
              "      <td>96.7</td>\n",
              "      <td>23.668895</td>\n",
              "      <td>72.475000</td>\n",
              "      <td>74.175735</td>\n",
              "      <td>6.567317</td>\n",
              "      <td>9.125</td>\n",
              "      <td>13.549375</td>\n",
              "      <td>24.003436</td>\n",
              "      <td>18.619665</td>\n",
              "      <td>0.0</td>\n",
              "      <td>61.188227</td>\n",
              "      <td>51.50</td>\n",
              "      <td>87.9</td>\n",
              "      <td>69.800000</td>\n",
              "      <td>16.594961</td>\n",
              "      <td>28.157500</td>\n",
              "      <td>28.157500</td>\n",
              "      <td>16.4000</td>\n",
              "      <td>24</td>\n",
              "      <td>36</td>\n",
              "      <td>28.583333</td>\n",
              "      <td>3.824760</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>57.0</td>\n",
              "      <td>11.820167</td>\n",
              "      <td>57</td>\n",
              "      <td>57</td>\n",
              "      <td>11.820167</td>\n",
              "      <td>11.820167</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>0.037383</td>\n",
              "      <td>5.648647</td>\n",
              "      <td>98.461538</td>\n",
              "      <td>16.084775</td>\n",
              "      <td>81.914103</td>\n",
              "      <td>78.010248</td>\n",
              "      <td>4.848596</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.496633</td>\n",
              "      <td>71.90</td>\n",
              "      <td>90.5</td>\n",
              "      <td>28.487900</td>\n",
              "      <td>58.760000</td>\n",
              "      <td>59.015377</td>\n",
              "      <td>6.562235</td>\n",
              "      <td>32.850</td>\n",
              "      <td>17.877847</td>\n",
              "      <td>33.922389</td>\n",
              "      <td>31.894178</td>\n",
              "      <td>100.0</td>\n",
              "      <td>74.673965</td>\n",
              "      <td>28.00</td>\n",
              "      <td>65.5</td>\n",
              "      <td>54.750000</td>\n",
              "      <td>9.336577</td>\n",
              "      <td>9.097215</td>\n",
              "      <td>9.097215</td>\n",
              "      <td>4.4200</td>\n",
              "      <td>41</td>\n",
              "      <td>53</td>\n",
              "      <td>46.500000</td>\n",
              "      <td>4.169999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>68.0</td>\n",
              "      <td>13.380706</td>\n",
              "      <td>68</td>\n",
              "      <td>68</td>\n",
              "      <td>13.380706</td>\n",
              "      <td>13.380706</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>31</td>\n",
              "      <td>0.023364</td>\n",
              "      <td>3.986448</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>7.487531</td>\n",
              "      <td>75.086033</td>\n",
              "      <td>71.995339</td>\n",
              "      <td>2.927091</td>\n",
              "      <td>74.087591</td>\n",
              "      <td>6.790914</td>\n",
              "      <td>69.50</td>\n",
              "      <td>76.3</td>\n",
              "      <td>24.618199</td>\n",
              "      <td>41.728571</td>\n",
              "      <td>42.058227</td>\n",
              "      <td>6.142869</td>\n",
              "      <td>12.600</td>\n",
              "      <td>7.080754</td>\n",
              "      <td>30.172104</td>\n",
              "      <td>73.998741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70.294207</td>\n",
              "      <td>27.20</td>\n",
              "      <td>58.2</td>\n",
              "      <td>43.728571</td>\n",
              "      <td>9.774067</td>\n",
              "      <td>22.448286</td>\n",
              "      <td>22.448286</td>\n",
              "      <td>3.6000</td>\n",
              "      <td>8</td>\n",
              "      <td>35</td>\n",
              "      <td>12.571429</td>\n",
              "      <td>9.947481</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.857143</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>...</td>\n",
              "      <td>50.0</td>\n",
              "      <td>11.978971</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>11.978971</td>\n",
              "      <td>11.978971</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>56</td>\n",
              "      <td>0.070093</td>\n",
              "      <td>8.359267</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>85.660143</td>\n",
              "      <td>85.660143</td>\n",
              "      <td>75.658814</td>\n",
              "      <td>19.957987</td>\n",
              "      <td>25.547445</td>\n",
              "      <td>5.406775</td>\n",
              "      <td>83.90</td>\n",
              "      <td>83.9</td>\n",
              "      <td>24.398101</td>\n",
              "      <td>43.188235</td>\n",
              "      <td>46.731975</td>\n",
              "      <td>3.583291</td>\n",
              "      <td>10.700</td>\n",
              "      <td>11.592671</td>\n",
              "      <td>15.440686</td>\n",
              "      <td>6.035377</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.086232</td>\n",
              "      <td>69.20</td>\n",
              "      <td>69.2</td>\n",
              "      <td>47.223529</td>\n",
              "      <td>16.006777</td>\n",
              "      <td>23.552353</td>\n",
              "      <td>23.552353</td>\n",
              "      <td>7.0800</td>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>32.294118</td>\n",
              "      <td>10.941690</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>35.294118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>67.0</td>\n",
              "      <td>13.284176</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>13.284176</td>\n",
              "      <td>13.284176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.647059</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.411765</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>57</td>\n",
              "      <td>0.037383</td>\n",
              "      <td>6.398267</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>2.516562</td>\n",
              "      <td>82.393160</td>\n",
              "      <td>81.402908</td>\n",
              "      <td>0.907825</td>\n",
              "      <td>37.226277</td>\n",
              "      <td>7.377359</td>\n",
              "      <td>72.40</td>\n",
              "      <td>93.3</td>\n",
              "      <td>20.468502</td>\n",
              "      <td>52.920000</td>\n",
              "      <td>50.707482</td>\n",
              "      <td>3.270570</td>\n",
              "      <td>18.100</td>\n",
              "      <td>8.463656</td>\n",
              "      <td>29.561014</td>\n",
              "      <td>40.199373</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.314037</td>\n",
              "      <td>32.60</td>\n",
              "      <td>50.6</td>\n",
              "      <td>32.270000</td>\n",
              "      <td>10.564095</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.0163</td>\n",
              "      <td>34</td>\n",
              "      <td>57</td>\n",
              "      <td>40.600000</td>\n",
              "      <td>6.736303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>56.0</td>\n",
              "      <td>12.279890</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>12.279890</td>\n",
              "      <td>12.279890</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>5</td>\n",
              "      <td>0.046729</td>\n",
              "      <td>6.078606</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>5.199885</td>\n",
              "      <td>79.112533</td>\n",
              "      <td>76.730010</td>\n",
              "      <td>1.729905</td>\n",
              "      <td>1.094891</td>\n",
              "      <td>5.718203</td>\n",
              "      <td>67.50</td>\n",
              "      <td>97.2</td>\n",
              "      <td>24.716151</td>\n",
              "      <td>57.091667</td>\n",
              "      <td>55.815206</td>\n",
              "      <td>5.762615</td>\n",
              "      <td>20.800</td>\n",
              "      <td>14.893113</td>\n",
              "      <td>36.689485</td>\n",
              "      <td>28.698280</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.804939</td>\n",
              "      <td>43.10</td>\n",
              "      <td>60.4</td>\n",
              "      <td>44.516667</td>\n",
              "      <td>12.546411</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.0525</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.984732</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>7.820038</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>7.820038</td>\n",
              "      <td>7.820038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>38</td>\n",
              "      <td>0.060748</td>\n",
              "      <td>6.630280</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>7.299547</td>\n",
              "      <td>80.878674</td>\n",
              "      <td>78.544538</td>\n",
              "      <td>1.980301</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>4.866722</td>\n",
              "      <td>78.16</td>\n",
              "      <td>85.7</td>\n",
              "      <td>20.413301</td>\n",
              "      <td>40.322667</td>\n",
              "      <td>39.695422</td>\n",
              "      <td>4.885491</td>\n",
              "      <td>10.800</td>\n",
              "      <td>4.095428</td>\n",
              "      <td>24.524718</td>\n",
              "      <td>8.230068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.332988</td>\n",
              "      <td>32.70</td>\n",
              "      <td>56.2</td>\n",
              "      <td>39.920000</td>\n",
              "      <td>7.972381</td>\n",
              "      <td>3.075563</td>\n",
              "      <td>3.075563</td>\n",
              "      <td>0.1380</td>\n",
              "      <td>10</td>\n",
              "      <td>41</td>\n",
              "      <td>15.466667</td>\n",
              "      <td>7.670599</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>44.0</td>\n",
              "      <td>11.309278</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>11.309278</td>\n",
              "      <td>11.309278</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 93 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  total_tracks  ...  sextile_score  tripartite_score\n",
              "0              25      0.037383  ...              3                 1\n",
              "1              69      0.070093  ...              4                 2\n",
              "2              44      0.233645  ...              1                 0\n",
              "3              43      0.046729  ...              3                 1\n",
              "4              60      0.037383  ...              4                 2\n",
              "...           ...           ...  ...            ...               ...\n",
              "16437          31      0.023364  ...              3                 1\n",
              "16438          56      0.070093  ...              5                 2\n",
              "16439          57      0.037383  ...              5                 2\n",
              "16440           5      0.046729  ...              5                 2\n",
              "16441          38      0.060748  ...              3                 1\n",
              "\n",
              "[16442 rows x 93 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "N6wWC7O-mPWb",
        "outputId": "eb91200f-b524-462f-c294-eedb2ba9b58d"
      },
      "source": [
        "scaled = scaled.drop(['rounded_score', 'sextile_score', 'tripartite_score'], axis=1)\n",
        "scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>album_duration_minutes</th>\n",
              "      <th>year</th>\n",
              "      <th>min_loudness</th>\n",
              "      <th>max_loudness</th>\n",
              "      <th>mean_loudness</th>\n",
              "      <th>stddev_loudness</th>\n",
              "      <th>label_frequency</th>\n",
              "      <th>mean_duration</th>\n",
              "      <th>min_valence</th>\n",
              "      <th>max_valence</th>\n",
              "      <th>stddev_valence</th>\n",
              "      <th>mean_valence</th>\n",
              "      <th>weighted_avg_valence</th>\n",
              "      <th>weighted_avg_speechiness</th>\n",
              "      <th>med_liveness</th>\n",
              "      <th>stddev_liveness</th>\n",
              "      <th>stddev_instrumentalness</th>\n",
              "      <th>weighted_avg_instrumentalness</th>\n",
              "      <th>explicit</th>\n",
              "      <th>weighted_avg_energy</th>\n",
              "      <th>min_danceability</th>\n",
              "      <th>max_danceability</th>\n",
              "      <th>mean_danceability</th>\n",
              "      <th>stddev_danceability</th>\n",
              "      <th>mean_acousticness</th>\n",
              "      <th>stddev_acousticness</th>\n",
              "      <th>med_acousticness</th>\n",
              "      <th>min_popularity</th>\n",
              "      <th>max_popularity</th>\n",
              "      <th>mean_popularity</th>\n",
              "      <th>stddev_popularity</th>\n",
              "      <th>key_0_pct</th>\n",
              "      <th>key_1_pct</th>\n",
              "      <th>key_2_pct</th>\n",
              "      <th>key_3_pct</th>\n",
              "      <th>key_4_pct</th>\n",
              "      <th>key_5_pct</th>\n",
              "      <th>key_6_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>sig_5_pct</th>\n",
              "      <th>num_artists</th>\n",
              "      <th>num_features</th>\n",
              "      <th>artist_popularity_mean</th>\n",
              "      <th>artist_followers_mean</th>\n",
              "      <th>artist_popularity_min</th>\n",
              "      <th>artist_popularity_max</th>\n",
              "      <th>artist_followers_min</th>\n",
              "      <th>artist_followers_max</th>\n",
              "      <th>artist_popularity_stddev</th>\n",
              "      <th>artist_followers_stddev</th>\n",
              "      <th>mean_feat_artist_popularity</th>\n",
              "      <th>mean_feat_artist_followers</th>\n",
              "      <th>min_feat_artist_popularity</th>\n",
              "      <th>min_feat_artist_followers</th>\n",
              "      <th>max_feat_artist_popularity</th>\n",
              "      <th>max_feat_artist_followers</th>\n",
              "      <th>stddev_feat_artist_popularity</th>\n",
              "      <th>stddev_feat_artist_followers</th>\n",
              "      <th>genre_0_pct</th>\n",
              "      <th>genre_1_pct</th>\n",
              "      <th>genre_2_pct</th>\n",
              "      <th>genre_3_pct</th>\n",
              "      <th>genre_4_pct</th>\n",
              "      <th>genre_5_pct</th>\n",
              "      <th>genre_6_pct</th>\n",
              "      <th>genre_7_pct</th>\n",
              "      <th>genre_8_pct</th>\n",
              "      <th>genre_9_pct</th>\n",
              "      <th>genre_10_pct</th>\n",
              "      <th>genre_11_pct</th>\n",
              "      <th>genre_12_pct</th>\n",
              "      <th>genre_13_pct</th>\n",
              "      <th>genre_14_pct</th>\n",
              "      <th>genre_15_pct</th>\n",
              "      <th>genre_16_pct</th>\n",
              "      <th>genre_17_pct</th>\n",
              "      <th>genre_18_pct</th>\n",
              "      <th>genre_19_pct</th>\n",
              "      <th>genre_20_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>0.037383</td>\n",
              "      <td>5.044812</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>8.695784</td>\n",
              "      <td>77.746616</td>\n",
              "      <td>71.966860</td>\n",
              "      <td>2.468588</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.787188</td>\n",
              "      <td>52.09</td>\n",
              "      <td>55.6</td>\n",
              "      <td>15.025998</td>\n",
              "      <td>18.476000</td>\n",
              "      <td>16.069549</td>\n",
              "      <td>3.524631</td>\n",
              "      <td>9.575</td>\n",
              "      <td>5.812945</td>\n",
              "      <td>30.604008</td>\n",
              "      <td>22.075199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.089854</td>\n",
              "      <td>39.40</td>\n",
              "      <td>63.3</td>\n",
              "      <td>45.330000</td>\n",
              "      <td>10.642582</td>\n",
              "      <td>76.730000</td>\n",
              "      <td>76.730000</td>\n",
              "      <td>81.6500</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>12.800000</td>\n",
              "      <td>2.699794</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057692</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.289716</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>6.289716</td>\n",
              "      <td>6.289716</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>7.482682</td>\n",
              "      <td>24.0</td>\n",
              "      <td>7.482682</td>\n",
              "      <td>24.0</td>\n",
              "      <td>7.482682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>0.070093</td>\n",
              "      <td>7.350411</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>5.087701</td>\n",
              "      <td>81.197035</td>\n",
              "      <td>78.453161</td>\n",
              "      <td>1.668215</td>\n",
              "      <td>0.364964</td>\n",
              "      <td>4.709538</td>\n",
              "      <td>75.31</td>\n",
              "      <td>82.5</td>\n",
              "      <td>20.156995</td>\n",
              "      <td>43.517059</td>\n",
              "      <td>43.974797</td>\n",
              "      <td>26.145333</td>\n",
              "      <td>11.200</td>\n",
              "      <td>10.004012</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.000364</td>\n",
              "      <td>100.0</td>\n",
              "      <td>55.135105</td>\n",
              "      <td>45.40</td>\n",
              "      <td>87.3</td>\n",
              "      <td>75.317647</td>\n",
              "      <td>12.166976</td>\n",
              "      <td>12.456412</td>\n",
              "      <td>12.456412</td>\n",
              "      <td>6.9500</td>\n",
              "      <td>33</td>\n",
              "      <td>72</td>\n",
              "      <td>40.941176</td>\n",
              "      <td>8.989373</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>41.176471</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.288462</td>\n",
              "      <td>69.0</td>\n",
              "      <td>11.990569</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>11.990569</td>\n",
              "      <td>11.990569</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.230769</td>\n",
              "      <td>15.280879</td>\n",
              "      <td>25.0</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>99.0</td>\n",
              "      <td>17.815850</td>\n",
              "      <td>20.753128</td>\n",
              "      <td>2.863981</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.117647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>0.233645</td>\n",
              "      <td>31.012511</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27.651865</td>\n",
              "      <td>77.851220</td>\n",
              "      <td>67.206191</td>\n",
              "      <td>7.829765</td>\n",
              "      <td>7.299270</td>\n",
              "      <td>6.699524</td>\n",
              "      <td>83.92</td>\n",
              "      <td>87.1</td>\n",
              "      <td>21.225589</td>\n",
              "      <td>29.830000</td>\n",
              "      <td>28.973155</td>\n",
              "      <td>9.620623</td>\n",
              "      <td>11.250</td>\n",
              "      <td>13.873995</td>\n",
              "      <td>32.165156</td>\n",
              "      <td>68.565822</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.134999</td>\n",
              "      <td>72.37</td>\n",
              "      <td>81.6</td>\n",
              "      <td>44.774600</td>\n",
              "      <td>19.179167</td>\n",
              "      <td>84.409600</td>\n",
              "      <td>84.409600</td>\n",
              "      <td>93.0000</td>\n",
              "      <td>13</td>\n",
              "      <td>34</td>\n",
              "      <td>18.960000</td>\n",
              "      <td>4.936164</td>\n",
              "      <td>13.461538</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>...</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>50.0</td>\n",
              "      <td>9.708324</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>9.708324</td>\n",
              "      <td>9.708324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>7.891518</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6.745236</td>\n",
              "      <td>41.0</td>\n",
              "      <td>8.411610</td>\n",
              "      <td>11.313708</td>\n",
              "      <td>2.181098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>9.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>0.046729</td>\n",
              "      <td>5.451592</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>5.084669</td>\n",
              "      <td>79.579461</td>\n",
              "      <td>76.552764</td>\n",
              "      <td>1.577898</td>\n",
              "      <td>22.992701</td>\n",
              "      <td>5.104305</td>\n",
              "      <td>73.80</td>\n",
              "      <td>96.7</td>\n",
              "      <td>23.668895</td>\n",
              "      <td>72.475000</td>\n",
              "      <td>74.175735</td>\n",
              "      <td>6.567317</td>\n",
              "      <td>9.125</td>\n",
              "      <td>13.549375</td>\n",
              "      <td>24.003436</td>\n",
              "      <td>18.619665</td>\n",
              "      <td>0.0</td>\n",
              "      <td>61.188227</td>\n",
              "      <td>51.50</td>\n",
              "      <td>87.9</td>\n",
              "      <td>69.800000</td>\n",
              "      <td>16.594961</td>\n",
              "      <td>28.157500</td>\n",
              "      <td>28.157500</td>\n",
              "      <td>16.4000</td>\n",
              "      <td>24</td>\n",
              "      <td>36</td>\n",
              "      <td>28.583333</td>\n",
              "      <td>3.824760</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>57.0</td>\n",
              "      <td>11.820167</td>\n",
              "      <td>57</td>\n",
              "      <td>57</td>\n",
              "      <td>11.820167</td>\n",
              "      <td>11.820167</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>0.037383</td>\n",
              "      <td>5.648647</td>\n",
              "      <td>98.461538</td>\n",
              "      <td>16.084775</td>\n",
              "      <td>81.914103</td>\n",
              "      <td>78.010248</td>\n",
              "      <td>4.848596</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.496633</td>\n",
              "      <td>71.90</td>\n",
              "      <td>90.5</td>\n",
              "      <td>28.487900</td>\n",
              "      <td>58.760000</td>\n",
              "      <td>59.015377</td>\n",
              "      <td>6.562235</td>\n",
              "      <td>32.850</td>\n",
              "      <td>17.877847</td>\n",
              "      <td>33.922389</td>\n",
              "      <td>31.894178</td>\n",
              "      <td>100.0</td>\n",
              "      <td>74.673965</td>\n",
              "      <td>28.00</td>\n",
              "      <td>65.5</td>\n",
              "      <td>54.750000</td>\n",
              "      <td>9.336577</td>\n",
              "      <td>9.097215</td>\n",
              "      <td>9.097215</td>\n",
              "      <td>4.4200</td>\n",
              "      <td>41</td>\n",
              "      <td>53</td>\n",
              "      <td>46.500000</td>\n",
              "      <td>4.169999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>68.0</td>\n",
              "      <td>13.380706</td>\n",
              "      <td>68</td>\n",
              "      <td>68</td>\n",
              "      <td>13.380706</td>\n",
              "      <td>13.380706</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>31</td>\n",
              "      <td>0.023364</td>\n",
              "      <td>3.986448</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>7.487531</td>\n",
              "      <td>75.086033</td>\n",
              "      <td>71.995339</td>\n",
              "      <td>2.927091</td>\n",
              "      <td>74.087591</td>\n",
              "      <td>6.790914</td>\n",
              "      <td>69.50</td>\n",
              "      <td>76.3</td>\n",
              "      <td>24.618199</td>\n",
              "      <td>41.728571</td>\n",
              "      <td>42.058227</td>\n",
              "      <td>6.142869</td>\n",
              "      <td>12.600</td>\n",
              "      <td>7.080754</td>\n",
              "      <td>30.172104</td>\n",
              "      <td>73.998741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70.294207</td>\n",
              "      <td>27.20</td>\n",
              "      <td>58.2</td>\n",
              "      <td>43.728571</td>\n",
              "      <td>9.774067</td>\n",
              "      <td>22.448286</td>\n",
              "      <td>22.448286</td>\n",
              "      <td>3.6000</td>\n",
              "      <td>8</td>\n",
              "      <td>35</td>\n",
              "      <td>12.571429</td>\n",
              "      <td>9.947481</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.857143</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>50.0</td>\n",
              "      <td>11.978971</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>11.978971</td>\n",
              "      <td>11.978971</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>56</td>\n",
              "      <td>0.070093</td>\n",
              "      <td>8.359267</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>85.660143</td>\n",
              "      <td>85.660143</td>\n",
              "      <td>75.658814</td>\n",
              "      <td>19.957987</td>\n",
              "      <td>25.547445</td>\n",
              "      <td>5.406775</td>\n",
              "      <td>83.90</td>\n",
              "      <td>83.9</td>\n",
              "      <td>24.398101</td>\n",
              "      <td>43.188235</td>\n",
              "      <td>46.731975</td>\n",
              "      <td>3.583291</td>\n",
              "      <td>10.700</td>\n",
              "      <td>11.592671</td>\n",
              "      <td>15.440686</td>\n",
              "      <td>6.035377</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.086232</td>\n",
              "      <td>69.20</td>\n",
              "      <td>69.2</td>\n",
              "      <td>47.223529</td>\n",
              "      <td>16.006777</td>\n",
              "      <td>23.552353</td>\n",
              "      <td>23.552353</td>\n",
              "      <td>7.0800</td>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>32.294118</td>\n",
              "      <td>10.941690</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>35.294118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>67.0</td>\n",
              "      <td>13.284176</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>13.284176</td>\n",
              "      <td>13.284176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.647059</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.411765</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>57</td>\n",
              "      <td>0.037383</td>\n",
              "      <td>6.398267</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>2.516562</td>\n",
              "      <td>82.393160</td>\n",
              "      <td>81.402908</td>\n",
              "      <td>0.907825</td>\n",
              "      <td>37.226277</td>\n",
              "      <td>7.377359</td>\n",
              "      <td>72.40</td>\n",
              "      <td>93.3</td>\n",
              "      <td>20.468502</td>\n",
              "      <td>52.920000</td>\n",
              "      <td>50.707482</td>\n",
              "      <td>3.270570</td>\n",
              "      <td>18.100</td>\n",
              "      <td>8.463656</td>\n",
              "      <td>29.561014</td>\n",
              "      <td>40.199373</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.314037</td>\n",
              "      <td>32.60</td>\n",
              "      <td>50.6</td>\n",
              "      <td>32.270000</td>\n",
              "      <td>10.564095</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.0163</td>\n",
              "      <td>34</td>\n",
              "      <td>57</td>\n",
              "      <td>40.600000</td>\n",
              "      <td>6.736303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>56.0</td>\n",
              "      <td>12.279890</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>12.279890</td>\n",
              "      <td>12.279890</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>5</td>\n",
              "      <td>0.046729</td>\n",
              "      <td>6.078606</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>5.199885</td>\n",
              "      <td>79.112533</td>\n",
              "      <td>76.730010</td>\n",
              "      <td>1.729905</td>\n",
              "      <td>1.094891</td>\n",
              "      <td>5.718203</td>\n",
              "      <td>67.50</td>\n",
              "      <td>97.2</td>\n",
              "      <td>24.716151</td>\n",
              "      <td>57.091667</td>\n",
              "      <td>55.815206</td>\n",
              "      <td>5.762615</td>\n",
              "      <td>20.800</td>\n",
              "      <td>14.893113</td>\n",
              "      <td>36.689485</td>\n",
              "      <td>28.698280</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.804939</td>\n",
              "      <td>43.10</td>\n",
              "      <td>60.4</td>\n",
              "      <td>44.516667</td>\n",
              "      <td>12.546411</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.0525</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.984732</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>17.0</td>\n",
              "      <td>7.820038</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>7.820038</td>\n",
              "      <td>7.820038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>38</td>\n",
              "      <td>0.060748</td>\n",
              "      <td>6.630280</td>\n",
              "      <td>66.153846</td>\n",
              "      <td>7.299547</td>\n",
              "      <td>80.878674</td>\n",
              "      <td>78.544538</td>\n",
              "      <td>1.980301</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>4.866722</td>\n",
              "      <td>78.16</td>\n",
              "      <td>85.7</td>\n",
              "      <td>20.413301</td>\n",
              "      <td>40.322667</td>\n",
              "      <td>39.695422</td>\n",
              "      <td>4.885491</td>\n",
              "      <td>10.800</td>\n",
              "      <td>4.095428</td>\n",
              "      <td>24.524718</td>\n",
              "      <td>8.230068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.332988</td>\n",
              "      <td>32.70</td>\n",
              "      <td>56.2</td>\n",
              "      <td>39.920000</td>\n",
              "      <td>7.972381</td>\n",
              "      <td>3.075563</td>\n",
              "      <td>3.075563</td>\n",
              "      <td>0.1380</td>\n",
              "      <td>10</td>\n",
              "      <td>41</td>\n",
              "      <td>15.466667</td>\n",
              "      <td>7.670599</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>44.0</td>\n",
              "      <td>11.309278</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>11.309278</td>\n",
              "      <td>11.309278</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 90 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  total_tracks  ...  genre_19_pct  genre_20_pct\n",
              "0              25      0.037383  ...     10.000000      0.000000\n",
              "1              69      0.070093  ...      0.000000      0.000000\n",
              "2              44      0.233645  ...      1.923077      9.615385\n",
              "3              43      0.046729  ...      0.000000      0.000000\n",
              "4              60      0.037383  ...      0.000000      0.000000\n",
              "...           ...           ...  ...           ...           ...\n",
              "16437          31      0.023364  ...     14.285714      0.000000\n",
              "16438          56      0.070093  ...     11.764706      0.000000\n",
              "16439          57      0.037383  ...      0.000000      0.000000\n",
              "16440           5      0.046729  ...      0.000000      0.000000\n",
              "16441          38      0.060748  ...      0.000000      0.000000\n",
              "\n",
              "[16442 rows x 90 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoTvV0ZAmHMS",
        "outputId": "184bbe01-78fb-4eca-a834-a0f06d2c8f2e"
      },
      "source": [
        "# 3 buckets ridge classifier \n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "real_predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45974215519338363"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYPGhOgrrzR6"
      },
      "source": [
        "classification_dict['small_scaled_ridge'] = classification_report(y_test, real_predictions, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLdNR8CFmhJL",
        "outputId": "a5f893bc-2d1a-4831-a358-f6d30c3ee5c0"
      },
      "source": [
        "# 3 buckets passive aggressive \n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4054974458769156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JTnWKhIlSME",
        "outputId": "ce60ac91-71cd-4631-83ab-98ad9fb7291c"
      },
      "source": [
        "# 3 buckets perceptron \n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31865726100705427"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYVjr9r0lZ5d",
        "outputId": "05587fda-d2fd-45fd-cba0-0e6bec0566d7"
      },
      "source": [
        "# bernoulli\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB(alpha=2)\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3799562150328387"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDX6PC0DlbUH",
        "outputId": "ed44b6e4-c09e-4e4e-b2fd-6c08dbf4f8b4"
      },
      "source": [
        "# 3 buckets gaussian \n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4254439309170518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH6oe9pHppTG"
      },
      "source": [
        "# LOGISTIC REGRESSION 🤠"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHenJzVXoKaT"
      },
      "source": [
        "#x = pd.read_csv('THE_REAL_ONE.csv')\n",
        "#x = x.drop('pitchfork_id', axis=1)\n",
        "#y = the_real_one_scaled.drop(labels=['score', 'rounded_score', 'sextile_score', 'tripartite_score'], axis=1)\n",
        "x = the_real_one"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKIoVpzSse4n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "472aa9ce-c176-49c9-d3ef-8a78884ddd7e"
      },
      "source": [
        "# 10 BUCKETS: the real one\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-fbdd548ce10e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 10 BUCKETS: the real one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe_real_one\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rounded_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             w0, n_iter_i = _newton_cg(hess, func, grad, w0, args=args,\n\u001b[0;32m--> 945\u001b[0;31m                                       maxiter=max_iter, tol=tol)\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_newton_cg\u001b[0;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Inner loop: solve the Newton update by conjugate gradient, to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# avoid inverting the Hessian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mxsupi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfhess_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtermcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0malphak\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_cg\u001b[0;34m(fhess_p, fgrad, maxiter, tol)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mAp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfhess_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m# check curvature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mcurv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mhessp\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minter_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mr_yhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     45\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     46\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Ap4FtZonEx"
      },
      "source": [
        "# 6 BUCKETS: the real one \n",
        "X_train, X_test, y_train, y_test = train_test_split(x, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_LVdUe-o5FP"
      },
      "source": [
        "# 10 BUCKETS: da big man \n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man_x, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsccHmKopP_U"
      },
      "source": [
        "# 6 BUCKETS: da big man \n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man_x, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF19OOqHpSm2"
      },
      "source": [
        "# 3 BUCKETS: da big man\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "SOqWeJreZRBw",
        "outputId": "d3c45dbf-a723-4803-aa4c-5e9568df5130"
      },
      "source": [
        "# 3 BUCKETS: da big man pct scaled\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-335-cb36c2f0343f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3 BUCKETS: da big man pct scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct_scaled_big_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe_real_one\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tripartite_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             w0, n_iter_i = _newton_cg(hess, func, grad, w0, args=args,\n\u001b[0;32m--> 945\u001b[0;31m                                       maxiter=max_iter, tol=tol)\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_newton_cg\u001b[0;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Inner loop: solve the Newton update by conjugate gradient, to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# avoid inverting the Hessian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mxsupi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfhess_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtermcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0malphak\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_cg\u001b[0;34m(fhess_p, fgrad, maxiter, tol)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mAp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfhess_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m# check curvature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mcurv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mhessp\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# r_yhat holds the result of applying the R-operator on the multinomial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# estimator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minter_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mr_yhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_0go4TGZVIC",
        "outputId": "5e1fa366-a548-4bb8-a07b-aa6ff5ca642f"
      },
      "source": [
        "# 3 BUCKETS: da big man scaled\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37922646558015083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHhuv28bZYjm",
        "outputId": "1e8cc9a6-891b-4a59-96f5-37eebbe275d4"
      },
      "source": [
        "# 6 BUCKETS: da big man pct scaled\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2094380929214303"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOT45oXJaw-k",
        "outputId": "9670aae4-1f04-408f-de1e-9cbe73f339d5"
      },
      "source": [
        "# 10 BUCKETS: da big man pct scaled\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38725370955971783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUXfo8ro42hh"
      },
      "source": [
        "# 3 BUCKETS: the real one\n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtaZmm_eaKyo",
        "outputId": "92016c75-cd04-44cb-a254-20b7823b3b94"
      },
      "source": [
        "# 3 BUCKETS: genius\n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39095638255302123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC2cE6bGrSXj",
        "outputId": "1e5b16eb-77a2-458b-9fcc-11c9d6bdf591"
      },
      "source": [
        "# 6 BUCKETS: genius\n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20208083233293317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYSB8Is_riqE",
        "outputId": "08659390-77f9-4b1d-868b-cd7c7d05a06c"
      },
      "source": [
        "type(genius_scores.loc[0]['rounded_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx2f6JkssjOO"
      },
      "source": [
        "dgenius = genius.astype('float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MeQOH6zs4_I",
        "outputId": "39fcd5f3-fba8-4368-d16a-6141e20a6ac0"
      },
      "source": [
        "genius_scores['rounded_score'].unique()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  8,  6,  5,  9, 10,  4,  3,  2,  1,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDvwg0WZrW8i",
        "outputId": "498e0959-ffd7-4ee0-db99-91e59b95d858"
      },
      "source": [
        "# 10 BUCKETS: genius\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000)\n",
        "#predictions = clf.predict(X_test)\n",
        "#clf.score(X_test, y_test)\n",
        "clf.fit(gxtrain, g10train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g10test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vx4SfEJp084"
      },
      "source": [
        "# PASSIVE AGGRESSIVE CLASSIFIER 😣"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b8JiFzS7_6T",
        "outputId": "782f1a81-69a2-478b-ad2a-5d805cf5f72a"
      },
      "source": [
        "# THE REAL ONE: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(the_real_one, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36900997324252005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLxGC_9v_NVr",
        "outputId": "720dae24-e705-4c8c-a7dd-8ae09e53cc2f"
      },
      "source": [
        "# THE REAL ONE SCALED: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17441011919241062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KdXEvsx8Zvt",
        "outputId": "7d918a16-0405-4638-bd27-83d986d2d476"
      },
      "source": [
        "# THE REAL ONE: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(the_real_one, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20335684748236438"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLT67nTL_Qx2",
        "outputId": "694b34bf-5d82-4b75-9435-ffb36783c8d7"
      },
      "source": [
        "# THE REAL ONE SCALED: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22111408416443687"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC4lqLba8crj",
        "outputId": "8c02cea7-3239-4e01-ea6a-9d8f1b5d93f1"
      },
      "source": [
        "# THE REAL ONE: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(the_real_one, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3400632449525663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqwTGg-I_ULP",
        "outputId": "5597be90-bdc8-4d8c-f5f2-5f648e95cb12"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4205789345657991"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwfpyQLC8fl5",
        "outputId": "0f123041-6879-457e-ff89-2ae356a41ee3"
      },
      "source": [
        "# DA BIG MAN: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man_x, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20651909511067867"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIChY-wz8mkj",
        "outputId": "00af0fe3-1224-4673-b70c-42774bbbb72d"
      },
      "source": [
        "# DA BIG MAN: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man_x, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19995135003648748"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7kXPIL_8qrk",
        "outputId": "65d6f5b6-a7e8-4f44-fcfb-c2c9b0712fb0"
      },
      "source": [
        "# DA BIG MAN: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3981999513500365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tJWUDKDbD2t",
        "outputId": "e3fcd446-c53a-4dec-ee80-fcd7bd92a7f8"
      },
      "source": [
        "# DA BIG MAN PCT SCALED: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34687423984432014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW5-LK64bJIo",
        "outputId": "52b44422-5656-48a2-b412-ccf253511071"
      },
      "source": [
        "# DA BIG MAN PCT SCALED: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20651909511067867"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJwuKGrpbL-P",
        "outputId": "3d904976-d0d6-4fe7-ade8-b5909668024c"
      },
      "source": [
        "# DA BIG MAN PCT SCALED: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.258574556069083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jH4HvTK8x7F",
        "outputId": "7a2022b4-202a-445f-e6b2-215423c07cda"
      },
      "source": [
        "# DA BIG MAN SCALED: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.383118462661153"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5ECCjzkbPSW",
        "outputId": "7bd877da-7e07-48a3-b48b-b0d2b4297c84"
      },
      "source": [
        "# DA BIG MAN SCALED: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17270737046947215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr18ejkBbSP4",
        "outputId": "c016bc64-8fba-4bc4-c5c2-cc4a0598d319"
      },
      "source": [
        "# DA BIG MAN SCALED: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.predict(X_test)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21454633909024567"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDoVsFs6rxS6",
        "outputId": "81aefa6d-9a89-4ffb-e0e8-895056ffcb11"
      },
      "source": [
        "type(genius_scores.loc[0]['sextile_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "MrIIVuDmsP8Y",
        "outputId": "94451e41-8fcb-4555-bf88-295fc477a128"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_pct_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_pct_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_pct_followers</th>\n",
              "      <th>track0_dur_pct</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness_pct</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_pct</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness_pct</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>track2_dur_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>track17_percentile_total_words</th>\n",
              "      <th>track17_lyric_happy_score</th>\n",
              "      <th>track17_lyric_surprise_score</th>\n",
              "      <th>track17_lyric_sad_score</th>\n",
              "      <th>track17_lyric_angry_score</th>\n",
              "      <th>track17_lyric_fear_score</th>\n",
              "      <th>track18_genius_pageviews</th>\n",
              "      <th>track18_is_eng</th>\n",
              "      <th>track18_ttr_lexical_richness</th>\n",
              "      <th>track18_nltk_neg</th>\n",
              "      <th>track18_nltk_neu</th>\n",
              "      <th>track18_nltk_pos</th>\n",
              "      <th>track18_nltk_compound</th>\n",
              "      <th>track18_textblob_polarity</th>\n",
              "      <th>track18_textblob_subjectivity</th>\n",
              "      <th>track18_percent_unique_words</th>\n",
              "      <th>track18_percent_expletive_words</th>\n",
              "      <th>track18_percentile_total_words</th>\n",
              "      <th>track18_lyric_happy_score</th>\n",
              "      <th>track18_lyric_surprise_score</th>\n",
              "      <th>track18_lyric_sad_score</th>\n",
              "      <th>track18_lyric_angry_score</th>\n",
              "      <th>track18_lyric_fear_score</th>\n",
              "      <th>track19_genius_pageviews</th>\n",
              "      <th>track19_is_eng</th>\n",
              "      <th>track19_ttr_lexical_richness</th>\n",
              "      <th>track19_nltk_neg</th>\n",
              "      <th>track19_nltk_neu</th>\n",
              "      <th>track19_nltk_pos</th>\n",
              "      <th>track19_nltk_compound</th>\n",
              "      <th>track19_textblob_polarity</th>\n",
              "      <th>track19_textblob_subjectivity</th>\n",
              "      <th>track19_percent_unique_words</th>\n",
              "      <th>track19_percent_expletive_words</th>\n",
              "      <th>track19_percentile_total_words</th>\n",
              "      <th>track19_lyric_happy_score</th>\n",
              "      <th>track19_lyric_surprise_score</th>\n",
              "      <th>track19_lyric_sad_score</th>\n",
              "      <th>track19_lyric_angry_score</th>\n",
              "      <th>track19_lyric_fear_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3541</th>\n",
              "      <td>33</td>\n",
              "      <td>5.008515</td>\n",
              "      <td>90.769231</td>\n",
              "      <td>66</td>\n",
              "      <td>82.150442</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84.338844</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>52.60000</td>\n",
              "      <td>45.5</td>\n",
              "      <td>40.1</td>\n",
              "      <td>11.8000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>6.65</td>\n",
              "      <td>35.343299</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.78</td>\n",
              "      <td>34.588844</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.51</td>\n",
              "      <td>80.700532</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>9.4800</td>\n",
              "      <td>36.3</td>\n",
              "      <td>48.9</td>\n",
              "      <td>0.00127</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>67.90</td>\n",
              "      <td>33.702812</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.62</td>\n",
              "      <td>31.808532</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9.65</td>\n",
              "      <td>76.447038</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1950</th>\n",
              "      <td>32</td>\n",
              "      <td>22.552001</td>\n",
              "      <td>95.384615</td>\n",
              "      <td>27</td>\n",
              "      <td>45.831858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.313096</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0.72800</td>\n",
              "      <td>40.4</td>\n",
              "      <td>92.7</td>\n",
              "      <td>85.4000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.80</td>\n",
              "      <td>32.121706</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.74</td>\n",
              "      <td>68.385498</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.09</td>\n",
              "      <td>94.918081</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0629</td>\n",
              "      <td>50.7</td>\n",
              "      <td>87.3</td>\n",
              "      <td>88.60000</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>11.10</td>\n",
              "      <td>39.935394</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.66</td>\n",
              "      <td>63.199368</td>\n",
              "      <td>80.0</td>\n",
              "      <td>80.30</td>\n",
              "      <td>94.376267</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1012</th>\n",
              "      <td>66</td>\n",
              "      <td>90.238414</td>\n",
              "      <td>96.923077</td>\n",
              "      <td>69</td>\n",
              "      <td>82.235988</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.891901</td>\n",
              "      <td>100</td>\n",
              "      <td>47</td>\n",
              "      <td>12.00000</td>\n",
              "      <td>58.4</td>\n",
              "      <td>39.7</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>39.60</td>\n",
              "      <td>36.412940</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.68</td>\n",
              "      <td>59.848313</td>\n",
              "      <td>80.0</td>\n",
              "      <td>11.90</td>\n",
              "      <td>68.254898</td>\n",
              "      <td>100</td>\n",
              "      <td>48</td>\n",
              "      <td>9.4300</td>\n",
              "      <td>75.7</td>\n",
              "      <td>58.6</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>30.90</td>\n",
              "      <td>60.392123</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.89</td>\n",
              "      <td>52.670664</td>\n",
              "      <td>80.0</td>\n",
              "      <td>67.20</td>\n",
              "      <td>64.675703</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3295</th>\n",
              "      <td>47</td>\n",
              "      <td>95.265175</td>\n",
              "      <td>90.769231</td>\n",
              "      <td>75</td>\n",
              "      <td>93.050147</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.382696</td>\n",
              "      <td>100</td>\n",
              "      <td>34</td>\n",
              "      <td>2.23000</td>\n",
              "      <td>83.0</td>\n",
              "      <td>52.7</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>10.30</td>\n",
              "      <td>50.227230</td>\n",
              "      <td>100.0</td>\n",
              "      <td>23.10</td>\n",
              "      <td>45.326981</td>\n",
              "      <td>80.0</td>\n",
              "      <td>28.40</td>\n",
              "      <td>65.341029</td>\n",
              "      <td>100</td>\n",
              "      <td>33</td>\n",
              "      <td>2.2700</td>\n",
              "      <td>62.5</td>\n",
              "      <td>62.1</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>22.60</td>\n",
              "      <td>79.507379</td>\n",
              "      <td>100.0</td>\n",
              "      <td>34.40</td>\n",
              "      <td>59.875623</td>\n",
              "      <td>80.0</td>\n",
              "      <td>41.60</td>\n",
              "      <td>56.636897</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6541</th>\n",
              "      <td>42</td>\n",
              "      <td>90.238414</td>\n",
              "      <td>81.538462</td>\n",
              "      <td>54</td>\n",
              "      <td>75.094395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84.802012</td>\n",
              "      <td>100</td>\n",
              "      <td>29</td>\n",
              "      <td>10.60000</td>\n",
              "      <td>83.3</td>\n",
              "      <td>72.9</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>10.50</td>\n",
              "      <td>77.293408</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.30</td>\n",
              "      <td>40.164505</td>\n",
              "      <td>80.0</td>\n",
              "      <td>46.20</td>\n",
              "      <td>80.883688</td>\n",
              "      <td>100</td>\n",
              "      <td>17</td>\n",
              "      <td>3.0800</td>\n",
              "      <td>84.5</td>\n",
              "      <td>52.9</td>\n",
              "      <td>0.05380</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>12.80</td>\n",
              "      <td>74.150462</td>\n",
              "      <td>100.0</td>\n",
              "      <td>26.60</td>\n",
              "      <td>37.278289</td>\n",
              "      <td>80.0</td>\n",
              "      <td>26.90</td>\n",
              "      <td>76.718605</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4587</th>\n",
              "      <td>2</td>\n",
              "      <td>5.008515</td>\n",
              "      <td>87.692308</td>\n",
              "      <td>19</td>\n",
              "      <td>31.094395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90.735052</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.20000</td>\n",
              "      <td>53.7</td>\n",
              "      <td>93.1</td>\n",
              "      <td>95.7000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>13.50</td>\n",
              "      <td>83.184486</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.69</td>\n",
              "      <td>56.393702</td>\n",
              "      <td>80.0</td>\n",
              "      <td>79.10</td>\n",
              "      <td>84.880394</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37.5000</td>\n",
              "      <td>36.1</td>\n",
              "      <td>91.9</td>\n",
              "      <td>51.70000</td>\n",
              "      <td>72.727273</td>\n",
              "      <td>18.30</td>\n",
              "      <td>94.710117</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.13</td>\n",
              "      <td>45.669084</td>\n",
              "      <td>80.0</td>\n",
              "      <td>23.10</td>\n",
              "      <td>73.133604</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6646</th>\n",
              "      <td>38</td>\n",
              "      <td>75.447026</td>\n",
              "      <td>81.538462</td>\n",
              "      <td>33</td>\n",
              "      <td>53.604720</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.826176</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>10.20000</td>\n",
              "      <td>32.8</td>\n",
              "      <td>66.3</td>\n",
              "      <td>0.0602</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>15.40</td>\n",
              "      <td>94.020247</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.85</td>\n",
              "      <td>61.139573</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.70</td>\n",
              "      <td>88.387541</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>3.6900</td>\n",
              "      <td>44.1</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.00856</td>\n",
              "      <td>27.272727</td>\n",
              "      <td>24.50</td>\n",
              "      <td>95.589741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.10</td>\n",
              "      <td>47.398209</td>\n",
              "      <td>80.0</td>\n",
              "      <td>13.80</td>\n",
              "      <td>74.579586</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5478</th>\n",
              "      <td>34</td>\n",
              "      <td>50.191583</td>\n",
              "      <td>84.615385</td>\n",
              "      <td>31</td>\n",
              "      <td>39.545723</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.835698</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2.91000</td>\n",
              "      <td>43.3</td>\n",
              "      <td>80.8</td>\n",
              "      <td>81.5000</td>\n",
              "      <td>90.909091</td>\n",
              "      <td>11.20</td>\n",
              "      <td>73.795499</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.32</td>\n",
              "      <td>56.723994</td>\n",
              "      <td>80.0</td>\n",
              "      <td>18.40</td>\n",
              "      <td>83.518337</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>55.1000</td>\n",
              "      <td>57.8</td>\n",
              "      <td>65.1</td>\n",
              "      <td>0.23100</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>11.40</td>\n",
              "      <td>75.501964</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.71</td>\n",
              "      <td>46.066929</td>\n",
              "      <td>80.0</td>\n",
              "      <td>40.20</td>\n",
              "      <td>75.043810</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8548</th>\n",
              "      <td>49</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>75.384615</td>\n",
              "      <td>52</td>\n",
              "      <td>75.734513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.785998</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0.00369</td>\n",
              "      <td>16.4</td>\n",
              "      <td>97.4</td>\n",
              "      <td>44.2000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>14.20</td>\n",
              "      <td>97.888428</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.30</td>\n",
              "      <td>66.216164</td>\n",
              "      <td>80.0</td>\n",
              "      <td>31.80</td>\n",
              "      <td>80.726396</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>2.3900</td>\n",
              "      <td>25.7</td>\n",
              "      <td>87.6</td>\n",
              "      <td>14.90000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>5.25</td>\n",
              "      <td>98.225709</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.88</td>\n",
              "      <td>32.322246</td>\n",
              "      <td>80.0</td>\n",
              "      <td>48.00</td>\n",
              "      <td>80.168482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6276</th>\n",
              "      <td>28</td>\n",
              "      <td>11.455419</td>\n",
              "      <td>81.538462</td>\n",
              "      <td>52</td>\n",
              "      <td>65.554572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.581138</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.56500</td>\n",
              "      <td>48.3</td>\n",
              "      <td>89.7</td>\n",
              "      <td>6.1000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>22.40</td>\n",
              "      <td>73.805791</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.90</td>\n",
              "      <td>50.146773</td>\n",
              "      <td>80.0</td>\n",
              "      <td>49.40</td>\n",
              "      <td>72.158443</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3.1400</td>\n",
              "      <td>26.5</td>\n",
              "      <td>45.8</td>\n",
              "      <td>76.30000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.50</td>\n",
              "      <td>17.315102</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.62</td>\n",
              "      <td>47.858040</td>\n",
              "      <td>80.0</td>\n",
              "      <td>16.90</td>\n",
              "      <td>58.960128</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7497 rows × 861 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      popularity  ...  track19_lyric_fear_score\n",
              "3541          33  ...                       0.0\n",
              "1950          32  ...                       0.0\n",
              "1012          66  ...                       0.0\n",
              "3295          47  ...                       0.0\n",
              "6541          42  ...                       0.0\n",
              "...          ...  ...                       ...\n",
              "4587           2  ...                       0.0\n",
              "6646          38  ...                       0.0\n",
              "5478          34  ...                       0.0\n",
              "8548          49  ...                       0.0\n",
              "6276          28  ...                       0.0\n",
              "\n",
              "[7497 rows x 861 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJtTRnI5rrFj",
        "outputId": "4e855d2e-80d7-4dc0-e15d-602c3174b796"
      },
      "source": [
        "# GENIUS: 10 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, g, test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "#clf.fit(X_train, y_train)\n",
        "#clf.predict(X_test)\n",
        "#clf.score(X_test, y_test)\n",
        "clf.fit(gxtrain, g10train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g10test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3437374949979992"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHn97VzWt9q-",
        "outputId": "7fe7b80c-e8dc-44fe-c79b-e8c1ca2275f2"
      },
      "source": [
        "# GENIUS: 6 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "#clf.fit(X_train, y_train)\n",
        "#clf.predict(X_test)\n",
        "#clf.score(X_test, y_test)\n",
        "clf.fit(gxtrain, g6train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g6test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20208083233293317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnvetZOfuCEH",
        "outputId": "cfdc645d-9924-4ae5-fa65-a184d74e4522"
      },
      "source": [
        "# GENIUS: 3 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "#clf.fit(X_train, y_train)\n",
        "#clf.predict(X_test)\n",
        "#clf.score(X_test, y_test)\n",
        "clf.fit(gxtrain, g3train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g3test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3701480592236895"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W71YiA0Wp8yd"
      },
      "source": [
        "# PERCEPTRON 🧐"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GebDrwr_qOiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7bf1e00-3b5e-44e8-fb06-52deb90868ac"
      },
      "source": [
        "# THE REAL ONE: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(the_real_one, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33471174896618827"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkUwYih__aiw",
        "outputId": "6cfbe2c7-8943-49dd-b6eb-29efb5155fc4"
      },
      "source": [
        "# THE REAL ONE SCALED: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24470931646801264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KltKFq8SEp3g",
        "outputId": "7d6aa7c6-0aee-4387-88e5-ac95c8f8bc61"
      },
      "source": [
        "# THE REAL ONE: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(the_real_one, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14740938944295792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T43KpbUp_d_G",
        "outputId": "fb830f44-5f92-4b2c-b7b3-e8e6bb1705b9"
      },
      "source": [
        "# THE REAL ONE SCALED: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2264655801508149"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsKIaRI7EslX",
        "outputId": "1e51ad21-233b-46da-aeca-5153d4785f2d"
      },
      "source": [
        "# THE REAL ONE: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(the_real_one, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3410362442228168"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxWdhO3b_h2r",
        "outputId": "ad02adeb-6c7b-43d6-ce9e-07c88bca9866"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3816589637557772"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9nTasL0EwHj",
        "outputId": "d80dbebc-6482-464f-e4c7-20f90567724a"
      },
      "source": [
        "# DA BIG MAN: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12843590367307225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEKxarKgE19M",
        "outputId": "cf8808fe-0470-4872-da65-f3218a711b3b"
      },
      "source": [
        "# DA BIG MAN: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19046460715154465"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuC9HL4HE7fZ",
        "outputId": "100b4d27-1833-4dd0-d405-30633c1e7602"
      },
      "source": [
        "# DA BIG MAN: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4033081975188519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx-k9yQw869S",
        "outputId": "e059d94b-7d2d-493f-a93d-5bb9e345117f"
      },
      "source": [
        "# DA BIG MAN SCALED: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3619557285332036"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5bMD_aublBt",
        "outputId": "ecdc0d88-891d-42cf-8f3d-4dffa402dc6a"
      },
      "source": [
        "# DA BIG MAN PCT SCALED: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39528095353928483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_mKp_mT8__o",
        "outputId": "d43f4729-c10a-4293-f071-be82226ab71b"
      },
      "source": [
        "# DA BIG MAN PCT SCALED: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20773534419849185"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJw7hiVNbn5y",
        "outputId": "56927028-3d6d-4e5f-8fc1-8622886c1aac"
      },
      "source": [
        "# DA BIG MAN SCALED: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20797859401605448"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soHvfyME9E4_",
        "outputId": "b4a3ec37-9e9f-43f8-82c4-15f25a556de9"
      },
      "source": [
        "# DA BIG MAN SCALED: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12843590367307225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsmR-BqOb1ED",
        "outputId": "d9300a38-92d4-41b4-977e-fda4b8c186b7"
      },
      "source": [
        "# DA BIG MAN SCALED: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2656288007783994"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKrctMwhb4JH",
        "outputId": "28057978-c66d-4fbe-b68c-ae7d33e5ab0d"
      },
      "source": [
        "# DA BIG MAN PCT SCALED: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29895402578448066"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz0TkmIzucz5",
        "outputId": "a35f527c-c218-4c2d-a08a-f3986c4a48c4"
      },
      "source": [
        "# GENIUS: 10 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "#clf.fit(X_train, y_train)\n",
        "#clf.score(X_test, y_test)\n",
        "clf.fit(gxtrain, g10train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g10test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3017206882753101"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6cions1uj1w",
        "outputId": "f0e9b175-dd62-489a-c09d-9c97e6f4e618"
      },
      "source": [
        "# GENIUS: 6 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "#clf.fit(X_train, y_train)\n",
        "#clf.score(X_test, y_test)\n",
        "clf.fit(gxtrain, g6train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g6test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22849139655862344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3a68pdCuni1",
        "outputId": "5b193487-418e-4e2f-f5aa-c6ed432a322b"
      },
      "source": [
        "# GENIUS: 3 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "#clf.fit(X_train, y_train)\n",
        "#clf.score(X_test, y_test)\n",
        "clf.fit(gxtrain, g3train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g3test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3673469387755102"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE9_9O73qB5i"
      },
      "source": [
        "# RIDGE CLASSIFIER 😝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8lVn0tdqPGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39fb969-5349-4ae7-8664-6ba807dff510"
      },
      "source": [
        "# THE REAL ONE: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.44971e-19): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4035514473364145"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "eZZ5HWT14aSI",
        "outputId": "a54dde6d-7e50-4b13-bcf2-7a1265cce1e2"
      },
      "source": [
        "x_scaled_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>album_duration_minutes</th>\n",
              "      <th>year</th>\n",
              "      <th>min_loudness</th>\n",
              "      <th>max_loudness</th>\n",
              "      <th>mean_loudness</th>\n",
              "      <th>stddev_loudness</th>\n",
              "      <th>label_frequency</th>\n",
              "      <th>mean_duration</th>\n",
              "      <th>min_valence</th>\n",
              "      <th>max_valence</th>\n",
              "      <th>stddev_valence</th>\n",
              "      <th>mean_valence</th>\n",
              "      <th>weighted_avg_valence</th>\n",
              "      <th>weighted_avg_speechiness</th>\n",
              "      <th>med_liveness</th>\n",
              "      <th>stddev_liveness</th>\n",
              "      <th>stddev_instrumentalness</th>\n",
              "      <th>weighted_avg_instrumentalness</th>\n",
              "      <th>explicit</th>\n",
              "      <th>weighted_avg_energy</th>\n",
              "      <th>min_danceability</th>\n",
              "      <th>max_danceability</th>\n",
              "      <th>mean_danceability</th>\n",
              "      <th>stddev_danceability</th>\n",
              "      <th>mean_acousticness</th>\n",
              "      <th>stddev_acousticness</th>\n",
              "      <th>med_acousticness</th>\n",
              "      <th>min_popularity</th>\n",
              "      <th>max_popularity</th>\n",
              "      <th>mean_popularity</th>\n",
              "      <th>stddev_popularity</th>\n",
              "      <th>key_0_pct</th>\n",
              "      <th>key_1_pct</th>\n",
              "      <th>key_2_pct</th>\n",
              "      <th>key_3_pct</th>\n",
              "      <th>key_4_pct</th>\n",
              "      <th>key_5_pct</th>\n",
              "      <th>key_6_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>sig_5_pct</th>\n",
              "      <th>num_artists</th>\n",
              "      <th>num_features</th>\n",
              "      <th>artist_popularity_mean</th>\n",
              "      <th>artist_followers_mean</th>\n",
              "      <th>artist_popularity_min</th>\n",
              "      <th>artist_popularity_max</th>\n",
              "      <th>artist_followers_min</th>\n",
              "      <th>artist_followers_max</th>\n",
              "      <th>artist_popularity_stddev</th>\n",
              "      <th>artist_followers_stddev</th>\n",
              "      <th>mean_feat_artist_popularity</th>\n",
              "      <th>mean_feat_artist_followers</th>\n",
              "      <th>min_feat_artist_popularity</th>\n",
              "      <th>min_feat_artist_followers</th>\n",
              "      <th>max_feat_artist_popularity</th>\n",
              "      <th>max_feat_artist_followers</th>\n",
              "      <th>stddev_feat_artist_popularity</th>\n",
              "      <th>stddev_feat_artist_followers</th>\n",
              "      <th>genre_0_pct</th>\n",
              "      <th>genre_1_pct</th>\n",
              "      <th>genre_2_pct</th>\n",
              "      <th>genre_3_pct</th>\n",
              "      <th>genre_4_pct</th>\n",
              "      <th>genre_5_pct</th>\n",
              "      <th>genre_6_pct</th>\n",
              "      <th>genre_7_pct</th>\n",
              "      <th>genre_8_pct</th>\n",
              "      <th>genre_9_pct</th>\n",
              "      <th>genre_10_pct</th>\n",
              "      <th>genre_11_pct</th>\n",
              "      <th>genre_12_pct</th>\n",
              "      <th>genre_13_pct</th>\n",
              "      <th>genre_14_pct</th>\n",
              "      <th>genre_15_pct</th>\n",
              "      <th>genre_16_pct</th>\n",
              "      <th>genre_17_pct</th>\n",
              "      <th>genre_18_pct</th>\n",
              "      <th>genre_19_pct</th>\n",
              "      <th>genre_20_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24</td>\n",
              "      <td>4.205607</td>\n",
              "      <td>5.216574</td>\n",
              "      <td>89.230769</td>\n",
              "      <td>39.344784</td>\n",
              "      <td>82.696360</td>\n",
              "      <td>73.918161</td>\n",
              "      <td>12.819280</td>\n",
              "      <td>0.142336</td>\n",
              "      <td>0.053809</td>\n",
              "      <td>44.99</td>\n",
              "      <td>50.0</td>\n",
              "      <td>12.949785</td>\n",
              "      <td>27.991818</td>\n",
              "      <td>30.245793</td>\n",
              "      <td>4.447069</td>\n",
              "      <td>15.10</td>\n",
              "      <td>21.153535</td>\n",
              "      <td>32.176957</td>\n",
              "      <td>44.898394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62.383915</td>\n",
              "      <td>31.40</td>\n",
              "      <td>57.0</td>\n",
              "      <td>41.400000</td>\n",
              "      <td>10.030952</td>\n",
              "      <td>34.881455</td>\n",
              "      <td>34.881455</td>\n",
              "      <td>22.600</td>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>11.727273</td>\n",
              "      <td>4.076540</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.272727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>35.0</td>\n",
              "      <td>9.463353</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>9.463353</td>\n",
              "      <td>9.463353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "      <td>5.140187</td>\n",
              "      <td>3.547831</td>\n",
              "      <td>84.615385</td>\n",
              "      <td>3.984052</td>\n",
              "      <td>71.497658</td>\n",
              "      <td>69.608254</td>\n",
              "      <td>1.280190</td>\n",
              "      <td>0.171533</td>\n",
              "      <td>0.029373</td>\n",
              "      <td>60.10</td>\n",
              "      <td>96.7</td>\n",
              "      <td>19.979390</td>\n",
              "      <td>70.846154</td>\n",
              "      <td>69.486688</td>\n",
              "      <td>3.513317</td>\n",
              "      <td>11.90</td>\n",
              "      <td>4.893759</td>\n",
              "      <td>27.287752</td>\n",
              "      <td>17.900103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.964133</td>\n",
              "      <td>43.70</td>\n",
              "      <td>65.6</td>\n",
              "      <td>43.153846</td>\n",
              "      <td>13.156786</td>\n",
              "      <td>14.313231</td>\n",
              "      <td>14.313231</td>\n",
              "      <td>10.400</td>\n",
              "      <td>8</td>\n",
              "      <td>28</td>\n",
              "      <td>14.153846</td>\n",
              "      <td>5.899804</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>27.0</td>\n",
              "      <td>9.391328</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>9.391328</td>\n",
              "      <td>9.391328</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.153846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32</td>\n",
              "      <td>7.476636</td>\n",
              "      <td>7.058179</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>54.782226</td>\n",
              "      <td>85.041614</td>\n",
              "      <td>68.918855</td>\n",
              "      <td>15.766528</td>\n",
              "      <td>0.029197</td>\n",
              "      <td>0.042183</td>\n",
              "      <td>48.10</td>\n",
              "      <td>53.8</td>\n",
              "      <td>11.907827</td>\n",
              "      <td>20.198333</td>\n",
              "      <td>20.467366</td>\n",
              "      <td>3.580182</td>\n",
              "      <td>16.35</td>\n",
              "      <td>17.250501</td>\n",
              "      <td>37.102197</td>\n",
              "      <td>7.120938</td>\n",
              "      <td>100.0</td>\n",
              "      <td>42.041608</td>\n",
              "      <td>47.23</td>\n",
              "      <td>56.4</td>\n",
              "      <td>27.453889</td>\n",
              "      <td>11.760904</td>\n",
              "      <td>56.753778</td>\n",
              "      <td>56.753778</td>\n",
              "      <td>63.900</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>12.777778</td>\n",
              "      <td>6.575852</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>...</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>53.0</td>\n",
              "      <td>12.128511</td>\n",
              "      <td>53</td>\n",
              "      <td>53</td>\n",
              "      <td>12.128511</td>\n",
              "      <td>12.128511</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>16.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42</td>\n",
              "      <td>4.205607</td>\n",
              "      <td>6.656771</td>\n",
              "      <td>76.923077</td>\n",
              "      <td>27.550293</td>\n",
              "      <td>83.058684</td>\n",
              "      <td>72.457424</td>\n",
              "      <td>8.320842</td>\n",
              "      <td>0.014599</td>\n",
              "      <td>0.069192</td>\n",
              "      <td>93.44</td>\n",
              "      <td>96.8</td>\n",
              "      <td>34.509269</td>\n",
              "      <td>45.536364</td>\n",
              "      <td>40.454860</td>\n",
              "      <td>4.322030</td>\n",
              "      <td>10.30</td>\n",
              "      <td>7.468719</td>\n",
              "      <td>31.851682</td>\n",
              "      <td>30.171808</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.876194</td>\n",
              "      <td>37.50</td>\n",
              "      <td>64.9</td>\n",
              "      <td>49.981818</td>\n",
              "      <td>11.898976</td>\n",
              "      <td>36.886091</td>\n",
              "      <td>36.886091</td>\n",
              "      <td>19.100</td>\n",
              "      <td>22</td>\n",
              "      <td>38</td>\n",
              "      <td>27.181818</td>\n",
              "      <td>5.600325</td>\n",
              "      <td>27.272727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.272727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>56.0</td>\n",
              "      <td>12.932638</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>12.932638</td>\n",
              "      <td>12.932638</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>27.272727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39</td>\n",
              "      <td>5.140187</td>\n",
              "      <td>8.593851</td>\n",
              "      <td>93.846154</td>\n",
              "      <td>12.132559</td>\n",
              "      <td>79.159529</td>\n",
              "      <td>74.213050</td>\n",
              "      <td>3.993543</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.074977</td>\n",
              "      <td>64.60</td>\n",
              "      <td>78.6</td>\n",
              "      <td>20.878642</td>\n",
              "      <td>37.953846</td>\n",
              "      <td>35.150907</td>\n",
              "      <td>3.878383</td>\n",
              "      <td>11.30</td>\n",
              "      <td>14.394478</td>\n",
              "      <td>21.857669</td>\n",
              "      <td>12.832999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.755922</td>\n",
              "      <td>29.60</td>\n",
              "      <td>63.0</td>\n",
              "      <td>51.623077</td>\n",
              "      <td>8.460610</td>\n",
              "      <td>84.638462</td>\n",
              "      <td>84.638462</td>\n",
              "      <td>85.200</td>\n",
              "      <td>16</td>\n",
              "      <td>30</td>\n",
              "      <td>23.307692</td>\n",
              "      <td>5.647782</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>60.0</td>\n",
              "      <td>13.220368</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>13.220368</td>\n",
              "      <td>13.220368</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4106</th>\n",
              "      <td>45</td>\n",
              "      <td>2.336449</td>\n",
              "      <td>3.586631</td>\n",
              "      <td>75.384615</td>\n",
              "      <td>10.301229</td>\n",
              "      <td>78.403044</td>\n",
              "      <td>73.356925</td>\n",
              "      <td>3.369865</td>\n",
              "      <td>0.021898</td>\n",
              "      <td>0.061199</td>\n",
              "      <td>55.80</td>\n",
              "      <td>89.6</td>\n",
              "      <td>20.684086</td>\n",
              "      <td>60.485714</td>\n",
              "      <td>58.976325</td>\n",
              "      <td>3.352628</td>\n",
              "      <td>11.00</td>\n",
              "      <td>6.603955</td>\n",
              "      <td>32.962211</td>\n",
              "      <td>47.311894</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.390375</td>\n",
              "      <td>27.80</td>\n",
              "      <td>65.0</td>\n",
              "      <td>51.700000</td>\n",
              "      <td>9.409570</td>\n",
              "      <td>47.171429</td>\n",
              "      <td>47.171429</td>\n",
              "      <td>47.100</td>\n",
              "      <td>28</td>\n",
              "      <td>41</td>\n",
              "      <td>33.714286</td>\n",
              "      <td>5.313953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>61.5</td>\n",
              "      <td>13.234404</td>\n",
              "      <td>53</td>\n",
              "      <td>70</td>\n",
              "      <td>11.999596</td>\n",
              "      <td>13.770376</td>\n",
              "      <td>12.020815</td>\n",
              "      <td>13.237234</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4107</th>\n",
              "      <td>13</td>\n",
              "      <td>1.401869</td>\n",
              "      <td>8.013314</td>\n",
              "      <td>81.538462</td>\n",
              "      <td>4.649576</td>\n",
              "      <td>78.569804</td>\n",
              "      <td>76.022012</td>\n",
              "      <td>1.778030</td>\n",
              "      <td>0.361314</td>\n",
              "      <td>0.192495</td>\n",
              "      <td>69.84</td>\n",
              "      <td>73.4</td>\n",
              "      <td>27.653996</td>\n",
              "      <td>43.352000</td>\n",
              "      <td>38.245479</td>\n",
              "      <td>3.726274</td>\n",
              "      <td>12.30</td>\n",
              "      <td>10.446908</td>\n",
              "      <td>7.992496</td>\n",
              "      <td>87.566247</td>\n",
              "      <td>0.0</td>\n",
              "      <td>63.491094</td>\n",
              "      <td>38.90</td>\n",
              "      <td>57.1</td>\n",
              "      <td>30.660000</td>\n",
              "      <td>16.158218</td>\n",
              "      <td>7.314880</td>\n",
              "      <td>7.314880</td>\n",
              "      <td>0.238</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>7.400000</td>\n",
              "      <td>1.673320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>28.0</td>\n",
              "      <td>9.362460</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>9.362460</td>\n",
              "      <td>9.362460</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4108</th>\n",
              "      <td>31</td>\n",
              "      <td>4.672897</td>\n",
              "      <td>5.704334</td>\n",
              "      <td>81.538462</td>\n",
              "      <td>5.832057</td>\n",
              "      <td>84.562558</td>\n",
              "      <td>82.085664</td>\n",
              "      <td>1.395754</td>\n",
              "      <td>0.660584</td>\n",
              "      <td>0.053518</td>\n",
              "      <td>65.35</td>\n",
              "      <td>74.8</td>\n",
              "      <td>20.818594</td>\n",
              "      <td>47.770833</td>\n",
              "      <td>47.513808</td>\n",
              "      <td>4.065934</td>\n",
              "      <td>12.80</td>\n",
              "      <td>12.409446</td>\n",
              "      <td>0.003982</td>\n",
              "      <td>0.001434</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70.841811</td>\n",
              "      <td>49.50</td>\n",
              "      <td>78.4</td>\n",
              "      <td>55.175000</td>\n",
              "      <td>14.464070</td>\n",
              "      <td>25.037500</td>\n",
              "      <td>25.037500</td>\n",
              "      <td>20.900</td>\n",
              "      <td>4</td>\n",
              "      <td>35</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.563488</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>35.0</td>\n",
              "      <td>9.703816</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>9.703816</td>\n",
              "      <td>9.703816</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4109</th>\n",
              "      <td>12</td>\n",
              "      <td>3.738318</td>\n",
              "      <td>7.568682</td>\n",
              "      <td>81.538462</td>\n",
              "      <td>15.539014</td>\n",
              "      <td>83.674181</td>\n",
              "      <td>77.040310</td>\n",
              "      <td>5.250762</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.087525</td>\n",
              "      <td>37.10</td>\n",
              "      <td>41.0</td>\n",
              "      <td>13.199538</td>\n",
              "      <td>21.344000</td>\n",
              "      <td>19.499446</td>\n",
              "      <td>3.996173</td>\n",
              "      <td>96.50</td>\n",
              "      <td>10.650618</td>\n",
              "      <td>0.334912</td>\n",
              "      <td>0.165199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.909902</td>\n",
              "      <td>17.80</td>\n",
              "      <td>41.1</td>\n",
              "      <td>31.670000</td>\n",
              "      <td>6.841710</td>\n",
              "      <td>62.330000</td>\n",
              "      <td>62.330000</td>\n",
              "      <td>67.500</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>1.791957</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>59.0</td>\n",
              "      <td>12.459307</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>12.459307</td>\n",
              "      <td>12.459307</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4110</th>\n",
              "      <td>12</td>\n",
              "      <td>3.271028</td>\n",
              "      <td>5.831518</td>\n",
              "      <td>96.923077</td>\n",
              "      <td>18.343617</td>\n",
              "      <td>70.923093</td>\n",
              "      <td>61.327141</td>\n",
              "      <td>5.998827</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.075350</td>\n",
              "      <td>25.44</td>\n",
              "      <td>29.0</td>\n",
              "      <td>9.191515</td>\n",
              "      <td>13.747778</td>\n",
              "      <td>13.321886</td>\n",
              "      <td>3.955371</td>\n",
              "      <td>9.75</td>\n",
              "      <td>3.614072</td>\n",
              "      <td>28.957330</td>\n",
              "      <td>61.442111</td>\n",
              "      <td>100.0</td>\n",
              "      <td>9.205103</td>\n",
              "      <td>15.20</td>\n",
              "      <td>36.4</td>\n",
              "      <td>28.988889</td>\n",
              "      <td>5.801389</td>\n",
              "      <td>96.111111</td>\n",
              "      <td>96.111111</td>\n",
              "      <td>96.600</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>4.111111</td>\n",
              "      <td>2.204793</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.773080</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>6.773080</td>\n",
              "      <td>6.773080</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.444444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.444444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4111 rows × 90 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      popularity  total_tracks  ...  genre_19_pct  genre_20_pct\n",
              "0             24      4.205607  ...      0.000000      0.000000\n",
              "1             30      5.140187  ...      0.000000      0.000000\n",
              "2             32      7.476636  ...     16.666667     16.666667\n",
              "3             42      4.205607  ...      0.000000      0.000000\n",
              "4             39      5.140187  ...      7.692308      0.000000\n",
              "...          ...           ...  ...           ...           ...\n",
              "4106          45      2.336449  ...     14.285714      0.000000\n",
              "4107          13      1.401869  ...      0.000000      0.000000\n",
              "4108          31      4.672897  ...      0.000000      0.000000\n",
              "4109          12      3.738318  ...     10.000000      0.000000\n",
              "4110          12      3.271028  ...      0.000000     44.444444\n",
              "\n",
              "[4111 rows x 90 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNIGx6o6vDKm",
        "outputId": "13ab0100-57cb-4eb4-ac88-5e6dafdeaf43"
      },
      "source": [
        "# GENIUS: 10 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "#clf.fit(X_train, y_train)\n",
        "#predictions = clf.predict(X_test)\n",
        "#num_score = clf.score(X_test, y_test)\n",
        "#num_score\n",
        "clf.fit(gxtrain, g10train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g10test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:940: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3513405362144858"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-6AaApEvIKq",
        "outputId": "0a4f722b-7b4b-4e99-94f7-fda5ac2c4145"
      },
      "source": [
        "# GENIUS: 6 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "#clf.fit(X_train, y_train)\n",
        "#predictions = clf.predict(X_test)\n",
        "#num_score = clf.score(X_test, y_test)\n",
        "#num_score\n",
        "clf.fit(gxtrain, g6train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g6test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:940: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2416966786714686"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Ufb1hBvLQN",
        "outputId": "39056cb7-b25b-41c9-bee3-8ae137293da8"
      },
      "source": [
        "# GENIUS: 3 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "#clf.fit(X_train, y_train)\n",
        "#predictions = clf.predict(X_test)\n",
        "#num_score = clf.score(X_test, y_test)\n",
        "#num_score\n",
        "clf.fit(gxtrain, g3train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g3test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:940: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4293717486994798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbGc_UgR-hVz",
        "outputId": "98e118c1-175e-410a-beed-a4df48f75a81"
      },
      "source": [
        "# THE REAL ONE SCALED: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4035514473364145"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6ikIw_4zmSG",
        "outputId": "23856aaa-7c36-4e22-cebb-ddcc5cf117e3"
      },
      "source": [
        "# THE REAL ONE: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.44971e-19): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.27341279494040377"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMo8DFFC-mnQ",
        "outputId": "e98ec6c5-d573-4f6d-aa8d-d3dfc3f2b11f"
      },
      "source": [
        "# THE REAL ONE SCALED: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2768182923862807"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeMBgU_BAjTp"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZoCBJSZBm2k"
      },
      "source": [
        "#da_big_man_scaled = pd.read_csv('DA_BIG_MAN_MINMAXED.csv')\n",
        "#da_big_man_pct_scaled = pd.read_csv('DA_BIG_MAN_MINMAXED_PCT.csv')\n",
        "da_big_man_pct_scaled = da_big_man_pct_scaled.drop('pitchfork_id', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoeXFwXDDJLl",
        "outputId": "03896bd2-cb38-4aec-93a1-165126052d29"
      },
      "source": [
        "# THE REAL ONE: 3 BUCKETS\n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier(alpha=1.1, solver='sparse_cg')\n",
        "clf.fit(X_train, y_train)\n",
        "normalized_predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3631719776210168"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnHTAd18zqBK",
        "outputId": "44803356-8c46-4408-bebe-a4f81b8348d1"
      },
      "source": [
        "# THE REAL ONE: 3 BUCKETS\n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "real_predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.44971e-19): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46144490391632204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "1srrqEJ57dXN",
        "outputId": "33c49048-97f9-4881-e601-c7cb9625fc37"
      },
      "source": [
        "confusion_matrix_metric(y_test, predictions, ['0', '1', '2'], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[703 410 343]\n",
            " [469 573 360]\n",
            " [306 326 621]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "E_yetjzE9UDn",
        "outputId": "2d5ea7ad-09be-47d8-a8a1-7bb5e049cef7"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtVXKLdF-LPQ",
        "outputId": "ea3eb71a-d240-43fe-b612-12d34814703c"
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.48      0.48      1456\n",
            "           1       0.44      0.41      0.42      1402\n",
            "           2       0.47      0.50      0.48      1253\n",
            "\n",
            "    accuracy                           0.46      4111\n",
            "   macro avg       0.46      0.46      0.46      4111\n",
            "weighted avg       0.46      0.46      0.46      4111\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_AxXhvb-P6A",
        "outputId": "81f94b12-c5b8-4fb6-db8c-6545a576f467"
      },
      "source": [
        "balanced_accuracy_score(y_test, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46238068651331027"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlhTHstj-TT5",
        "outputId": "202819c8-7957-42d0-9589-b34c14fd4658"
      },
      "source": [
        "f1_score(y_test, predictions, average=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.47920927, 0.42272224, 0.48195576])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSx_SnE7-m9S",
        "outputId": "c427ce6c-e06b-41c7-f042-187cc7c1270b"
      },
      "source": [
        "f1_score(y_test, predictions, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46078225559235003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TQDXamu-ras",
        "outputId": "23b32577-5f2e-4c66-9048-310635190d2e"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45803940647044517"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shNoTGKR7qqB",
        "outputId": "25d807af-f480-414b-e5d7-41604d209142"
      },
      "source": [
        "# TRANSFORMING TO 50 FEATURES: the real one 3 buckets\n",
        "transformer = FastICA(n_components=50, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44855266358550233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1YVo430-wsb",
        "outputId": "06fd7def-fe53-4c15-a56f-6505ab2fc4a1"
      },
      "source": [
        "# TRANSFORMING TO 50 FEATURES: the real one scaled 3 buckets\n",
        "transformer = FastICA(n_components=50, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4429579177815617"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg7_X9mG8hEJ",
        "outputId": "b8be1df4-5cca-4a0b-a98c-e2213806f5b4"
      },
      "source": [
        "# TRANSFORMING TO 75 FEATURES: the real one 3 buckets\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed75 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed75, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4560934079299441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHEuoeOc-3HG",
        "outputId": "5d813f81-7e1f-4103-ffaa-fc584221b4b6"
      },
      "source": [
        "# TRANSFORMING TO 75 FEATURES: the real one scaled 3 buckets\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed75 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed75, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45682315738263196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqamYGVk8s8K",
        "outputId": "96a3b10b-b7d6-4560-a6bb-08241169738f"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: the real one 3 buckets\n",
        "transformer = FastICA(n_components=80, random_state=0)\n",
        "X_transformed80 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed80, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4609584042811968"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xArdZEiv_AIg",
        "outputId": "d3563fcf-6529-4907-ed11-d5a00c00a693"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: the real one scaled 3 buckets\n",
        "transformer = FastICA(n_components=80, random_state=0)\n",
        "X_transformed80 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed80, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4560934079299441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngIbHtGP_Esy",
        "outputId": "8aaeab3c-38e2-4383-f2de-e165e1d44b35"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one scaled 3 buckets\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed85 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4560934079299441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA9rSM204ZH8",
        "outputId": "7a46f726-02fc-483a-cde4-2845770e055f"
      },
      "source": [
        "# TRANSFORMING TO 90 FEATURES: the real one scaled 3 buckets\n",
        "transformer = FastICA(n_components=90, random_state=0)\n",
        "X_transformed85 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45803940647044517"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Ba9dRq5D4lBh",
        "outputId": "25a12aaa-2e80-4e67-dd06-af57800a8a4c"
      },
      "source": [
        "scores = pd.read_csv('final_pitchfork_scrape.csv')\n",
        "scores = scores[['pitchfork_id', 'score']]\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pitchfork_id</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>7.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>6.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>7.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>22319</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>22321</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>22322</td>\n",
              "      <td>9.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>22323</td>\n",
              "      <td>8.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>22324</td>\n",
              "      <td>7.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       pitchfork_id  score\n",
              "0                 2    7.5\n",
              "1                 3    7.7\n",
              "2                 5    6.5\n",
              "3                 6    7.6\n",
              "4                 7    8.0\n",
              "...             ...    ...\n",
              "16437         22319    7.5\n",
              "16438         22321    9.4\n",
              "16439         22322    9.3\n",
              "16440         22323    8.1\n",
              "16441         22324    7.4\n",
              "\n",
              "[16442 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxu-cxrg8z0-",
        "outputId": "88910dc4-6eae-4227-dcc0-d1f2cdf19f2b"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed85 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46266115300413524"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afYSPPip6lc0",
        "outputId": "759fae77-80bd-4999-97f3-1c646f7f7a9e"
      },
      "source": [
        "f1_score(y_test, predictions, average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46255502854486835"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ep_NTxz4xXM",
        "outputId": "342c05f8-be66-49cd-ba2b-4b35a4513756"
      },
      "source": [
        "balanced_accuracy_score(y_test, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4611896626048397"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "CPSEvKu49NGa",
        "outputId": "5d4fa5f8-b9d9-4cfb-9cdf-eb7c337bb2a7"
      },
      "source": [
        "confusion_matrix_metric(y_test, predictions, ['0', '1', '2'], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[726 452 278]\n",
            " [488 632 282]\n",
            " [334 375 544]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "whIjuDGt9Y86",
        "outputId": "febd675c-d044-4ed7-c928-96cd35432ba3"
      },
      "source": [
        "classification_scores(predictions, y_test, ['0', '1', '2'], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.50      0.48      1456\n",
            "           1       0.43      0.45      0.44      1402\n",
            "           2       0.49      0.43      0.46      1253\n",
            "\n",
            "    accuracy                           0.46      4111\n",
            "   macro avg       0.46      0.46      0.46      4111\n",
            "weighted avg       0.46      0.46      0.46      4111\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.47      0.50      0.48      1456\\n           1       0.43      0.45      0.44      1402\\n           2       0.49      0.43      0.46      1253\\n\\n    accuracy                           0.46      4111\\n   macro avg       0.46      0.46      0.46      4111\\nweighted avg       0.46      0.46      0.46      4111\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEh4dscJz4tc",
        "outputId": "e7dc06a6-3470-4a27-84a4-15de040e9fe3"
      },
      "source": [
        "# DA BIG MAN 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38652396010702994"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpi6oPVm9ZuF",
        "outputId": "4a52d0b4-6522-46ad-a1fe-a6d1f7d87954"
      },
      "source": [
        "# DA BIG MAN SCALED 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.4963e-83): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3860374604719046"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhME1pKacBZY",
        "outputId": "8ef16e57-40ef-4bb1-a533-2de238c590c6"
      },
      "source": [
        "# DA BIG MAN PCT SCALED 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3819022135733398"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESv300Ofz8QH",
        "outputId": "f12a15c6-c658-423f-8357-a797267c1aab"
      },
      "source": [
        "# DA BIG MAN 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2556555582583313"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhrXgSaYcFtt",
        "outputId": "33cba211-0774-4c41-dcc7-3595ce1f4ac7"
      },
      "source": [
        "# DA BIG MAN SCALED 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.4963e-83): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2554123084407687"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWJxscELcI_z",
        "outputId": "2abe1a23-5db4-4eb9-d895-015e6491f88c"
      },
      "source": [
        "# DA BIG MAN PCT SCALED 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2529798102651423"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-yNnD5H0DAo",
        "outputId": "302ac96a-63e3-4636-f109-b11ebbab6b5d"
      },
      "source": [
        "# DA BIG MAN 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43420092434930674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvnPGZMlDQbx",
        "outputId": "1531f4a8-777f-46c4-e145-fcf2c4610ea7"
      },
      "source": [
        "# DA BIG MAN SCALED 3 BUCKETS normalized\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man_scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier(normalize=True, alpha=1.1, solver='sparse_cg')\n",
        "clf.fit(X_train, y_train)\n",
        "n_predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45585015811238144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyZUZJtt9hh-",
        "outputId": "53e23606-9bf0-40a3-c4cb-e1080d8eb94d"
      },
      "source": [
        "# DA BIG MAN SCALED 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man_scaled, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.4963e-83): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43420092434930674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edYz-7TYCwB5",
        "outputId": "0b58fc38-1e5b-445c-c84a-34d57186dd55"
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.45      0.45      1456\n",
            "           1       0.42      0.41      0.42      1402\n",
            "           2       0.43      0.44      0.44      1253\n",
            "\n",
            "    accuracy                           0.43      4111\n",
            "   macro avg       0.43      0.43      0.43      4111\n",
            "weighted avg       0.43      0.43      0.43      4111\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gBZHRFDcNOL",
        "outputId": "79fb70e9-0509-4fd3-b1dd-81239ae6d122"
      },
      "source": [
        "# DA BIG MAN PCT SCALED 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4286061785453661"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx92iAvB0LZk"
      },
      "source": [
        "# BERNOULLI 🤫"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D_lO7ycvUoX",
        "outputId": "65e55ef5-8de7-4fa7-8031-a3e31a218e0d"
      },
      "source": [
        "# GENIUS : 10 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "#clf.fit(X_train, y_train)\n",
        "#predictions = clf.predict(X_test)\n",
        "#num_score = clf.score(X_test, y_test)\n",
        "#num_score\n",
        "clf.fit(gxtrain, g10train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g10test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1996798719487795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnWaVTy1vZ6N",
        "outputId": "10762c61-d356-40d0-9a1b-d15792a686da"
      },
      "source": [
        "# GENIUS : 6 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "#clf.fit(X_train, y_train)\n",
        "#predictions = clf.predict(X_test)\n",
        "#num_score = clf.score(X_test, y_test)\n",
        "#num_score\n",
        "clf.fit(gxtrain, g6train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g6test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18687474989995997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir9PnVLavc-u",
        "outputId": "bb2878b6-f76c-4a88-861c-f49772e2e7bc"
      },
      "source": [
        "# GENIUS : 3 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "#clf.fit(X_train, y_train)\n",
        "#predictions = clf.predict(X_test)\n",
        "#num_score = clf.score(X_test, y_test)\n",
        "#num_score\n",
        "clf.fit(gxtrain, g3train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g3test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3637454981992797"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5noR-XQN0f6D",
        "outputId": "43651bdc-4046-4bfb-f7ec-bd22cb7e9775"
      },
      "source": [
        "# THE REAL ONE: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33763074677693994"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDG3R67D_nlS",
        "outputId": "f8b36fd2-c7c0-4cdc-e9b8-8c0fefde0189"
      },
      "source": [
        "# THE REAL SCALED: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3463877402091948"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq215QHZ172y",
        "outputId": "ae334012-43a3-45f0-9094-ae021abc4727"
      },
      "source": [
        "# THE REAL ONE: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2087083434687424"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiGn3jRX_rBQ",
        "outputId": "12720a5a-7073-417d-d193-ebed279969fd"
      },
      "source": [
        "# THE REAL ONE SCALED: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21503283872537096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svbUoXTn2AF3",
        "outputId": "48d85928-9adf-4d8e-cc23-b38ed856bb0a"
      },
      "source": [
        "# THE REAL ONE: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3755777183167113"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2zbJzr5_utv",
        "outputId": "1300083b-3714-4431-8f1e-fa7a04e2e090"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.380442714667964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H2JrE822Dww",
        "outputId": "0c00236f-ee6b-4b4a-8ca6-91ef43b85b2c"
      },
      "source": [
        "# DA BIG MAN: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22476283142787642"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4XWTq0I2JvH",
        "outputId": "d840ad1f-c5c7-495e-84da-7ab196350a1b"
      },
      "source": [
        "# DA BIG MAN: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19654585259061055"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvnNblLa2NND",
        "outputId": "1758bdbb-0942-4018-b6da-9bceed746c36"
      },
      "source": [
        "# DA BIG MAN: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39771345171491124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9jb16Di9s_T",
        "outputId": "5a629fa0-c515-4e70-b9a5-37c686b6d867"
      },
      "source": [
        "# DA BIG MAN PCT SCALED : 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39747020189734855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHpPs5bzcbir",
        "outputId": "6778d672-aeea-4c1b-9e22-ed7ebcdb8abc"
      },
      "source": [
        "# DA BIG MAN PCT SCALED : 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19630260277304792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVSN--PgceK2",
        "outputId": "481aa86e-36e3-4447-80cc-41c1eed9b3dd"
      },
      "source": [
        "# DA BIG MAN PCT SCALED : 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22500608124543905"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih_XPn4lcTkE"
      },
      "source": [
        "# DA BIG MAN SCALED : 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewz_dryz9jfb",
        "outputId": "65e4cc21-9acf-452f-d3a7-577eaafb3c93"
      },
      "source": [
        "# TRANSFORMING TO 250 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3943079542690343"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_gQV1Zy9z1R",
        "outputId": "4d40b6c2-1f6e-41a4-afd4-b07110d513e6"
      },
      "source": [
        "# TRANSFORMING TO 250 FEATURES: da big scaled man 3 buckets\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(scaled_big_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3626854779858915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld9U5c6scnoD",
        "outputId": "3b78bf4b-cde2-4a62-ba1d-f43a11b61d71"
      },
      "source": [
        "# TRANSFORMING TO 250 FEATURES: da big pct scaled man 3 buckets\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(pct_scaled_big_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39795670153247387"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9UR2ywG9iZU",
        "outputId": "65610bac-0aea-498e-df5c-fea5a89d0205"
      },
      "source": [
        "# TRANSFORMING TO 275 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=275, random_state=0)\n",
        "X_transformed275 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed275, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39479445390415957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NZ7lLPy-LNb",
        "outputId": "908d3ff6-ebee-4cc0-84dc-8171c0885dc1"
      },
      "source": [
        "# TRANSFORMING TO 275 FEATURES: da big man scaled 3 buckets\n",
        "transformer = FastICA(n_components=275, random_state=0)\n",
        "X_transformed275 = transformer.fit_transform(scaled_big_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed275, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3626854779858915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCLqGmGK_5oo",
        "outputId": "f537d8b8-ce87-4fb7-e95e-9d514714137b"
      },
      "source": [
        "# TRANSFORMING TO 290 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=290, random_state=0)\n",
        "X_transformed290 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed290, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3960107029919728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOhLamIyAWqV",
        "outputId": "ce6bf484-43dc-499c-ab68-64d3e5c34012"
      },
      "source": [
        "# TRANSFORMING TO 295 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=295, random_state=0)\n",
        "X_transformed295 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed295, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39528095353928483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5rZ-teY_ZJV",
        "outputId": "025f77c3-29b1-4510-9090-559b64ba7cb9"
      },
      "source": [
        "# TRANSFORMING TO 300 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=300, random_state=0)\n",
        "X_transformed300 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed300, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38214546339090244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnRI-iVO2a3w"
      },
      "source": [
        "# GAUSSIAN 😇"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvuXrYRlvjc_",
        "outputId": "024315cc-b570-4960-ab63-c4e4dae4a16f"
      },
      "source": [
        "# GENIUS: 10 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "#clf.fit(X_train, y_train)\n",
        "#predictions = clf.predict(X_test)\n",
        "#num_score = clf.score(X_test, y_test)\n",
        "#num_score\n",
        "clf.fit(gxtrain, g10train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g10test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015606242496998799"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU4hhJ1fvoNp",
        "outputId": "f5cec74c-2e19-4bbe-be17-e86961a47a40"
      },
      "source": [
        "# GENIUS: 6 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "#clf.fit(X_train, y_train)\n",
        "#predictions = clf.predict(X_test)\n",
        "#num_score = clf.score(X_test, y_test)\n",
        "#num_score\n",
        "clf.fit(gxtrain, g6train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g6test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17286914765906364"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRyNBEk7vrCL",
        "outputId": "3a00b295-dd4e-4cb5-8119-f3edc3fba36d"
      },
      "source": [
        "# GENIUS: 3 BUCKETS\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "#clf.fit(X_train, y_train)\n",
        "#predictions = clf.predict(X_test)\n",
        "#num_score = clf.score(X_test, y_test)\n",
        "#num_score\n",
        "clf.fit(gxtrain, g3train)\n",
        "clf.predict(gxtest)\n",
        "clf.score(gxtest, g3test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3133253301320528"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFTOrjHJ336Q",
        "outputId": "7099990b-a941-4d54-e18c-46f55f10067a"
      },
      "source": [
        "# THE REAL ONE: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009486742884942837"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YXtkVlj_06u",
        "outputId": "ff42f282-bea2-4600-e891-3d8c7f403d95"
      },
      "source": [
        "# THE REAL ONE SCALED: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0581367063974702"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvI1F7Ro4KN6",
        "outputId": "fa5ca83e-ab39-4e75-cd69-a5d3a0a9b698"
      },
      "source": [
        "# THE REAL ONE: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17684261736803697"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akLbPJBF_3pu",
        "outputId": "35447713-a85b-48be-aac0-94399d188428"
      },
      "source": [
        "# THE REAL ONE SCALED: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24616881537338847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT7amPgg4TFv",
        "outputId": "925c7181-0fb8-4c7c-d3b1-af996cb5043b"
      },
      "source": [
        "# THE REAL ONE: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(real, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31598151301386523"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvWd2HJ3_61z",
        "outputId": "ddb33390-8a56-497f-fb58-a88a5c89e27f"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4254439309170518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwotpL5p4Xp2",
        "outputId": "1e8f6f0b-7268-4527-9a53-54ac2ab65619"
      },
      "source": [
        "# DA BIG MAN: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01070299197275602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCWPUpP64br1",
        "outputId": "beef6a77-a288-435f-e58b-0eab94b10d3d"
      },
      "source": [
        "# DA BIG MAN: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17684261736803697"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6ZeG5mT4e9e",
        "outputId": "481b5c24-3199-4a81-f75b-095a8317c539"
      },
      "source": [
        "# DA BIG MAN: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(da_big_man, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3673072245195816"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQoachAH-oDU",
        "outputId": "0c66b383-bcfc-4f98-80fd-a2bdf29cb1e7"
      },
      "source": [
        "# DA BIG MAN SCALED: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3626854779858915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHQobsbJC8DY",
        "outputId": "7b11244a-49db-46a2-da68-0a9abb032453"
      },
      "source": [
        "# DA BIG MAN PCT SCALED: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36682072488445633"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6aU3PJTA5aC",
        "outputId": "928d0ef4-318d-48d7-ed83-bb1ee7838417"
      },
      "source": [
        "# TRANSFORMING TO 250 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3891997081002189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYBG01Zp-swP",
        "outputId": "4da46c77-16e8-45b2-9e8a-0060e438961b"
      },
      "source": [
        "# TRANSFORMING TO 250 FEATURES: da big man scaled 3 buckets\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(scaled_big_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3626854779858915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZctI_usBJEA",
        "outputId": "37e0e5e4-5daa-456d-ca3b-c47a8dc48879"
      },
      "source": [
        "# TRANSFORMING TO 300 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=300, random_state=0)\n",
        "X_transformed300 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed300, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38214546339090244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "godaaXpF_SGh",
        "outputId": "cebcaff1-51d2-4c48-de9e-72b71b5464f5"
      },
      "source": [
        "# TRANSFORMING TO 300 FEATURES: da big man scaled 3 buckets\n",
        "transformer = FastICA(n_components=300, random_state=0)\n",
        "X_transformed300 = transformer.fit_transform(scaled_big_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed300, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3626854779858915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm96Q-EqBiGp",
        "outputId": "e5461f1a-445b-4f76-ed25-aab8527a73bc"
      },
      "source": [
        "# TRANSFORMING TO 275 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=275, random_state=0)\n",
        "X_transformed275 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed275, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3816589637557772"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmPsBTJVB7hR",
        "outputId": "a406eb0d-fd2b-430a-ec6f-6196a3fe3f93"
      },
      "source": [
        "# TRANSFORMING TO 225 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=225, random_state=0)\n",
        "X_transformed225 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed225, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3889564582826563"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGpO0PsmDCwW",
        "outputId": "44121866-756f-4c22-e998-88690d7cd30b"
      },
      "source": [
        "# TRANSFORMING TO 225 FEATURES: da big man pct scaled 3 buckets\n",
        "transformer = FastICA(n_components=225, random_state=0)\n",
        "X_transformed225 = transformer.fit_transform(pct_scaled_big_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed225, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3969837022622233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2elGJoaDYVV",
        "outputId": "80aff8b5-f6d1-4c93-801b-92b91f1ba6f0"
      },
      "source": [
        "# TRANSFORMING TO 300 FEATURES: da big man pct scaled 3 buckets\n",
        "transformer = FastICA(n_components=300, random_state=0)\n",
        "X_transformed225 = transformer.fit_transform(pct_scaled_big_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed225, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39114570664072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_LLhy-FDxRj",
        "outputId": "ce75443b-6a93-4268-87d1-8142af7bbc53"
      },
      "source": [
        "# TRANSFORMING TO 275 FEATURES: da big man pct scaled 3 buckets\n",
        "transformer = FastICA(n_components=275, random_state=0)\n",
        "X_transformed225 = transformer.fit_transform(pct_scaled_big_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed225, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39333495499878374"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j08XIgyw_sPK",
        "outputId": "e5d6e520-2b67-44e7-c428-0f89b41b0e3b"
      },
      "source": [
        "# TRANSFORMING TO 225 FEATURES: da big man scaled 3 buckets\n",
        "transformer = FastICA(n_components=225, random_state=0)\n",
        "X_transformed225 = transformer.fit_transform(scaled_big_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed225, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3626854779858915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNWxj_y15o1s"
      },
      "source": [
        "# MULTINOMIAL 😂"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYREb-4Wvvhe",
        "outputId": "057c13b2-4c69-416c-c653-3af6f1b9b796"
      },
      "source": [
        "# GENIUS: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0056022408963585435"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_tOFKbjv1F0",
        "outputId": "e41a5d09-5e8a-4e5b-8e7d-6d7d2955eddc"
      },
      "source": [
        "# GENIUS: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13005202080832334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHBKXL4Vv4pi",
        "outputId": "53d13d82-9974-4c77-cd1c-5deddcd18ccd"
      },
      "source": [
        "# GENIUS: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29851940776310526"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHZAhdvk50RT",
        "outputId": "19553faa-c037-4846-bab1-062fac59447f"
      },
      "source": [
        "# THE REAL ONE SCALED: 10 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1797616151787886"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR6HIfMdgLn3",
        "outputId": "04b4f507-20c2-4110-d539-a69e08eb208a"
      },
      "source": [
        "# THE REAL ONE SCALED: 6 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22938457796156653"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLUj6S_EgPFc",
        "outputId": "6aaac10f-d24a-42c7-d76c-c1b1c3e09ca1"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(y, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "num_score = clf.score(X_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40282169788372657"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H599mf_9WBnM"
      },
      "source": [
        "# FAST ICA 😶‍🌫️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR8RZso9wQUL",
        "outputId": "f936fe82-d897-4e5d-98b0-ba7d6b22d7e1"
      },
      "source": [
        "# TRANSFORMING TO 500 FEATURES: genius 10 buckets \n",
        "transformer = FastICA(n_components=500, random_state=0)\n",
        "X_transformed = transformer.fit_transform(genius)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed, genius_scores['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35294117647058826"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVNlHvIRxOEl",
        "outputId": "a8e53ae5-1f25-485f-c339-19b34c96f75f"
      },
      "source": [
        "# TRANSFORMING TO 700 FEATURES: genius 10 buckets \n",
        "transformer = FastICA(n_components=700, random_state=0)\n",
        "X_transformed = transformer.fit_transform(genius)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed, genius_scores['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35294117647058826"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgKsqOqeyXAL",
        "outputId": "29ecc325-8229-4172-882f-075cc1c85dfa"
      },
      "source": [
        "# TRANSFORMING TO 700 FEATURES: genius 10 buckets \n",
        "transformer = FastICA(n_components=700, random_state=0)\n",
        "X_transformed = transformer.fit_transform(genius)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed, genius_scores['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35334133653461386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBSHoqwf0IUM",
        "outputId": "f623be12-9673-45f8-e28d-655a5d50d38e"
      },
      "source": [
        "# TRANSFORMING TO 800 FEATURES: genius 10 buckets \n",
        "transformer = FastICA(n_components=800, random_state=0)\n",
        "X_transformed = transformer.fit_transform(genius)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed, genius_scores['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35334133653461386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7BekQq01iIw",
        "outputId": "5d142847-4a1c-4ed1-ab51-ab1b415b8a92"
      },
      "source": [
        "# TRANSFORMING TO 600 FEATURES: genius 10 buckets \n",
        "transformer = FastICA(n_components=600, random_state=0)\n",
        "X_transformed = transformer.fit_transform(genius)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed, genius_scores['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35334133653461386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O50ee6nx2a8a",
        "outputId": "bb06e1b9-0de5-45ce-bcae-0fe0b5372930"
      },
      "source": [
        "# TRANSFORMING TO 600 FEATURES: genius 10 buckets \n",
        "transformer = FastICA(n_components=600, random_state=0)\n",
        "X_transformed = transformer.fit_transform(genius)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed, genius_scores['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0196078431372549"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2kcIvRy3UIp",
        "outputId": "ad4547b0-5bee-4b33-b4a5-07c21e5aad34"
      },
      "source": [
        "# TRANSFORMING TO 600 FEATURES: genius 3 buckets \n",
        "transformer = FastICA(n_components=600, random_state=0)\n",
        "X_transformed = transformer.fit_transform(genius)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2933173269307723"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhEOfuh1Qgj_",
        "outputId": "b8b8bf95-36f9-44d0-cad4-fa57602ba758"
      },
      "source": [
        "#ha = pd.read_csv('DA_BIG_MAN_GENIUS_PCT_MINMAX.csv')\n",
        "ha.loc[27]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pitchfork_id                     48.000000\n",
              "popularity                       63.000000\n",
              "total_tracks                     98.643717\n",
              "release_year                    100.000000\n",
              "artist0_popularity               75.000000\n",
              "                                   ...    \n",
              "track19_lyric_happy_score         0.000000\n",
              "track19_lyric_surprise_score      0.000000\n",
              "track19_lyric_sad_score           0.000000\n",
              "track19_lyric_angry_score         0.000000\n",
              "track19_lyric_fear_score          0.000000\n",
              "Name: 27, Length: 862, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gc_udETtS6U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "id": "d8QXhQYYs7FO",
        "outputId": "cadfdaa3-5284-4201-d1ca-b5ac37d64e47"
      },
      "source": [
        "with pd.option_context('display.max_columns', 40000):\n",
        "    display(new_genius[(new_genius > 1E10).any(axis=1)].loc[:,(new_genius > 1E10).any(axis=0)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfhfcb4iVfnm",
        "outputId": "5a55d27d-33ad-4da0-9cac-ac13ae4dcb5e"
      },
      "source": [
        "new_genius.loc[27]['tracks_others']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pitchfork_id                     48.000000\n",
              "popularity                       63.000000\n",
              "total_tracks                     98.643717\n",
              "release_year                    100.000000\n",
              "artist0_popularity               75.000000\n",
              "                                   ...    \n",
              "track19_lyric_happy_score         0.000000\n",
              "track19_lyric_surprise_score      0.000000\n",
              "track19_lyric_sad_score           0.000000\n",
              "track19_lyric_angry_score         0.000000\n",
              "track19_lyric_fear_score          0.000000\n",
              "Name: 27, Length: 862, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oc5lJ1Zr7Rg"
      },
      "source": [
        "new_genius = pd.read_csv('DA_BIG_MAN_GENIUS_PCT_MINMAX.csv')\n",
        "new_big_x = pd.read_csv('DA_BIG_MAN_MINMAXED_PCT.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqwYGQa6OZm2"
      },
      "source": [
        "lol = pd.read_csv('GENIUS_X_TRAIN.csv')\n",
        "lol\n",
        "lmao = pd.read_csv('GENIUS_REGRESSION_Y_TRAIN.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfDOv8d94JQ4",
        "outputId": "5bba23f1-5dd4-4e95-bb0c-de9cfd50b156"
      },
      "source": [
        "# TRANSFORMING TO 700 FEATURES: genius 3 buckets \n",
        "transformer = FastICA(n_components=700, random_state=0)\n",
        "X_transformed = transformer.fit_transform(genius)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2933173269307723"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olt5kACzhz9X"
      },
      "source": [
        "da_big_man_x = pd.read_csv('DA_BIG_MAN.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "2wz9xZ9gh7z_",
        "outputId": "4aa022db-51c7-483a-f3b6-b6edd0a5941d"
      },
      "source": [
        "da_big_man_x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_followers</th>\n",
              "      <th>track0_dur_min</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_min</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>track2_dur_min</th>\n",
              "      <th>...</th>\n",
              "      <th>track13_feat_artist1_followers</th>\n",
              "      <th>track13_feat_artist2_popularity</th>\n",
              "      <th>track13_feat_artist2_followers</th>\n",
              "      <th>track14_feat_artist0_popularity</th>\n",
              "      <th>track14_feat_artist0_followers</th>\n",
              "      <th>track14_feat_artist1_popularity</th>\n",
              "      <th>track14_feat_artist1_followers</th>\n",
              "      <th>track14_feat_artist2_popularity</th>\n",
              "      <th>track14_feat_artist2_followers</th>\n",
              "      <th>track15_feat_artist0_popularity</th>\n",
              "      <th>track15_feat_artist0_followers</th>\n",
              "      <th>track15_feat_artist1_popularity</th>\n",
              "      <th>track15_feat_artist1_followers</th>\n",
              "      <th>track15_feat_artist2_popularity</th>\n",
              "      <th>track15_feat_artist2_followers</th>\n",
              "      <th>track16_feat_artist0_popularity</th>\n",
              "      <th>track16_feat_artist0_followers</th>\n",
              "      <th>track16_feat_artist1_popularity</th>\n",
              "      <th>track16_feat_artist1_followers</th>\n",
              "      <th>track16_feat_artist2_popularity</th>\n",
              "      <th>track16_feat_artist2_followers</th>\n",
              "      <th>track17_feat_artist0_popularity</th>\n",
              "      <th>track17_feat_artist0_followers</th>\n",
              "      <th>track17_feat_artist1_popularity</th>\n",
              "      <th>track17_feat_artist1_followers</th>\n",
              "      <th>track17_feat_artist2_popularity</th>\n",
              "      <th>track17_feat_artist2_followers</th>\n",
              "      <th>track18_feat_artist0_popularity</th>\n",
              "      <th>track18_feat_artist0_followers</th>\n",
              "      <th>track18_feat_artist1_popularity</th>\n",
              "      <th>track18_feat_artist1_followers</th>\n",
              "      <th>track18_feat_artist2_popularity</th>\n",
              "      <th>track18_feat_artist2_followers</th>\n",
              "      <th>track19_feat_artist0_popularity</th>\n",
              "      <th>track19_feat_artist0_followers</th>\n",
              "      <th>track19_feat_artist1_popularity</th>\n",
              "      <th>track19_feat_artist1_followers</th>\n",
              "      <th>track19_feat_artist2_popularity</th>\n",
              "      <th>track19_feat_artist2_followers</th>\n",
              "      <th>label_albums_reviewed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "      <td>2021</td>\n",
              "      <td>18</td>\n",
              "      <td>34.568080</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.833433</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90000</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.10</td>\n",
              "      <td>72.044934</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>119.406</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.9</td>\n",
              "      <td>4.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10000</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.37</td>\n",
              "      <td>70.090808</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>141.560</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>4.166667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>17</td>\n",
              "      <td>2021</td>\n",
              "      <td>69</td>\n",
              "      <td>65.899789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.402050</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34000</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.54</td>\n",
              "      <td>79.341449</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>96.973</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.8</td>\n",
              "      <td>5.224483</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30000</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.82</td>\n",
              "      <td>76.608098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>69.304</td>\n",
              "      <td>3.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>3.795200</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>52</td>\n",
              "      <td>2021</td>\n",
              "      <td>50</td>\n",
              "      <td>53.356644</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.316083</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60000</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>66.70</td>\n",
              "      <td>67.463578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>119.817</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.1</td>\n",
              "      <td>6.983333</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80000</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.10</td>\n",
              "      <td>76.315510</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>179.937</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>6.916183</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>2021</td>\n",
              "      <td>57</td>\n",
              "      <td>64.963270</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.945900</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00000</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.37</td>\n",
              "      <td>75.415005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>107.970</td>\n",
              "      <td>4.0</td>\n",
              "      <td>44.3</td>\n",
              "      <td>4.570550</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20000</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.89</td>\n",
              "      <td>76.674803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>160.015</td>\n",
              "      <td>4.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>4.305250</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>2020</td>\n",
              "      <td>68</td>\n",
              "      <td>73.539939</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.694367</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66000</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>41.70</td>\n",
              "      <td>78.628928</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>165.037</td>\n",
              "      <td>3.0</td>\n",
              "      <td>90.5</td>\n",
              "      <td>5.132817</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37000</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>34.30</td>\n",
              "      <td>76.370086</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>138.016</td>\n",
              "      <td>4.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>4.958417</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>1999</td>\n",
              "      <td>50</td>\n",
              "      <td>65.836051</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.524883</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>1.80000</td>\n",
              "      <td>44.5</td>\n",
              "      <td>53.7</td>\n",
              "      <td>88.400000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.60</td>\n",
              "      <td>73.841396</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.64</td>\n",
              "      <td>75.655</td>\n",
              "      <td>4.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>4.882883</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1.62000</td>\n",
              "      <td>58.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>75.900000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.50</td>\n",
              "      <td>73.175871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.17</td>\n",
              "      <td>154.323</td>\n",
              "      <td>4.0</td>\n",
              "      <td>67.10</td>\n",
              "      <td>4.816667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>56</td>\n",
              "      <td>17</td>\n",
              "      <td>1999</td>\n",
              "      <td>67</td>\n",
              "      <td>73.009415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.560000</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60000</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.33</td>\n",
              "      <td>78.580416</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>93.653</td>\n",
              "      <td>4.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>4.714667</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28000</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.70</td>\n",
              "      <td>81.556327</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>73.604</td>\n",
              "      <td>4.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>4.330000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>1999</td>\n",
              "      <td>56</td>\n",
              "      <td>67.489890</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.677333</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0.01470</td>\n",
              "      <td>20.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>24.200000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>29.10</td>\n",
              "      <td>82.331004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.89</td>\n",
              "      <td>84.700</td>\n",
              "      <td>4.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>5.731550</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>0.00135</td>\n",
              "      <td>26.4</td>\n",
              "      <td>81.2</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.62</td>\n",
              "      <td>82.393160</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>94.095</td>\n",
              "      <td>4.0</td>\n",
              "      <td>45.80</td>\n",
              "      <td>5.373333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1999</td>\n",
              "      <td>17</td>\n",
              "      <td>42.978684</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.004217</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00678</td>\n",
              "      <td>56.7</td>\n",
              "      <td>72.2</td>\n",
              "      <td>4.740000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.00</td>\n",
              "      <td>75.048133</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.47</td>\n",
              "      <td>116.134</td>\n",
              "      <td>4.0</td>\n",
              "      <td>37.4</td>\n",
              "      <td>4.580433</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.08220</td>\n",
              "      <td>39.0</td>\n",
              "      <td>83.5</td>\n",
              "      <td>1.370000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>79.112533</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.40</td>\n",
              "      <td>157.071</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.20</td>\n",
              "      <td>4.470000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>38</td>\n",
              "      <td>15</td>\n",
              "      <td>1999</td>\n",
              "      <td>44</td>\n",
              "      <td>62.155438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97000</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.80</td>\n",
              "      <td>80.746782</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>130.341</td>\n",
              "      <td>4.0</td>\n",
              "      <td>48.6</td>\n",
              "      <td>4.751550</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20000</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.60</td>\n",
              "      <td>73.579128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>110.315</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>4.290667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 520 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  ...  label_albums_reviewed\n",
              "0              25  ...                      1\n",
              "1              69  ...                      2\n",
              "2              44  ...                     21\n",
              "3              43  ...                     64\n",
              "4              60  ...                      1\n",
              "...           ...  ...                    ...\n",
              "16437          31  ...                    204\n",
              "16438          56  ...                     71\n",
              "16439          57  ...                    103\n",
              "16440           5  ...                      4\n",
              "16441          38  ...                    275\n",
              "\n",
              "[16442 rows x 520 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "N2ifVrdyiikt",
        "outputId": "602a8742-884c-45b3-85a2-eb21fef3ea2a"
      },
      "source": [
        "real = pd.read_csv('THE_REAL_ONE.csv')\n",
        "real = real.drop('pitchfork_id', axis=1)\n",
        "regression_full_y = real['score']\n",
        "regression_full_y.to_csv('REGRESSION_FULL_Y.csv', index=False)\n",
        "real = real.drop(['rounded_score', 'score'], axis=1)\n",
        "real"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>album_duration_minutes</th>\n",
              "      <th>year</th>\n",
              "      <th>min_loudness</th>\n",
              "      <th>max_loudness</th>\n",
              "      <th>mean_loudness</th>\n",
              "      <th>stddev_loudness</th>\n",
              "      <th>label_frequency</th>\n",
              "      <th>mean_duration</th>\n",
              "      <th>min_valence</th>\n",
              "      <th>max_valence</th>\n",
              "      <th>stddev_valence</th>\n",
              "      <th>mean_valence</th>\n",
              "      <th>weighted_avg_valence</th>\n",
              "      <th>weighted_avg_speechiness</th>\n",
              "      <th>med_liveness</th>\n",
              "      <th>stddev_liveness</th>\n",
              "      <th>stddev_instrumentalness</th>\n",
              "      <th>weighted_avg_instrumentalness</th>\n",
              "      <th>explicit</th>\n",
              "      <th>weighted_avg_energy</th>\n",
              "      <th>min_danceability</th>\n",
              "      <th>max_danceability</th>\n",
              "      <th>mean_danceability</th>\n",
              "      <th>stddev_danceability</th>\n",
              "      <th>mean_acousticness</th>\n",
              "      <th>stddev_acousticness</th>\n",
              "      <th>med_acousticness</th>\n",
              "      <th>min_popularity</th>\n",
              "      <th>max_popularity</th>\n",
              "      <th>mean_popularity</th>\n",
              "      <th>stddev_popularity</th>\n",
              "      <th>key_0_pct</th>\n",
              "      <th>key_1_pct</th>\n",
              "      <th>key_2_pct</th>\n",
              "      <th>key_3_pct</th>\n",
              "      <th>key_4_pct</th>\n",
              "      <th>key_5_pct</th>\n",
              "      <th>key_6_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>sig_5_pct</th>\n",
              "      <th>num_artists</th>\n",
              "      <th>num_features</th>\n",
              "      <th>artist_popularity_mean</th>\n",
              "      <th>artist_followers_mean</th>\n",
              "      <th>artist_popularity_min</th>\n",
              "      <th>artist_popularity_max</th>\n",
              "      <th>artist_followers_min</th>\n",
              "      <th>artist_followers_max</th>\n",
              "      <th>artist_popularity_stddev</th>\n",
              "      <th>artist_followers_stddev</th>\n",
              "      <th>mean_feat_artist_popularity</th>\n",
              "      <th>mean_feat_artist_followers</th>\n",
              "      <th>min_feat_artist_popularity</th>\n",
              "      <th>min_feat_artist_followers</th>\n",
              "      <th>max_feat_artist_popularity</th>\n",
              "      <th>max_feat_artist_followers</th>\n",
              "      <th>stddev_feat_artist_popularity</th>\n",
              "      <th>stddev_feat_artist_followers</th>\n",
              "      <th>genre_0_pct</th>\n",
              "      <th>genre_1_pct</th>\n",
              "      <th>genre_2_pct</th>\n",
              "      <th>genre_3_pct</th>\n",
              "      <th>genre_4_pct</th>\n",
              "      <th>genre_5_pct</th>\n",
              "      <th>genre_6_pct</th>\n",
              "      <th>genre_7_pct</th>\n",
              "      <th>genre_8_pct</th>\n",
              "      <th>genre_9_pct</th>\n",
              "      <th>genre_10_pct</th>\n",
              "      <th>genre_11_pct</th>\n",
              "      <th>genre_12_pct</th>\n",
              "      <th>genre_13_pct</th>\n",
              "      <th>genre_14_pct</th>\n",
              "      <th>genre_15_pct</th>\n",
              "      <th>genre_16_pct</th>\n",
              "      <th>genre_17_pct</th>\n",
              "      <th>genre_18_pct</th>\n",
              "      <th>genre_19_pct</th>\n",
              "      <th>genre_20_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "      <td>37.699950</td>\n",
              "      <td>2021</td>\n",
              "      <td>8.695784</td>\n",
              "      <td>77.746616</td>\n",
              "      <td>71.966860</td>\n",
              "      <td>2.468588</td>\n",
              "      <td>1</td>\n",
              "      <td>3.769995</td>\n",
              "      <td>52.09</td>\n",
              "      <td>55.6</td>\n",
              "      <td>15.025998</td>\n",
              "      <td>18.476000</td>\n",
              "      <td>16.069549</td>\n",
              "      <td>3.524631</td>\n",
              "      <td>9.575</td>\n",
              "      <td>5.812945</td>\n",
              "      <td>30.604008</td>\n",
              "      <td>22.075199</td>\n",
              "      <td>0</td>\n",
              "      <td>22.089854</td>\n",
              "      <td>39.40</td>\n",
              "      <td>63.3</td>\n",
              "      <td>45.330000</td>\n",
              "      <td>10.642582</td>\n",
              "      <td>76.730000</td>\n",
              "      <td>76.730000</td>\n",
              "      <td>81.6500</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>12.800000</td>\n",
              "      <td>2.699794</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18.0</td>\n",
              "      <td>538.0</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>538</td>\n",
              "      <td>538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.776000e+03</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1776.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1776.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>17</td>\n",
              "      <td>53.442883</td>\n",
              "      <td>2021</td>\n",
              "      <td>5.087701</td>\n",
              "      <td>81.197035</td>\n",
              "      <td>78.453161</td>\n",
              "      <td>1.668215</td>\n",
              "      <td>2</td>\n",
              "      <td>3.143699</td>\n",
              "      <td>75.31</td>\n",
              "      <td>82.5</td>\n",
              "      <td>20.156995</td>\n",
              "      <td>43.517059</td>\n",
              "      <td>43.974797</td>\n",
              "      <td>26.145333</td>\n",
              "      <td>11.200</td>\n",
              "      <td>10.004012</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.000364</td>\n",
              "      <td>1</td>\n",
              "      <td>55.135105</td>\n",
              "      <td>45.40</td>\n",
              "      <td>87.3</td>\n",
              "      <td>75.317647</td>\n",
              "      <td>12.166976</td>\n",
              "      <td>12.456412</td>\n",
              "      <td>12.456412</td>\n",
              "      <td>6.9500</td>\n",
              "      <td>33</td>\n",
              "      <td>72</td>\n",
              "      <td>40.941176</td>\n",
              "      <td>8.989373</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>41.176471</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>69.0</td>\n",
              "      <td>161226.0</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>161226</td>\n",
              "      <td>161226</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.230769</td>\n",
              "      <td>4.329135e+06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>54616704.0</td>\n",
              "      <td>20.753128</td>\n",
              "      <td>1.511468e+07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.117647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>52</td>\n",
              "      <td>215.010783</td>\n",
              "      <td>2021</td>\n",
              "      <td>27.651865</td>\n",
              "      <td>77.851220</td>\n",
              "      <td>67.206191</td>\n",
              "      <td>7.829765</td>\n",
              "      <td>21</td>\n",
              "      <td>4.300216</td>\n",
              "      <td>83.92</td>\n",
              "      <td>87.1</td>\n",
              "      <td>21.225589</td>\n",
              "      <td>29.830000</td>\n",
              "      <td>28.973155</td>\n",
              "      <td>9.620623</td>\n",
              "      <td>11.250</td>\n",
              "      <td>13.873995</td>\n",
              "      <td>32.165156</td>\n",
              "      <td>68.565822</td>\n",
              "      <td>0</td>\n",
              "      <td>31.134999</td>\n",
              "      <td>72.37</td>\n",
              "      <td>81.6</td>\n",
              "      <td>44.774600</td>\n",
              "      <td>19.179167</td>\n",
              "      <td>84.409600</td>\n",
              "      <td>84.409600</td>\n",
              "      <td>93.0000</td>\n",
              "      <td>13</td>\n",
              "      <td>34</td>\n",
              "      <td>18.960000</td>\n",
              "      <td>4.936164</td>\n",
              "      <td>13.461538</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>...</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>50.0</td>\n",
              "      <td>16453.0</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>16453</td>\n",
              "      <td>16453</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>2.673500e+03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>849.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>4498.0</td>\n",
              "      <td>11.313708</td>\n",
              "      <td>2.580233e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>9.615385</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>5.769231</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>1.923077</td>\n",
              "      <td>9.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>40.477500</td>\n",
              "      <td>2021</td>\n",
              "      <td>5.084669</td>\n",
              "      <td>79.579461</td>\n",
              "      <td>76.552764</td>\n",
              "      <td>1.577898</td>\n",
              "      <td>64</td>\n",
              "      <td>3.373125</td>\n",
              "      <td>73.80</td>\n",
              "      <td>96.7</td>\n",
              "      <td>23.668895</td>\n",
              "      <td>72.475000</td>\n",
              "      <td>74.175735</td>\n",
              "      <td>6.567317</td>\n",
              "      <td>9.125</td>\n",
              "      <td>13.549375</td>\n",
              "      <td>24.003436</td>\n",
              "      <td>18.619665</td>\n",
              "      <td>0</td>\n",
              "      <td>61.188227</td>\n",
              "      <td>51.50</td>\n",
              "      <td>87.9</td>\n",
              "      <td>69.800000</td>\n",
              "      <td>16.594961</td>\n",
              "      <td>28.157500</td>\n",
              "      <td>28.157500</td>\n",
              "      <td>16.4000</td>\n",
              "      <td>24</td>\n",
              "      <td>36</td>\n",
              "      <td>28.583333</td>\n",
              "      <td>3.824760</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>135966.0</td>\n",
              "      <td>57</td>\n",
              "      <td>57</td>\n",
              "      <td>135966</td>\n",
              "      <td>135966</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>41.823017</td>\n",
              "      <td>2020</td>\n",
              "      <td>16.084775</td>\n",
              "      <td>81.914103</td>\n",
              "      <td>78.010248</td>\n",
              "      <td>4.848596</td>\n",
              "      <td>1</td>\n",
              "      <td>4.182302</td>\n",
              "      <td>71.90</td>\n",
              "      <td>90.5</td>\n",
              "      <td>28.487900</td>\n",
              "      <td>58.760000</td>\n",
              "      <td>59.015377</td>\n",
              "      <td>6.562235</td>\n",
              "      <td>32.850</td>\n",
              "      <td>17.877847</td>\n",
              "      <td>33.922389</td>\n",
              "      <td>31.894178</td>\n",
              "      <td>1</td>\n",
              "      <td>74.673965</td>\n",
              "      <td>28.00</td>\n",
              "      <td>65.5</td>\n",
              "      <td>54.750000</td>\n",
              "      <td>9.336577</td>\n",
              "      <td>9.097215</td>\n",
              "      <td>9.097215</td>\n",
              "      <td>4.4200</td>\n",
              "      <td>41</td>\n",
              "      <td>53</td>\n",
              "      <td>46.500000</td>\n",
              "      <td>4.169999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>647390.0</td>\n",
              "      <td>68</td>\n",
              "      <td>68</td>\n",
              "      <td>647390</td>\n",
              "      <td>647390</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>30.473300</td>\n",
              "      <td>1999</td>\n",
              "      <td>7.487531</td>\n",
              "      <td>75.086033</td>\n",
              "      <td>71.995339</td>\n",
              "      <td>2.927091</td>\n",
              "      <td>204</td>\n",
              "      <td>4.353329</td>\n",
              "      <td>69.50</td>\n",
              "      <td>76.3</td>\n",
              "      <td>24.618199</td>\n",
              "      <td>41.728571</td>\n",
              "      <td>42.058227</td>\n",
              "      <td>6.142869</td>\n",
              "      <td>12.600</td>\n",
              "      <td>7.080754</td>\n",
              "      <td>30.172104</td>\n",
              "      <td>73.998741</td>\n",
              "      <td>0</td>\n",
              "      <td>70.294207</td>\n",
              "      <td>27.20</td>\n",
              "      <td>58.2</td>\n",
              "      <td>43.728571</td>\n",
              "      <td>9.774067</td>\n",
              "      <td>22.448286</td>\n",
              "      <td>22.448286</td>\n",
              "      <td>3.6000</td>\n",
              "      <td>8</td>\n",
              "      <td>35</td>\n",
              "      <td>12.571429</td>\n",
              "      <td>9.947481</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.857143</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>159367.0</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>159367</td>\n",
              "      <td>159367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>56</td>\n",
              "      <td>17</td>\n",
              "      <td>60.331483</td>\n",
              "      <td>1999</td>\n",
              "      <td>85.660143</td>\n",
              "      <td>85.660143</td>\n",
              "      <td>75.658814</td>\n",
              "      <td>19.957987</td>\n",
              "      <td>71</td>\n",
              "      <td>3.548911</td>\n",
              "      <td>83.90</td>\n",
              "      <td>83.9</td>\n",
              "      <td>24.398101</td>\n",
              "      <td>43.188235</td>\n",
              "      <td>46.731975</td>\n",
              "      <td>3.583291</td>\n",
              "      <td>10.700</td>\n",
              "      <td>11.592671</td>\n",
              "      <td>15.440686</td>\n",
              "      <td>6.035377</td>\n",
              "      <td>0</td>\n",
              "      <td>64.086232</td>\n",
              "      <td>69.20</td>\n",
              "      <td>69.2</td>\n",
              "      <td>47.223529</td>\n",
              "      <td>16.006777</td>\n",
              "      <td>23.552353</td>\n",
              "      <td>23.552353</td>\n",
              "      <td>7.0800</td>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>32.294118</td>\n",
              "      <td>10.941690</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>35.294118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>587819.0</td>\n",
              "      <td>67</td>\n",
              "      <td>67</td>\n",
              "      <td>587819</td>\n",
              "      <td>587819</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>17.647059</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.411765</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.882353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.764706</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>46.941517</td>\n",
              "      <td>1999</td>\n",
              "      <td>2.516562</td>\n",
              "      <td>82.393160</td>\n",
              "      <td>81.402908</td>\n",
              "      <td>0.907825</td>\n",
              "      <td>103</td>\n",
              "      <td>4.694152</td>\n",
              "      <td>72.40</td>\n",
              "      <td>93.3</td>\n",
              "      <td>20.468502</td>\n",
              "      <td>52.920000</td>\n",
              "      <td>50.707482</td>\n",
              "      <td>3.270570</td>\n",
              "      <td>18.100</td>\n",
              "      <td>8.463656</td>\n",
              "      <td>29.561014</td>\n",
              "      <td>40.199373</td>\n",
              "      <td>0</td>\n",
              "      <td>76.314037</td>\n",
              "      <td>32.60</td>\n",
              "      <td>50.6</td>\n",
              "      <td>32.270000</td>\n",
              "      <td>10.564095</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>0.0163</td>\n",
              "      <td>34</td>\n",
              "      <td>57</td>\n",
              "      <td>40.600000</td>\n",
              "      <td>6.736303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>215321.0</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>215321</td>\n",
              "      <td>215321</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>44.758833</td>\n",
              "      <td>1999</td>\n",
              "      <td>5.199885</td>\n",
              "      <td>79.112533</td>\n",
              "      <td>76.730010</td>\n",
              "      <td>1.729905</td>\n",
              "      <td>4</td>\n",
              "      <td>3.729903</td>\n",
              "      <td>67.50</td>\n",
              "      <td>97.2</td>\n",
              "      <td>24.716151</td>\n",
              "      <td>57.091667</td>\n",
              "      <td>55.815206</td>\n",
              "      <td>5.762615</td>\n",
              "      <td>20.800</td>\n",
              "      <td>14.893113</td>\n",
              "      <td>36.689485</td>\n",
              "      <td>28.698280</td>\n",
              "      <td>0</td>\n",
              "      <td>73.804939</td>\n",
              "      <td>43.10</td>\n",
              "      <td>60.4</td>\n",
              "      <td>44.516667</td>\n",
              "      <td>12.546411</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.185167</td>\n",
              "      <td>0.0525</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.984732</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2489.0</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>2489</td>\n",
              "      <td>2489</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>38</td>\n",
              "      <td>15</td>\n",
              "      <td>48.525733</td>\n",
              "      <td>1999</td>\n",
              "      <td>7.299547</td>\n",
              "      <td>80.878674</td>\n",
              "      <td>78.544538</td>\n",
              "      <td>1.980301</td>\n",
              "      <td>275</td>\n",
              "      <td>3.235049</td>\n",
              "      <td>78.16</td>\n",
              "      <td>85.7</td>\n",
              "      <td>20.413301</td>\n",
              "      <td>40.322667</td>\n",
              "      <td>39.695422</td>\n",
              "      <td>4.885491</td>\n",
              "      <td>10.800</td>\n",
              "      <td>4.095428</td>\n",
              "      <td>24.524718</td>\n",
              "      <td>8.230068</td>\n",
              "      <td>0</td>\n",
              "      <td>75.332988</td>\n",
              "      <td>32.70</td>\n",
              "      <td>56.2</td>\n",
              "      <td>39.920000</td>\n",
              "      <td>7.972381</td>\n",
              "      <td>3.075563</td>\n",
              "      <td>3.075563</td>\n",
              "      <td>0.1380</td>\n",
              "      <td>10</td>\n",
              "      <td>41</td>\n",
              "      <td>15.466667</td>\n",
              "      <td>7.670599</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>81574.0</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>81574</td>\n",
              "      <td>81574</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 90 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  total_tracks  ...  genre_19_pct  genre_20_pct\n",
              "0              25            10  ...     10.000000      0.000000\n",
              "1              69            17  ...      0.000000      0.000000\n",
              "2              44            52  ...      1.923077      9.615385\n",
              "3              43            12  ...      0.000000      0.000000\n",
              "4              60            10  ...      0.000000      0.000000\n",
              "...           ...           ...  ...           ...           ...\n",
              "16437          31             7  ...     14.285714      0.000000\n",
              "16438          56            17  ...     11.764706      0.000000\n",
              "16439          57            10  ...      0.000000      0.000000\n",
              "16440           5            12  ...      0.000000      0.000000\n",
              "16441          38            15  ...      0.000000      0.000000\n",
              "\n",
              "[16442 rows x 90 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q0WsYO4NMmB",
        "outputId": "310fd402-1795-4c0e-c9c9-bb30cf4845a5"
      },
      "source": [
        "da_big_man"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_followers</th>\n",
              "      <th>track0_dur_min</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_min</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>track2_dur_min</th>\n",
              "      <th>...</th>\n",
              "      <th>track13_feat_artist1_followers</th>\n",
              "      <th>track13_feat_artist2_popularity</th>\n",
              "      <th>track13_feat_artist2_followers</th>\n",
              "      <th>track14_feat_artist0_popularity</th>\n",
              "      <th>track14_feat_artist0_followers</th>\n",
              "      <th>track14_feat_artist1_popularity</th>\n",
              "      <th>track14_feat_artist1_followers</th>\n",
              "      <th>track14_feat_artist2_popularity</th>\n",
              "      <th>track14_feat_artist2_followers</th>\n",
              "      <th>track15_feat_artist0_popularity</th>\n",
              "      <th>track15_feat_artist0_followers</th>\n",
              "      <th>track15_feat_artist1_popularity</th>\n",
              "      <th>track15_feat_artist1_followers</th>\n",
              "      <th>track15_feat_artist2_popularity</th>\n",
              "      <th>track15_feat_artist2_followers</th>\n",
              "      <th>track16_feat_artist0_popularity</th>\n",
              "      <th>track16_feat_artist0_followers</th>\n",
              "      <th>track16_feat_artist1_popularity</th>\n",
              "      <th>track16_feat_artist1_followers</th>\n",
              "      <th>track16_feat_artist2_popularity</th>\n",
              "      <th>track16_feat_artist2_followers</th>\n",
              "      <th>track17_feat_artist0_popularity</th>\n",
              "      <th>track17_feat_artist0_followers</th>\n",
              "      <th>track17_feat_artist1_popularity</th>\n",
              "      <th>track17_feat_artist1_followers</th>\n",
              "      <th>track17_feat_artist2_popularity</th>\n",
              "      <th>track17_feat_artist2_followers</th>\n",
              "      <th>track18_feat_artist0_popularity</th>\n",
              "      <th>track18_feat_artist0_followers</th>\n",
              "      <th>track18_feat_artist1_popularity</th>\n",
              "      <th>track18_feat_artist1_followers</th>\n",
              "      <th>track18_feat_artist2_popularity</th>\n",
              "      <th>track18_feat_artist2_followers</th>\n",
              "      <th>track19_feat_artist0_popularity</th>\n",
              "      <th>track19_feat_artist0_followers</th>\n",
              "      <th>track19_feat_artist1_popularity</th>\n",
              "      <th>track19_feat_artist1_followers</th>\n",
              "      <th>track19_feat_artist2_popularity</th>\n",
              "      <th>track19_feat_artist2_followers</th>\n",
              "      <th>label_albums_reviewed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "      <td>2021</td>\n",
              "      <td>18</td>\n",
              "      <td>34.568080</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.833433</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90000</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.10</td>\n",
              "      <td>72.044934</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>119.406</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.9</td>\n",
              "      <td>4.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10000</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.37</td>\n",
              "      <td>70.090808</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>141.560</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>4.166667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>17</td>\n",
              "      <td>2021</td>\n",
              "      <td>69</td>\n",
              "      <td>65.899789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.402050</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34000</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.54</td>\n",
              "      <td>79.341449</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>96.973</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.8</td>\n",
              "      <td>5.224483</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30000</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.82</td>\n",
              "      <td>76.608098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>69.304</td>\n",
              "      <td>3.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>3.795200</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>52</td>\n",
              "      <td>2021</td>\n",
              "      <td>50</td>\n",
              "      <td>53.356644</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.316083</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60000</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>66.70</td>\n",
              "      <td>67.463578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>119.817</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.1</td>\n",
              "      <td>6.983333</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80000</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.10</td>\n",
              "      <td>76.315510</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>179.937</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>6.916183</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>2021</td>\n",
              "      <td>57</td>\n",
              "      <td>64.963270</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.945900</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00000</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.37</td>\n",
              "      <td>75.415005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>107.970</td>\n",
              "      <td>4.0</td>\n",
              "      <td>44.3</td>\n",
              "      <td>4.570550</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20000</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.89</td>\n",
              "      <td>76.674803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>160.015</td>\n",
              "      <td>4.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>4.305250</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>2020</td>\n",
              "      <td>68</td>\n",
              "      <td>73.539939</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.694367</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66000</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>41.70</td>\n",
              "      <td>78.628928</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>165.037</td>\n",
              "      <td>3.0</td>\n",
              "      <td>90.5</td>\n",
              "      <td>5.132817</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37000</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>34.30</td>\n",
              "      <td>76.370086</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>138.016</td>\n",
              "      <td>4.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>4.958417</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>1999</td>\n",
              "      <td>50</td>\n",
              "      <td>65.836051</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.524883</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>1.80000</td>\n",
              "      <td>44.5</td>\n",
              "      <td>53.7</td>\n",
              "      <td>88.400000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.60</td>\n",
              "      <td>73.841396</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.64</td>\n",
              "      <td>75.655</td>\n",
              "      <td>4.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>4.882883</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1.62000</td>\n",
              "      <td>58.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>75.900000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.50</td>\n",
              "      <td>73.175871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.17</td>\n",
              "      <td>154.323</td>\n",
              "      <td>4.0</td>\n",
              "      <td>67.10</td>\n",
              "      <td>4.816667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>56</td>\n",
              "      <td>17</td>\n",
              "      <td>1999</td>\n",
              "      <td>67</td>\n",
              "      <td>73.009415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.560000</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60000</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.33</td>\n",
              "      <td>78.580416</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>93.653</td>\n",
              "      <td>4.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>4.714667</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28000</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.70</td>\n",
              "      <td>81.556327</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>73.604</td>\n",
              "      <td>4.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>4.330000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>1999</td>\n",
              "      <td>56</td>\n",
              "      <td>67.489890</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.677333</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0.01470</td>\n",
              "      <td>20.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>24.200000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>29.10</td>\n",
              "      <td>82.331004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.89</td>\n",
              "      <td>84.700</td>\n",
              "      <td>4.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>5.731550</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>0.00135</td>\n",
              "      <td>26.4</td>\n",
              "      <td>81.2</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.62</td>\n",
              "      <td>82.393160</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>94.095</td>\n",
              "      <td>4.0</td>\n",
              "      <td>45.80</td>\n",
              "      <td>5.373333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1999</td>\n",
              "      <td>17</td>\n",
              "      <td>42.978684</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.004217</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00678</td>\n",
              "      <td>56.7</td>\n",
              "      <td>72.2</td>\n",
              "      <td>4.740000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.00</td>\n",
              "      <td>75.048133</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.47</td>\n",
              "      <td>116.134</td>\n",
              "      <td>4.0</td>\n",
              "      <td>37.4</td>\n",
              "      <td>4.580433</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.08220</td>\n",
              "      <td>39.0</td>\n",
              "      <td>83.5</td>\n",
              "      <td>1.370000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>79.112533</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.40</td>\n",
              "      <td>157.071</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.20</td>\n",
              "      <td>4.470000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>38</td>\n",
              "      <td>15</td>\n",
              "      <td>1999</td>\n",
              "      <td>44</td>\n",
              "      <td>62.155438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97000</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.80</td>\n",
              "      <td>80.746782</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>130.341</td>\n",
              "      <td>4.0</td>\n",
              "      <td>48.6</td>\n",
              "      <td>4.751550</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20000</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.60</td>\n",
              "      <td>73.579128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>110.315</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>4.290667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 520 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  ...  label_albums_reviewed\n",
              "0              25  ...                      1\n",
              "1              69  ...                      2\n",
              "2              44  ...                     21\n",
              "3              43  ...                     64\n",
              "4              60  ...                      1\n",
              "...           ...  ...                    ...\n",
              "16437          31  ...                    204\n",
              "16438          56  ...                     71\n",
              "16439          57  ...                    103\n",
              "16440           5  ...                      4\n",
              "16441          38  ...                    275\n",
              "\n",
              "[16442 rows x 520 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luJrh3q2hWq7",
        "outputId": "9cff268b-9a44-4f39-c0d5-e605193e0d9f"
      },
      "source": [
        "# TRANSFORMING TO 75 FEATURES: the real one 10 buckets \n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3862807102894673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FCstjDuAm25",
        "outputId": "511e6281-df1c-4e5a-b671-183e60ee1fb4"
      },
      "source": [
        "# TRANSFORMING TO 75 FEATURES: the real one scaled 10 buckets \n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.385794210654342"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6rKTsyDp8kF"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLkOdj3iqrjQ",
        "outputId": "a2008421-5fcd-4b0d-c2b6-e52838a45343"
      },
      "source": [
        "# TRANSFORMING TO 50 FEATURES: the real one 10 buckets\n",
        "transformer = FastICA(n_components=50, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.385794210654342"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehDekUAuA9b5",
        "outputId": "6dbdb702-1106-4b86-f7b1-e4e9e95e3cea"
      },
      "source": [
        "# TRANSFORMING TO 50 FEATURES: the real one scaled 10 buckets\n",
        "transformer = FastICA(n_components=50, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38336171247871564"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tb--xoGqCSW"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoaghqJurIDF",
        "outputId": "cc844a83-b56f-4ef8-9cf8-5c6222ee684d"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: the real one 10 buckets\n",
        "transformer = FastICA(n_components=80, random_state=0)\n",
        "X_transformed80 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed80, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38725370955971783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um9ZB8feBM0w",
        "outputId": "fe2ca1c4-bb89-407e-b6b6-d320adc828d9"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: the real one scaled 10 buckets\n",
        "transformer = FastICA(n_components=80, random_state=0)\n",
        "X_transformed80 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed80, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38749695937728046"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfe1fI7ZqC3e"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUVmxGqdrZVu",
        "outputId": "93a82415-7ab2-4a8f-dcad-f249ecd6f65d"
      },
      "source": [
        "# TRANSFORMING TO 60 FEATURES: the real one 10 buckets\n",
        "transformer = FastICA(n_components=60, random_state=0)\n",
        "X_transformed60 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed60, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38676720992459257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LD-0eWGBRWZ",
        "outputId": "e97b4ef0-cdba-45b5-dc4a-ef3faa972811"
      },
      "source": [
        "# TRANSFORMING TO 60 FEATURES: the real one scaled 10 buckets\n",
        "transformer = FastICA(n_components=60, random_state=0)\n",
        "X_transformed60 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed60, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38530771101921674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeE8rX0jqDWg"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwIOD2L7rkvC",
        "outputId": "471a784e-37b2-4dc3-9a54-fb7edd370f44"
      },
      "source": [
        "# TRANSFORMING TO 55 FEATURES: the real one 10 buckets\n",
        "transformer = FastICA(n_components=55, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed55, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38725370955971783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEwHQugoBV6G",
        "outputId": "88d2155b-ae1a-4273-dee4-59719929850d"
      },
      "source": [
        "# TRANSFORMING TO 55 FEATURES: the real one scaled 10 buckets\n",
        "transformer = FastICA(n_components=55, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed55, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3850644612016541"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1QGjg8QqD_H"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WEpXtnrt141",
        "outputId": "2f68084c-ee30-41f5-8665-f3086657529d"
      },
      "source": [
        "# TRANSFORMING TO 55 FEATURES: the real one 6 buckets\n",
        "transformer = FastICA(n_components=55, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed55, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2245195816103138"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78dg8z9bBaDp",
        "outputId": "50f6853e-c491-45b7-f4e2-951fee7a6548"
      },
      "source": [
        "# TRANSFORMING TO 55 FEATURES: the real one scaled 6 buckets\n",
        "transformer = FastICA(n_components=55, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed55, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22378983215762588"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1ffin7eqFNx"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSM1BaL10QfK",
        "outputId": "d2d2db46-51ea-4663-c804-1b8f21ad2ba9"
      },
      "source": [
        "# TRANSFORMING TO 75 FEATURES: the real one 6 buckets\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed75 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed75, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2286548285088786"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DYHunS1BdoA",
        "outputId": "4218cb20-ebeb-4eeb-f01c-1d1f1d09c359"
      },
      "source": [
        "# TRANSFORMING TO 75 FEATURES: the real one scaled 6 buckets\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed75 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed75, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2332765750425687"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-i0sbqYqFsv"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFS4ZlBRt4wS",
        "outputId": "6c1a3254-dc49-49a1-92bd-53cf43866645"
      },
      "source": [
        "# TRANSFORMING TO 55 FEATURES: the real one 3 buckets\n",
        "transformer = FastICA(n_components=55, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed55, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4483094137679397"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5Rh95vfBi6p",
        "outputId": "42e02f58-eefb-4f41-d300-72c02b9b2533"
      },
      "source": [
        "# TRANSFORMING TO 55 FEATURES: the real one scaled 3 buckets\n",
        "transformer = FastICA(n_components=55, random_state=0)\n",
        "X_transformed55 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed55, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4412551690586232"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AepgFolWqGUq"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7wob9yVvBGn",
        "outputId": "a863b99c-71ea-4c58-a87d-810129365362"
      },
      "source": [
        "# TRANSFORMING TO 65 FEATURES: the real one 3 buckets\n",
        "transformer = FastICA(n_components=65, random_state=0)\n",
        "X_transformed65 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed65, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44757966431525176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lzPk-N7Bmy7",
        "outputId": "b00732fc-610f-42fc-af47-008f062e8e07"
      },
      "source": [
        "# TRANSFORMING TO 65 FEATURES: the real one scaled 3 buckets\n",
        "transformer = FastICA(n_components=65, random_state=0)\n",
        "X_transformed65 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed65, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44879591340306496"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzX0uTpiqG7u"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTJ6pJ9lSsO4",
        "outputId": "ee7a4327-4012-4f0e-bda9-4f617b103f23"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: the real one 3 buckets\n",
        "transformer = FastICA(n_components=80, random_state=0)\n",
        "X_transformed80 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed80, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4504986621260034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8KkPs0zBqYI",
        "outputId": "9f425dfd-5bc8-4025-ebca-6d7c2a5a0cae"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: the real one scaled 3 buckets\n",
        "transformer = FastICA(n_components=80, random_state=0)\n",
        "X_transformed80 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed80, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4509851617611287"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRSGxZAdCEkn",
        "outputId": "e3af228c-fa4f-4c2b-95db-8f39ebaf6127"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one scaled 3 buckets\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed80 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed80, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45268791048406715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8JAlcVICL-L",
        "outputId": "ae90af34-c8af-48bb-dfdd-601feb115423"
      },
      "source": [
        "# TRANSFORMING TO 75 FEATURES: the real one scaled 3 buckets\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed80 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed80, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4502554123084408"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEuPgq9_vHJf",
        "outputId": "0a501386-6fc3-4d0d-f25e-43ea2ae4ea5a"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: the real one 3 buckets\n",
        "transformer = FastICA(n_components=80, random_state=0)\n",
        "X_transformed80 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed80, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4504986621260034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "4qywZFYGqHg0",
        "outputId": "fe281f45-335e-4052-e610-5fb6c5698945"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "-JXC6fzGrqQ-",
        "outputId": "358b9ed8-2fea-485c-a02e-3be3147762c2"
      },
      "source": [
        "confusion_matrix_metric(y_test, predictions, ['0', '1', '2'], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[758 545 153]\n",
            " [511 715 176]\n",
            " [394 480 379]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "ei2zSvvpuN6b",
        "outputId": "ee4cc0b4-c592-4384-d26e-03b733fb8aa7"
      },
      "source": [
        "classification_scores(predictions, y_test, ['0', '1', '2'], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.52      0.49      1456\n",
            "           1       0.41      0.51      0.46      1402\n",
            "           2       0.54      0.30      0.39      1253\n",
            "\n",
            "    accuracy                           0.45      4111\n",
            "   macro avg       0.47      0.44      0.44      4111\n",
            "weighted avg       0.46      0.45      0.45      4111\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.46      0.52      0.49      1456\\n           1       0.41      0.51      0.46      1402\\n           2       0.54      0.30      0.39      1253\\n\\n    accuracy                           0.45      4111\\n   macro avg       0.47      0.44      0.44      4111\\nweighted avg       0.46      0.45      0.45      4111\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt4jpxrFvQWR",
        "outputId": "4297c230-f620-4eb0-f2ae-0d5fb532b60c"
      },
      "source": [
        "# TRANSFORMING TO 75 FEATURES: the real one 3 buckets\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed75 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed75, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4492824130381902"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtZ6QvoUqIIK"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EpjiqNZvmgz",
        "outputId": "baca63f5-35c8-4242-d8da-6f73a4f4aab1"
      },
      "source": [
        "# TRANSFORMING TO 250 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4397956701532474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp8qBBH3qIxZ"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ALcZbmMwOMx",
        "outputId": "11af14fd-6a85-4f13-9925-4dd91a00e001"
      },
      "source": [
        "# TRANSFORMING TO 300 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=300, random_state=0)\n",
        "X_transformed300 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed300, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4368766723424957"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gwpT-0UqJWB"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4GgrDDsNi_f",
        "outputId": "9b46d54b-3126-4190-cbd4-cb476f4e3219"
      },
      "source": [
        "da_big_man"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_followers</th>\n",
              "      <th>track0_dur_min</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_min</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>track2_dur_min</th>\n",
              "      <th>...</th>\n",
              "      <th>track13_feat_artist1_followers</th>\n",
              "      <th>track13_feat_artist2_popularity</th>\n",
              "      <th>track13_feat_artist2_followers</th>\n",
              "      <th>track14_feat_artist0_popularity</th>\n",
              "      <th>track14_feat_artist0_followers</th>\n",
              "      <th>track14_feat_artist1_popularity</th>\n",
              "      <th>track14_feat_artist1_followers</th>\n",
              "      <th>track14_feat_artist2_popularity</th>\n",
              "      <th>track14_feat_artist2_followers</th>\n",
              "      <th>track15_feat_artist0_popularity</th>\n",
              "      <th>track15_feat_artist0_followers</th>\n",
              "      <th>track15_feat_artist1_popularity</th>\n",
              "      <th>track15_feat_artist1_followers</th>\n",
              "      <th>track15_feat_artist2_popularity</th>\n",
              "      <th>track15_feat_artist2_followers</th>\n",
              "      <th>track16_feat_artist0_popularity</th>\n",
              "      <th>track16_feat_artist0_followers</th>\n",
              "      <th>track16_feat_artist1_popularity</th>\n",
              "      <th>track16_feat_artist1_followers</th>\n",
              "      <th>track16_feat_artist2_popularity</th>\n",
              "      <th>track16_feat_artist2_followers</th>\n",
              "      <th>track17_feat_artist0_popularity</th>\n",
              "      <th>track17_feat_artist0_followers</th>\n",
              "      <th>track17_feat_artist1_popularity</th>\n",
              "      <th>track17_feat_artist1_followers</th>\n",
              "      <th>track17_feat_artist2_popularity</th>\n",
              "      <th>track17_feat_artist2_followers</th>\n",
              "      <th>track18_feat_artist0_popularity</th>\n",
              "      <th>track18_feat_artist0_followers</th>\n",
              "      <th>track18_feat_artist1_popularity</th>\n",
              "      <th>track18_feat_artist1_followers</th>\n",
              "      <th>track18_feat_artist2_popularity</th>\n",
              "      <th>track18_feat_artist2_followers</th>\n",
              "      <th>track19_feat_artist0_popularity</th>\n",
              "      <th>track19_feat_artist0_followers</th>\n",
              "      <th>track19_feat_artist1_popularity</th>\n",
              "      <th>track19_feat_artist1_followers</th>\n",
              "      <th>track19_feat_artist2_popularity</th>\n",
              "      <th>track19_feat_artist2_followers</th>\n",
              "      <th>label_albums_reviewed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "      <td>2021</td>\n",
              "      <td>18</td>\n",
              "      <td>34.568080</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.833433</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>77.90000</td>\n",
              "      <td>50.4</td>\n",
              "      <td>22.6</td>\n",
              "      <td>43.200000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>11.10</td>\n",
              "      <td>72.044934</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>119.406</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.9</td>\n",
              "      <td>4.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>87.10000</td>\n",
              "      <td>47.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.37</td>\n",
              "      <td>70.090808</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>141.560</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.42</td>\n",
              "      <td>4.166667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>17</td>\n",
              "      <td>2021</td>\n",
              "      <td>69</td>\n",
              "      <td>65.899789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.402050</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0.34000</td>\n",
              "      <td>75.6</td>\n",
              "      <td>57.7</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.54</td>\n",
              "      <td>79.341449</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.80</td>\n",
              "      <td>96.973</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.8</td>\n",
              "      <td>5.224483</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>77.30000</td>\n",
              "      <td>41.9</td>\n",
              "      <td>70.3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.82</td>\n",
              "      <td>76.608098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.50</td>\n",
              "      <td>69.304</td>\n",
              "      <td>3.0</td>\n",
              "      <td>59.90</td>\n",
              "      <td>3.795200</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>52</td>\n",
              "      <td>2021</td>\n",
              "      <td>50</td>\n",
              "      <td>53.356644</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.316083</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>92.60000</td>\n",
              "      <td>40.4</td>\n",
              "      <td>54.7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>66.70</td>\n",
              "      <td>67.463578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.40</td>\n",
              "      <td>119.817</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.1</td>\n",
              "      <td>6.983333</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>91.80000</td>\n",
              "      <td>40.6</td>\n",
              "      <td>47.6</td>\n",
              "      <td>90.800000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.10</td>\n",
              "      <td>76.315510</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.35</td>\n",
              "      <td>179.937</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.70</td>\n",
              "      <td>6.916183</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>2021</td>\n",
              "      <td>57</td>\n",
              "      <td>64.963270</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.945900</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>21.00000</td>\n",
              "      <td>87.9</td>\n",
              "      <td>49.5</td>\n",
              "      <td>2.690000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.37</td>\n",
              "      <td>75.415005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.03</td>\n",
              "      <td>107.970</td>\n",
              "      <td>4.0</td>\n",
              "      <td>44.3</td>\n",
              "      <td>4.570550</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>24.20000</td>\n",
              "      <td>68.2</td>\n",
              "      <td>83.8</td>\n",
              "      <td>39.700000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.89</td>\n",
              "      <td>76.674803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.39</td>\n",
              "      <td>160.015</td>\n",
              "      <td>4.0</td>\n",
              "      <td>83.00</td>\n",
              "      <td>4.305250</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>2020</td>\n",
              "      <td>68</td>\n",
              "      <td>73.539939</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.694367</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>4.66000</td>\n",
              "      <td>63.8</td>\n",
              "      <td>83.1</td>\n",
              "      <td>3.040000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>41.70</td>\n",
              "      <td>78.628928</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>165.037</td>\n",
              "      <td>3.0</td>\n",
              "      <td>90.5</td>\n",
              "      <td>5.132817</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>4.37000</td>\n",
              "      <td>54.4</td>\n",
              "      <td>33.8</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>34.30</td>\n",
              "      <td>76.370086</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.86</td>\n",
              "      <td>138.016</td>\n",
              "      <td>4.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>4.958417</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>1999</td>\n",
              "      <td>50</td>\n",
              "      <td>65.836051</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.524883</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>1.80000</td>\n",
              "      <td>44.5</td>\n",
              "      <td>53.7</td>\n",
              "      <td>88.400000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.60</td>\n",
              "      <td>73.841396</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.64</td>\n",
              "      <td>75.655</td>\n",
              "      <td>4.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>4.882883</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1.62000</td>\n",
              "      <td>58.2</td>\n",
              "      <td>63.2</td>\n",
              "      <td>75.900000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.50</td>\n",
              "      <td>73.175871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.17</td>\n",
              "      <td>154.323</td>\n",
              "      <td>4.0</td>\n",
              "      <td>67.10</td>\n",
              "      <td>4.816667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>56</td>\n",
              "      <td>17</td>\n",
              "      <td>1999</td>\n",
              "      <td>67</td>\n",
              "      <td>73.009415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.560000</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>30.60000</td>\n",
              "      <td>54.0</td>\n",
              "      <td>42.2</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.33</td>\n",
              "      <td>78.580416</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>93.653</td>\n",
              "      <td>4.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>4.714667</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>6.28000</td>\n",
              "      <td>37.6</td>\n",
              "      <td>53.7</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.70</td>\n",
              "      <td>81.556327</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.72</td>\n",
              "      <td>73.604</td>\n",
              "      <td>4.0</td>\n",
              "      <td>34.90</td>\n",
              "      <td>4.330000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>1999</td>\n",
              "      <td>56</td>\n",
              "      <td>67.489890</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.677333</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0.01470</td>\n",
              "      <td>20.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>24.200000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>29.10</td>\n",
              "      <td>82.331004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.89</td>\n",
              "      <td>84.700</td>\n",
              "      <td>4.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>5.731550</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>0.00135</td>\n",
              "      <td>26.4</td>\n",
              "      <td>81.2</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.62</td>\n",
              "      <td>82.393160</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>94.095</td>\n",
              "      <td>4.0</td>\n",
              "      <td>45.80</td>\n",
              "      <td>5.373333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1999</td>\n",
              "      <td>17</td>\n",
              "      <td>42.978684</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.004217</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00678</td>\n",
              "      <td>56.7</td>\n",
              "      <td>72.2</td>\n",
              "      <td>4.740000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.00</td>\n",
              "      <td>75.048133</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.47</td>\n",
              "      <td>116.134</td>\n",
              "      <td>4.0</td>\n",
              "      <td>37.4</td>\n",
              "      <td>4.580433</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.08220</td>\n",
              "      <td>39.0</td>\n",
              "      <td>83.5</td>\n",
              "      <td>1.370000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>79.112533</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.40</td>\n",
              "      <td>157.071</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.20</td>\n",
              "      <td>4.470000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>38</td>\n",
              "      <td>15</td>\n",
              "      <td>1999</td>\n",
              "      <td>44</td>\n",
              "      <td>62.155438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>3.97000</td>\n",
              "      <td>48.8</td>\n",
              "      <td>96.2</td>\n",
              "      <td>42.900000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.80</td>\n",
              "      <td>80.746782</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>130.341</td>\n",
              "      <td>4.0</td>\n",
              "      <td>48.6</td>\n",
              "      <td>4.751550</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>30.20000</td>\n",
              "      <td>40.5</td>\n",
              "      <td>38.4</td>\n",
              "      <td>0.494000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>13.60</td>\n",
              "      <td>73.579128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.13</td>\n",
              "      <td>110.315</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.54</td>\n",
              "      <td>4.290667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 520 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  ...  label_albums_reviewed\n",
              "0              25  ...                      1\n",
              "1              69  ...                      2\n",
              "2              44  ...                     21\n",
              "3              43  ...                     64\n",
              "4              60  ...                      1\n",
              "...           ...  ...                    ...\n",
              "16437          31  ...                    204\n",
              "16438          56  ...                     71\n",
              "16439          57  ...                    103\n",
              "16440           5  ...                      4\n",
              "16441          38  ...                    275\n",
              "\n",
              "[16442 rows x 520 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWEYOYGywoV5",
        "outputId": "b22c0032-ccae-4d00-dd6e-15b88aff6806"
      },
      "source": [
        "# TRANSFORMING TO 275 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=275, random_state=0)\n",
        "X_transformed275 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed275, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44149841887618585"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SCbAAl0UDGO",
        "outputId": "b7737b20-2c1a-42b4-c145-980ec68f66c8"
      },
      "source": [
        "# TRANSFORMING TO 250 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed275 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed275, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4397956701532474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQbDcUvSqJ6b"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtOW8w9cxg6-",
        "outputId": "db729a69-031e-4d70-9a4d-2628e4044853"
      },
      "source": [
        "# TRANSFORMING TO 280 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=280, random_state=0)\n",
        "X_transformed280 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed280, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44222816832887374"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Paa0sQFVqKbj"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbSX55Mtx7z2",
        "outputId": "126f75ff-32ed-4633-c12d-a23fbfe1f339"
      },
      "source": [
        "# TRANSFORMING TO 290 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=290, random_state=0)\n",
        "X_transformed290 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed290, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4407686694234979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYul07XlqK8w"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8AZM6LmyOFf",
        "outputId": "0386ff62-9433-4d07-d42f-dcddb17d51f0"
      },
      "source": [
        "# TRANSFORMING TO 285 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=285, random_state=0)\n",
        "X_transformed285 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed285, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4407686694234979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76-vCJn6qLef"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmuyG1JP0ayp",
        "outputId": "2faff189-41b6-4632-8372-41d6515ac33e"
      },
      "source": [
        "# TRANSFORMING TO 350 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=350, random_state=0)\n",
        "X_transformed350 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed350, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4388226708829968"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zKBfjJZS8fR",
        "outputId": "f75e3929-a668-4de0-a243-072c386870d8"
      },
      "source": [
        "# TRANSFORMING TO 400 FEATURES: da big man 3 buckets\n",
        "transformer = FastICA(n_components=400, random_state=0)\n",
        "X_transformed350 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed350, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4359036730722452"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46nBt_DIqMAA"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS6P9QMv01ns",
        "outputId": "a2963a53-6b13-47ae-965d-3cf0f3cd9577"
      },
      "source": [
        "# TRANSFORMING TO 250 FEATURES: da big man 10 buckets\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38846995864753103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-_gkZslqMft"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpgv0-N02XQ0",
        "outputId": "5a18d91f-93b6-4a6a-d74a-f980eab10d45"
      },
      "source": [
        "# TRANSFORMING TO 200 FEATURES: da big man 10 buckets\n",
        "transformer = FastICA(n_components=200, random_state=0)\n",
        "X_transformed200 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed200, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38530771101921674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJchFAxoqNBq"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpSgMqer2q-h",
        "outputId": "30d1281d-a68a-4300-b7bd-ca04db578b46"
      },
      "source": [
        "# TRANSFORMING TO 175 FEATURES: da big man 10 buckets\n",
        "transformer = FastICA(n_components=175, random_state=0)\n",
        "X_transformed175 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed175, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3848212113840915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhXbThc6TcCD",
        "outputId": "a280fdd8-06e4-4fb9-ca11-6c0526785562"
      },
      "source": [
        "# TRANSFORMING TO 400 FEATURES: da big man 10 buckets\n",
        "transformer = FastICA(n_components=400, random_state=0)\n",
        "X_transformed175 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed175, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3862807102894673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o62godEkqNkC"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vqLK4rR28NC",
        "outputId": "104ad931-9435-4f3a-eb84-cb6b16dc6a28"
      },
      "source": [
        "# TRANSFORMING TO 200 FEATURES: da big man 6 buckets\n",
        "transformer = FastICA(n_components=200, random_state=0)\n",
        "X_transformed200 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed200, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2325468255898808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2gBLjNuqOEo"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCSlnjYa78mj",
        "outputId": "cad2cc3f-ba61-4348-d1d7-8f0a2735fcd7"
      },
      "source": [
        "# THE REAL ONE PASSIVE AGGRESSIVE 50 FEATURES: the real one 10 BUCKETS\n",
        "transformer = FastICA(n_components=50, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2892240330819752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axJbqiSLCVd4",
        "outputId": "1719a791-269a-4dc9-f33f-6c1698319622"
      },
      "source": [
        "# THE REAL ONE PASSIVE AGGRESSIVE 50 FEATURES: the real one scaled 10 BUCKETS\n",
        "transformer = FastICA(n_components=50, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19703235222573584"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoXK7z3aqOlS"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfT_cUkRCZVF",
        "outputId": "2c4a0cf2-e7a0-411d-b2b6-63752beeeff9"
      },
      "source": [
        "# THE REAL ONE PASSIVE AGGRESSIVE 85 FEATURES: the real scaled one 3 BUCKETS\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40063244952566285"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-yhhLEghHB8",
        "outputId": "4ec3e36c-fd1a-4e2a-9cb8-03ef8ed85016"
      },
      "source": [
        "# THE REAL ONE PASSIVE AGGRESSIVE 75 FEATURES: the real scaled one 3 BUCKETS\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40257844806616394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5C9sfY-hKdR",
        "outputId": "e7c25dc7-a05c-40bc-eb67-06c34c3a0de6"
      },
      "source": [
        "# THE REAL ONE PASSIVE AGGRESSIVE 65 FEATURES: the real scaled one 3 BUCKETS\n",
        "transformer = FastICA(n_components=65, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40890294332279253"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Igl6WE7-g_07",
        "outputId": "da7f761d-d576-4930-b947-f04a75fe09e1"
      },
      "source": [
        "# THE REAL ONE PASSIVE AGGRESSIVE 50 FEATURES: the real scaled one 3 BUCKETS\n",
        "transformer = FastICA(n_components=50, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4324981756263683"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGqt4KS7hQ16",
        "outputId": "6f7235bc-1a99-4741-b3b8-b2217f9eda58"
      },
      "source": [
        "# THE REAL ONE PASSIVE AGGRESSIVE 40 FEATURES: the real scaled one 3 BUCKETS\n",
        "transformer = FastICA(n_components=40, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4033081975188519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHeqawol_pZ_",
        "outputId": "7cdea14d-91b6-4107-a41c-ab628d2c37ee"
      },
      "source": [
        "# THE REAL ONE PASSIVE AGGRESSIVE 50 FEATURES: the real one 3 BUCKETS\n",
        "transformer = FastICA(n_components=50, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4524446606665045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "MncYyxjhqPHJ",
        "outputId": "bc6f513a-b144-4c04-c9e6-4833310ad9b4"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "N3phqhTdsBkr",
        "outputId": "d76d1bd2-2817-4cdd-b4c7-90daf22e2ac4"
      },
      "source": [
        "confusion_matrix_metric(y_test, predictions, ['0', '1', '2'], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[758 545 153]\n",
            " [511 715 176]\n",
            " [394 480 379]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrXmMz1B_hAP",
        "outputId": "09e356f0-e7f1-498d-dbd8-ecc71acbc75d"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 250 FEATURES: 10 BUCKETS\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39260520554609585"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0XMGlV0UW-W",
        "outputId": "00ea37d2-f3ad-4116-e2c3-586057a13a23"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 350 FEATURES: 10 BUCKETS\n",
        "transformer = FastICA(n_components=3500, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:469: UserWarning: n_components is too large: it will be set to 520\n",
            "  % n_components\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38457796156652885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVNYhBsBqPnp"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-lyLPXxAs2R",
        "outputId": "e80ff525-cfb1-48dd-f6d1-0a066b85b355"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 250 FEATURES:3 BUCKETS\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3904159571880321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zPsQWbKVFev",
        "outputId": "b99ba4f7-8ec9-4371-db26-663e04640abf"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 350 FEATURES:3 BUCKETS\n",
        "transformer = FastICA(n_components=350, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3463877402091948"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TsAoyBuVrRP",
        "outputId": "65f3c292-f361-4c86-e334-938dc28e45f7"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 200 FEATURES:3 BUCKETS\n",
        "transformer = FastICA(n_components=200, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4008756993432255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC7b3g9XV5zz",
        "outputId": "cce4e12a-0b83-4507-d124-5f338bb4e7e5"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 150 FEATURES:3 BUCKETS\n",
        "transformer = FastICA(n_components=150, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44028216978837265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ff6h1RkWSVL",
        "outputId": "daca81bb-1e7f-4792-9027-caf2bb4bacff"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 125 FEATURES:3 BUCKETS\n",
        "transformer = FastICA(n_components=125, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.32644125516905864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJxbLQVCWDVj",
        "outputId": "c3a9b6f3-7e88-4483-a35d-c069108ea8f8"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 100 FEATURES:3 BUCKETS\n",
        "transformer = FastICA(n_components=100, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4001459498905376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-6jWLi7qQJZ"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xccwZZ-lAlP_",
        "outputId": "c9f50b1f-8466-4fa8-b565-4a2ff12bd79a"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 300 FEATURES: 10 BUCKETS\n",
        "transformer = FastICA(n_components=300, random_state=0)\n",
        "X_transformed300 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed300, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39357820481634637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4cqw445qQrJ"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qwC5NZ_CVAK",
        "outputId": "bf60c0b6-d849-43ac-afdd-b482e9631aa8"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 350 FEATURES: 10 BUCKETS\n",
        "transformer = FastICA(n_components=350, random_state=0)\n",
        "X_transformed350 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed350, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3653612259790805"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBzYBMqOqRLE"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rmidwkRC2LB",
        "outputId": "2cb98e3d-b635-4dff-956b-547830265574"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 275 FEATURES: 10 BUCKETS\n",
        "transformer = FastICA(n_components=275, random_state=0)\n",
        "X_transformed275 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed275, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39455120408659694"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcFaH_zlqRuz"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjRQlqsZC7ed",
        "outputId": "6ec6cc8d-122c-470d-e966-f775e32296f4"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 275 FEATURES: 10 BUCKETS\n",
        "transformer = FastICA(n_components=325, random_state=0)\n",
        "X_transformed325 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed325, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38676720992459257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyzzV73OqSUT"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilP77VKNDVCP",
        "outputId": "b8665fe0-17ef-4801-d853-30e90ab4dc46"
      },
      "source": [
        "# DA BIG MAN PASSIVE AGGRESSIVE 275 FEATURES: 3 BUCKETS\n",
        "transformer = FastICA(n_components=275, random_state=0)\n",
        "X_transformed275 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed275, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33325225006081244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkux9h3ZqS01"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JAeNHR0FX0F",
        "outputId": "cff9517c-7405-4ce7-9a9e-b59817d94ca0"
      },
      "source": [
        "# DA BIG MAN PERCEPTRON 275 FEATURES: 3 BUCKETS\n",
        "transformer = FastICA(n_components=275, random_state=0)\n",
        "X_transformed275 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed275, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38676720992459257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULtypCtqqTSy"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrKYDUE1Fz8H",
        "outputId": "1c451ccb-b272-4760-ed16-9366cd57b2b2"
      },
      "source": [
        "# DA BIG MAN PERCEPTRON 250 FEATURES: 3 BUCKETS\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed250 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed250, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30479202140598394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtFPHp3XqULo"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwesu1jFGDuI",
        "outputId": "e2ed7965-1f10-4472-8ffe-82b411d1694b"
      },
      "source": [
        "# DA BIG MAN PERCEPTRON 300 FEATURES: 3 BUCKETS\n",
        "transformer = FastICA(n_components=300, random_state=0)\n",
        "X_transformed300 = transformer.fit_transform(da_big_man_x)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed300, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3052785210411092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxqsnVUrqU79"
      },
      "source": [
        "graphMetrics(y_test, predictions, X_transformed_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sphs0dCACg6j",
        "outputId": "aa0f37af-fdc1-4177-e3e0-8f6bee6acf4a"
      },
      "source": [
        "# THE REAL ONE BERNOULLI 50 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=50, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4127949404037947"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeNk6irZC2Gf",
        "outputId": "1bb338af-bc22-46bb-f9bc-b39c31324de8"
      },
      "source": [
        "# THE REAL ONE BERNOULLI 75 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4247141814643639"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48o7b8ZwC7ZY",
        "outputId": "f9217d77-9664-45a0-cca8-814fc494d27b"
      },
      "source": [
        "# THE REAL ONE BERNOULLI 85 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43128192653855507"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHo6VDtpC_zz",
        "outputId": "68309dca-b7bf-43d7-d805-a314c5d98bb7"
      },
      "source": [
        "# THE REAL ONE BERNOULLI 90 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=90, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42301143274142544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kb467EtDUNN",
        "outputId": "074ab84f-404e-4df8-cb63-9305c443d1be"
      },
      "source": [
        "# THE REAL ONE BERNOULLI 75 FEATURES: the real one 3 BUCKETS\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43030892726830455"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hatCb4-3DY_P",
        "outputId": "3c9f38a6-4397-4d2c-c80e-57287554c75d"
      },
      "source": [
        "# THE REAL ONE BERNOULLI 85 FEATURES: the real one 3 BUCKETS\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42325468255898807"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLWdDlexDciN",
        "outputId": "fb810411-ab0c-4435-f92f-cc45eaf42064"
      },
      "source": [
        "# THE REAL ONE BERNOULLI 80 FEATURES: the real one 3 BUCKETS\n",
        "transformer = FastICA(n_components=80, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4220384334711749"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-JhkYS7DhHD",
        "outputId": "bca8353b-7d51-4928-9907-73ce8e37ce84"
      },
      "source": [
        "# THE REAL ONE BERNOULLI 65 FEATURES: the real one 3 BUCKETS\n",
        "transformer = FastICA(n_components=65, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42520068109948916"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VnAauaHDvZd",
        "outputId": "94432d3f-5172-4261-f026-48c3a6d921a2"
      },
      "source": [
        "# THE REAL ONE RIDGE CLASSIFIER 65 FEATURES: the real one 10 BUCKETS\n",
        "transformer = FastICA(n_components=65, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39552420335684746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r28bYxXRD6Il",
        "outputId": "3c30d125-4b69-4511-8e99-9c9f4af37abb"
      },
      "source": [
        "# THE REAL ONE RIDGE CLASSIFIER 75 FEATURES: the real one 10 BUCKETS\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39333495499878374"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7FySCQmZsLb",
        "outputId": "b572775a-7ce1-4c39-af17-fb474d918b68"
      },
      "source": [
        "# DA BIG MAN RIDGE CLASSIFIER 300 FEATURES: DA BIG MAN 3 BUCKETS\n",
        "transformer = FastICA(n_components=300, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4419849185113111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21C_JINzaS7z",
        "outputId": "88f2d2a0-ae0b-4062-967b-5775f79ad7ef"
      },
      "source": [
        "# DA BIG MAN RIDGE CLASSIFIER 375 FEATURES: DA BIG MAN 3 BUCKETS\n",
        "transformer = FastICA(n_components=375, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4366334225249331"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKaFpGtsa5tW",
        "outputId": "d9e93b90-4dae-4ed6-f893-1251bf220135"
      },
      "source": [
        "# DA BIG MAN RIDGE CLASSIFIER 250 FEATURES: DA BIG MAN 3 BUCKETS\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4429579177815617"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH6cYmXEbJi0",
        "outputId": "30983ffe-db6c-4db6-ef44-0071ce2c5c10"
      },
      "source": [
        "# DA BIG MAN RIDGE CLASSIFIER 200 FEATURES: DA BIG MAN 3 BUCKETS\n",
        "transformer = FastICA(n_components=200, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44660666504500124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJbFExxkb3T6",
        "outputId": "83efb4e9-b390-4305-ef53-f198e1884365"
      },
      "source": [
        "# DA BIG MAN RIDGE CLASSIFIER 180 FEATURES: DA BIG MAN 3 BUCKETS\n",
        "transformer = FastICA(n_components=180, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4473364144976891"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZw04PjVcLdP",
        "outputId": "c76fc83f-ba7e-4f50-fa80-eef12cd3ad4c"
      },
      "source": [
        "# DA BIG MAN RIDGE CLASSIFIER 165 FEATURES: DA BIG MAN 3 BUCKETS\n",
        "transformer = FastICA(n_components=165, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44684991486256387"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ph-EwV8cB2p",
        "outputId": "407dfeda-62e2-4eb9-8124-7685dfb7e1a6"
      },
      "source": [
        "# DA BIG MAN RIDGE CLASSIFIER 150 FEATURES: DA BIG MAN 3 BUCKETS\n",
        "transformer = FastICA(n_components=150, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4461201654098759"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8O3L5MdD9q1",
        "outputId": "14b9a544-3a6d-4578-a531-2c06b0375e0b"
      },
      "source": [
        "# THE REAL ONE RIDGE CLASSIFIER 55 FEATURES: the real one 10 BUCKETS\n",
        "transformer = FastICA(n_components=55, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3930917051812211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvx_iUxhEBYG",
        "outputId": "f2ea4edd-6dcc-4da7-d4d7-a9b1c6cc7f2f"
      },
      "source": [
        "# THE REAL ONE RIDGE CLASSIFIER 85 FEATURES: the real one 10 BUCKETS\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = RidgeClassifier()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39868645098516176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYGiVgdLEdDm",
        "outputId": "67666c42-da40-40bf-cb54-4e54f69a4e1b"
      },
      "source": [
        "# THE REAL ONE PERCEPTRON 85 FEATURES: the real one 10 BUCKETS\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38749695937728046"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOGyJhUpHHR1",
        "outputId": "28f12666-c3ed-4d64-9dd9-b27561d04dc5"
      },
      "source": [
        "# THE REAL ONE PERCEPTRON 75 FEATURES: the real one 10 BUCKETS\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12916565312576014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNvieE7EHLFH",
        "outputId": "14796690-2aef-4f1f-8235-36018d30c02a"
      },
      "source": [
        "# THE REAL ONE PERCEPTRON 85 FEATURES: the real one scaled 10 BUCKETS\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3836049622962783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtL7ZftDHPGF",
        "outputId": "e1d68be4-be0d-4700-8f7d-fea47369f397"
      },
      "source": [
        "# THE REAL ONE PERCEPTRON 75 FEATURES: the real one scaled 10 BUCKETS\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38749695937728046"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GwRIUQGHWaw",
        "outputId": "ed0acbd8-21af-405e-81e3-f6e56b65037a"
      },
      "source": [
        "# THE REAL ONE PERCEPTRON 85 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3541717343711992"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ayuzkx0aHcYS",
        "outputId": "0257fec7-b91a-4528-fb9f-a02eac249a56"
      },
      "source": [
        "# THE REAL ONE PERCEPTRON 75 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38725370955971783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9H-C3tYHg8E",
        "outputId": "57777167-9e96-41cc-c48a-4cf9ab494691"
      },
      "source": [
        "# THE REAL ONE PERCEPTRON 65 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=65, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4093894429579178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0VbxIG9h4lj",
        "outputId": "00bdd9fb-c172-4a54-8150-f5ca87be3c19"
      },
      "source": [
        "# THE REAL ONE PERCEPTRON 55 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=55, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4123084407686694"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRxpaFNEh7YL",
        "outputId": "a28a139b-b56a-4607-e4c8-31f9856f59e7"
      },
      "source": [
        "# THE REAL ONE PERCEPTRON 45 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=45, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3541717343711992"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGdZOsjWh-LO",
        "outputId": "facbddf1-c290-4875-e1e4-345ac445fd12"
      },
      "source": [
        "# THE REAL ONE PERCEPTRON 50 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=50, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3410362442228168"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7X-3Ckpc-i6",
        "outputId": "3309fb2d-f766-45fe-bde0-0de4ea33b7ba"
      },
      "source": [
        "# DA BIG MAN PERCEPTRON 250 FEATURES: da big man 3 BUCKETS\n",
        "transformer = FastICA(n_components=250, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30479202140598394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKiIgFJ7dQZ_",
        "outputId": "506f07fc-fc95-41af-9aa4-8810ea659028"
      },
      "source": [
        "# DA BIG MAN PERCEPTRON 350 FEATURES: da big man 3 BUCKETS\n",
        "transformer = FastICA(n_components=350, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3828752128435904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeRcHUjwd15x",
        "outputId": "2510ebab-d99a-4cf7-c274-1c014fd00634"
      },
      "source": [
        "# DA BIG MAN PERCEPTRON 400 FEATURES: da big man 3 BUCKETS\n",
        "transformer = FastICA(n_components=400, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4174166869374848"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEMhxkOAeQtO",
        "outputId": "5a843736-c3f9-4d2e-8989-0a58211ae1a1"
      },
      "source": [
        "# DA BIG MAN PERCEPTRON 450 FEATURES: da big man 3 BUCKETS\n",
        "transformer = FastICA(n_components=400, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4174166869374848"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX4B_wwfetPd",
        "outputId": "6203d566-8ebc-47ab-ae11-ee07e201a5c2"
      },
      "source": [
        "# DA BIG MAN PERCEPTRON 375 FEATURES: da big man 3 BUCKETS\n",
        "transformer = FastICA(n_components=375, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(da_big_man)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3541717343711992"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OFO1iWoH3VS",
        "outputId": "dcdd451e-69ad-40af-965e-bfd0d43e3e39"
      },
      "source": [
        "# THE REAL ONE GAUSSIAN 65 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=65, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42641693018730237"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q95gSf_bH99R",
        "outputId": "7d8fa6ee-2dcb-4aa2-a820-ce0eee0b0c1e"
      },
      "source": [
        "# THE REAL ONE GAUSSIAN 85 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4023351982486013"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eGwMHqwICMC",
        "outputId": "c7e3255d-dadd-4351-e4ac-b7049e3af21a"
      },
      "source": [
        "# THE REAL ONE GAUSSIAN 75 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42617368036973974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5GbCKY2iRk1",
        "outputId": "6ff6534d-d582-49bf-e0b7-e09848f348f5"
      },
      "source": [
        "# THE REAL ONE GAUSSIAN 70 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=70, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4247141814643639"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9TzSyLIIGK9",
        "outputId": "57dac4e6-2304-469e-f62b-2b7b114e544f"
      },
      "source": [
        "# THE REAL ONE GAUSSIAN 55 FEATURES: the real one scaled 3 BUCKETS\n",
        "transformer = FastICA(n_components=55, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(y)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4147409389442958"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOnZWXUoIQF6",
        "outputId": "6fca871f-f5e6-49de-eec0-c5941b70c32b"
      },
      "source": [
        "# THE REAL ONE GAUSSIAN 65 FEATURES: the real one 3 BUCKETS\n",
        "transformer = FastICA(n_components=65, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4016054487959134"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlbgZbW_ISoZ",
        "outputId": "e6fba319-23e5-4925-9861-77fbf383be53"
      },
      "source": [
        "# THE REAL ONE GAUSSIAN 75 FEATURES: the real one 3 BUCKETS\n",
        "transformer = FastICA(n_components=75, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40890294332279253"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhuyg3YUIXEk",
        "outputId": "98b08966-c86c-45b6-e5d2-10ca69aa5edb"
      },
      "source": [
        "# THE REAL ONE GAUSSIAN 85 FEATURES: the real one 3 BUCKETS\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed50 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed50, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3943079542690343"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUGKpBBbH3LX"
      },
      "source": [
        "# PCA 🥶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "xGq3JeuDGwK6",
        "outputId": "a1f587c9-6491-442d-9a85-66a557686464"
      },
      "source": [
        "# TRANSFORMING TO 75 FEATURES: the real one 10 buckets \n",
        "pca = PCA(n_components=250)\n",
        "pca.fit(da_big_man)\n",
        "pca.explained_variance_ratio_\n",
        "sum1 = np.sum(pca.explained_variance_ratio_)\n",
        "print(sum1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9999999999999069\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nX_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed, the_real_one['rounded_score'], test_size=0.25, random_state=22)\\nclf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\\npredictions = clf.predict(X_transformed_test)\\nnum_score = clf.score(X_transformed_test, y_test)\\nnum_score \\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "QfNa-FGCpeuY",
        "outputId": "fb4af0c7-2afd-4933-a4a2-31fd90ef067d"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>release_year</th>\n",
              "      <th>artist0_popularity</th>\n",
              "      <th>artist0_pct_followers</th>\n",
              "      <th>artist1_popularity</th>\n",
              "      <th>artist1_pct_followers</th>\n",
              "      <th>artist2_popularity</th>\n",
              "      <th>artist2_pct_followers</th>\n",
              "      <th>track0_dur_pct</th>\n",
              "      <th>track0_explicit</th>\n",
              "      <th>track0_popularity</th>\n",
              "      <th>track0_acousticness</th>\n",
              "      <th>track0_danceability</th>\n",
              "      <th>track0_energy</th>\n",
              "      <th>track0_instrumentalness</th>\n",
              "      <th>track0_key</th>\n",
              "      <th>track0_liveness</th>\n",
              "      <th>track0_loudness_pct</th>\n",
              "      <th>track0_mode</th>\n",
              "      <th>track0_speechiness</th>\n",
              "      <th>track0_tempo</th>\n",
              "      <th>track0_time_signature</th>\n",
              "      <th>track0_valence</th>\n",
              "      <th>track1_dur_pct</th>\n",
              "      <th>track1_explicit</th>\n",
              "      <th>track1_popularity</th>\n",
              "      <th>track1_acousticness</th>\n",
              "      <th>track1_danceability</th>\n",
              "      <th>track1_energy</th>\n",
              "      <th>track1_instrumentalness</th>\n",
              "      <th>track1_key</th>\n",
              "      <th>track1_liveness</th>\n",
              "      <th>track1_loudness_pct</th>\n",
              "      <th>track1_mode</th>\n",
              "      <th>track1_speechiness</th>\n",
              "      <th>track1_tempo</th>\n",
              "      <th>track1_time_signature</th>\n",
              "      <th>track1_valence</th>\n",
              "      <th>track2_dur_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>track17_percentile_total_words</th>\n",
              "      <th>track17_lyric_happy_score</th>\n",
              "      <th>track17_lyric_surprise_score</th>\n",
              "      <th>track17_lyric_sad_score</th>\n",
              "      <th>track17_lyric_angry_score</th>\n",
              "      <th>track17_lyric_fear_score</th>\n",
              "      <th>track18_genius_pageviews</th>\n",
              "      <th>track18_is_eng</th>\n",
              "      <th>track18_ttr_lexical_richness</th>\n",
              "      <th>track18_nltk_neg</th>\n",
              "      <th>track18_nltk_neu</th>\n",
              "      <th>track18_nltk_pos</th>\n",
              "      <th>track18_nltk_compound</th>\n",
              "      <th>track18_textblob_polarity</th>\n",
              "      <th>track18_textblob_subjectivity</th>\n",
              "      <th>track18_percent_unique_words</th>\n",
              "      <th>track18_percent_expletive_words</th>\n",
              "      <th>track18_percentile_total_words</th>\n",
              "      <th>track18_lyric_happy_score</th>\n",
              "      <th>track18_lyric_surprise_score</th>\n",
              "      <th>track18_lyric_sad_score</th>\n",
              "      <th>track18_lyric_angry_score</th>\n",
              "      <th>track18_lyric_fear_score</th>\n",
              "      <th>track19_genius_pageviews</th>\n",
              "      <th>track19_is_eng</th>\n",
              "      <th>track19_ttr_lexical_richness</th>\n",
              "      <th>track19_nltk_neg</th>\n",
              "      <th>track19_nltk_neu</th>\n",
              "      <th>track19_nltk_pos</th>\n",
              "      <th>track19_nltk_compound</th>\n",
              "      <th>track19_textblob_polarity</th>\n",
              "      <th>track19_textblob_subjectivity</th>\n",
              "      <th>track19_percent_unique_words</th>\n",
              "      <th>track19_percent_expletive_words</th>\n",
              "      <th>track19_percentile_total_words</th>\n",
              "      <th>track19_lyric_happy_score</th>\n",
              "      <th>track19_lyric_surprise_score</th>\n",
              "      <th>track19_lyric_sad_score</th>\n",
              "      <th>track19_lyric_angry_score</th>\n",
              "      <th>track19_lyric_fear_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3541</th>\n",
              "      <td>33</td>\n",
              "      <td>5.008515</td>\n",
              "      <td>90.769231</td>\n",
              "      <td>66</td>\n",
              "      <td>82.150442</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84.338844</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>52.60000</td>\n",
              "      <td>45.5</td>\n",
              "      <td>40.1</td>\n",
              "      <td>11.8000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>6.65</td>\n",
              "      <td>35.343299</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.78</td>\n",
              "      <td>34.588844</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.51</td>\n",
              "      <td>80.700532</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>9.4800</td>\n",
              "      <td>36.3</td>\n",
              "      <td>48.9</td>\n",
              "      <td>0.00127</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>67.90</td>\n",
              "      <td>33.702812</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.62</td>\n",
              "      <td>31.808532</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9.65</td>\n",
              "      <td>76.447038</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1950</th>\n",
              "      <td>32</td>\n",
              "      <td>22.552001</td>\n",
              "      <td>95.384615</td>\n",
              "      <td>27</td>\n",
              "      <td>45.831858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.313096</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0.72800</td>\n",
              "      <td>40.4</td>\n",
              "      <td>92.7</td>\n",
              "      <td>85.4000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.80</td>\n",
              "      <td>32.121706</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.74</td>\n",
              "      <td>68.385498</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.09</td>\n",
              "      <td>94.918081</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0629</td>\n",
              "      <td>50.7</td>\n",
              "      <td>87.3</td>\n",
              "      <td>88.60000</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>11.10</td>\n",
              "      <td>39.935394</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.66</td>\n",
              "      <td>63.199368</td>\n",
              "      <td>80.0</td>\n",
              "      <td>80.30</td>\n",
              "      <td>94.376267</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1012</th>\n",
              "      <td>66</td>\n",
              "      <td>90.238414</td>\n",
              "      <td>96.923077</td>\n",
              "      <td>69</td>\n",
              "      <td>82.235988</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.891901</td>\n",
              "      <td>100</td>\n",
              "      <td>47</td>\n",
              "      <td>12.00000</td>\n",
              "      <td>58.4</td>\n",
              "      <td>39.7</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>39.60</td>\n",
              "      <td>36.412940</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.68</td>\n",
              "      <td>59.848313</td>\n",
              "      <td>80.0</td>\n",
              "      <td>11.90</td>\n",
              "      <td>68.254898</td>\n",
              "      <td>100</td>\n",
              "      <td>48</td>\n",
              "      <td>9.4300</td>\n",
              "      <td>75.7</td>\n",
              "      <td>58.6</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>30.90</td>\n",
              "      <td>60.392123</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.89</td>\n",
              "      <td>52.670664</td>\n",
              "      <td>80.0</td>\n",
              "      <td>67.20</td>\n",
              "      <td>64.675703</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3295</th>\n",
              "      <td>47</td>\n",
              "      <td>95.265175</td>\n",
              "      <td>90.769231</td>\n",
              "      <td>75</td>\n",
              "      <td>93.050147</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.382696</td>\n",
              "      <td>100</td>\n",
              "      <td>34</td>\n",
              "      <td>2.23000</td>\n",
              "      <td>83.0</td>\n",
              "      <td>52.7</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>10.30</td>\n",
              "      <td>50.227230</td>\n",
              "      <td>100.0</td>\n",
              "      <td>23.10</td>\n",
              "      <td>45.326981</td>\n",
              "      <td>80.0</td>\n",
              "      <td>28.40</td>\n",
              "      <td>65.341029</td>\n",
              "      <td>100</td>\n",
              "      <td>33</td>\n",
              "      <td>2.2700</td>\n",
              "      <td>62.5</td>\n",
              "      <td>62.1</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>22.60</td>\n",
              "      <td>79.507379</td>\n",
              "      <td>100.0</td>\n",
              "      <td>34.40</td>\n",
              "      <td>59.875623</td>\n",
              "      <td>80.0</td>\n",
              "      <td>41.60</td>\n",
              "      <td>56.636897</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6541</th>\n",
              "      <td>42</td>\n",
              "      <td>90.238414</td>\n",
              "      <td>81.538462</td>\n",
              "      <td>54</td>\n",
              "      <td>75.094395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84.802012</td>\n",
              "      <td>100</td>\n",
              "      <td>29</td>\n",
              "      <td>10.60000</td>\n",
              "      <td>83.3</td>\n",
              "      <td>72.9</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>10.50</td>\n",
              "      <td>77.293408</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.30</td>\n",
              "      <td>40.164505</td>\n",
              "      <td>80.0</td>\n",
              "      <td>46.20</td>\n",
              "      <td>80.883688</td>\n",
              "      <td>100</td>\n",
              "      <td>17</td>\n",
              "      <td>3.0800</td>\n",
              "      <td>84.5</td>\n",
              "      <td>52.9</td>\n",
              "      <td>0.05380</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>12.80</td>\n",
              "      <td>74.150462</td>\n",
              "      <td>100.0</td>\n",
              "      <td>26.60</td>\n",
              "      <td>37.278289</td>\n",
              "      <td>80.0</td>\n",
              "      <td>26.90</td>\n",
              "      <td>76.718605</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4587</th>\n",
              "      <td>2</td>\n",
              "      <td>5.008515</td>\n",
              "      <td>87.692308</td>\n",
              "      <td>19</td>\n",
              "      <td>31.094395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90.735052</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.20000</td>\n",
              "      <td>53.7</td>\n",
              "      <td>93.1</td>\n",
              "      <td>95.7000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>13.50</td>\n",
              "      <td>83.184486</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.69</td>\n",
              "      <td>56.393702</td>\n",
              "      <td>80.0</td>\n",
              "      <td>79.10</td>\n",
              "      <td>84.880394</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37.5000</td>\n",
              "      <td>36.1</td>\n",
              "      <td>91.9</td>\n",
              "      <td>51.70000</td>\n",
              "      <td>72.727273</td>\n",
              "      <td>18.30</td>\n",
              "      <td>94.710117</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.13</td>\n",
              "      <td>45.669084</td>\n",
              "      <td>80.0</td>\n",
              "      <td>23.10</td>\n",
              "      <td>73.133604</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6646</th>\n",
              "      <td>38</td>\n",
              "      <td>75.447026</td>\n",
              "      <td>81.538462</td>\n",
              "      <td>33</td>\n",
              "      <td>53.604720</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.826176</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>10.20000</td>\n",
              "      <td>32.8</td>\n",
              "      <td>66.3</td>\n",
              "      <td>0.0602</td>\n",
              "      <td>81.818182</td>\n",
              "      <td>15.40</td>\n",
              "      <td>94.020247</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.85</td>\n",
              "      <td>61.139573</td>\n",
              "      <td>80.0</td>\n",
              "      <td>14.70</td>\n",
              "      <td>88.387541</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>3.6900</td>\n",
              "      <td>44.1</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.00856</td>\n",
              "      <td>27.272727</td>\n",
              "      <td>24.50</td>\n",
              "      <td>95.589741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.10</td>\n",
              "      <td>47.398209</td>\n",
              "      <td>80.0</td>\n",
              "      <td>13.80</td>\n",
              "      <td>74.579586</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5478</th>\n",
              "      <td>34</td>\n",
              "      <td>50.191583</td>\n",
              "      <td>84.615385</td>\n",
              "      <td>31</td>\n",
              "      <td>39.545723</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.835698</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2.91000</td>\n",
              "      <td>43.3</td>\n",
              "      <td>80.8</td>\n",
              "      <td>81.5000</td>\n",
              "      <td>90.909091</td>\n",
              "      <td>11.20</td>\n",
              "      <td>73.795499</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.32</td>\n",
              "      <td>56.723994</td>\n",
              "      <td>80.0</td>\n",
              "      <td>18.40</td>\n",
              "      <td>83.518337</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>55.1000</td>\n",
              "      <td>57.8</td>\n",
              "      <td>65.1</td>\n",
              "      <td>0.23100</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>11.40</td>\n",
              "      <td>75.501964</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.71</td>\n",
              "      <td>46.066929</td>\n",
              "      <td>80.0</td>\n",
              "      <td>40.20</td>\n",
              "      <td>75.043810</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8548</th>\n",
              "      <td>49</td>\n",
              "      <td>34.527430</td>\n",
              "      <td>75.384615</td>\n",
              "      <td>52</td>\n",
              "      <td>75.734513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.785998</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0.00369</td>\n",
              "      <td>16.4</td>\n",
              "      <td>97.4</td>\n",
              "      <td>44.2000</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>14.20</td>\n",
              "      <td>97.888428</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.30</td>\n",
              "      <td>66.216164</td>\n",
              "      <td>80.0</td>\n",
              "      <td>31.80</td>\n",
              "      <td>80.726396</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>2.3900</td>\n",
              "      <td>25.7</td>\n",
              "      <td>87.6</td>\n",
              "      <td>14.90000</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>5.25</td>\n",
              "      <td>98.225709</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.88</td>\n",
              "      <td>32.322246</td>\n",
              "      <td>80.0</td>\n",
              "      <td>48.00</td>\n",
              "      <td>80.168482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6276</th>\n",
              "      <td>28</td>\n",
              "      <td>11.455419</td>\n",
              "      <td>81.538462</td>\n",
              "      <td>52</td>\n",
              "      <td>65.554572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.581138</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.56500</td>\n",
              "      <td>48.3</td>\n",
              "      <td>89.7</td>\n",
              "      <td>6.1000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>22.40</td>\n",
              "      <td>73.805791</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.90</td>\n",
              "      <td>50.146773</td>\n",
              "      <td>80.0</td>\n",
              "      <td>49.40</td>\n",
              "      <td>72.158443</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3.1400</td>\n",
              "      <td>26.5</td>\n",
              "      <td>45.8</td>\n",
              "      <td>76.30000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.50</td>\n",
              "      <td>17.315102</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.62</td>\n",
              "      <td>47.858040</td>\n",
              "      <td>80.0</td>\n",
              "      <td>16.90</td>\n",
              "      <td>58.960128</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7497 rows × 861 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      popularity  ...  track19_lyric_fear_score\n",
              "3541          33  ...                       0.0\n",
              "1950          32  ...                       0.0\n",
              "1012          66  ...                       0.0\n",
              "3295          47  ...                       0.0\n",
              "6541          42  ...                       0.0\n",
              "...          ...  ...                       ...\n",
              "4587           2  ...                       0.0\n",
              "6646          38  ...                       0.0\n",
              "5478          34  ...                       0.0\n",
              "8548          49  ...                       0.0\n",
              "6276          28  ...                       0.0\n",
              "\n",
              "[7497 rows x 861 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcS5qJRJoB7O",
        "outputId": "77f2d519-6035-4b0f-d41c-0ca8432fc286"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=500)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42817126850740295"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhqBpxRWrhrg",
        "outputId": "cc381ba0-3f82-44c7-815e-7186e27ae0e8"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=600)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4369747899159664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PPetyZkrwIx",
        "outputId": "f8e0baad-72ba-41d2-b247-4fd546ebe439"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=600)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = PassiveAggressiveClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40456182472989194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1WE923Ur9zB",
        "outputId": "b68d4c54-4b38-4f47-eb4b-fd66ab3fca0c"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=700)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = PassiveAggressiveClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38575430172068825"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RZeyWwfsAe2",
        "outputId": "3febfa10-33f4-495b-8c6b-e886259854e1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=500)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = PassiveAggressiveClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39615846338535415"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81dYaQWKrlNh",
        "outputId": "b320b1a2-5d48-4009-9781-6fde784459a3"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=700)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4369747899159664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83aHnx1JuYPg",
        "outputId": "dd9955f5-c230-40b8-e78d-d3ebeed1280b"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=400)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35392848455363657"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g--HF2OAurXD",
        "outputId": "289858d2-82a6-4c05-b736-c23590da7f62"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=400)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35392848455363657"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmMAwo1MrpEo",
        "outputId": "8a026f42-795f-432f-8e41-ccc06895ad35"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=450)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38535414165666265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yen7pklvu2Tw",
        "outputId": "4fbc3b84-3df0-4c90-c864-62aa779c8862"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=400)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4011189491607881"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVDFkJezvC2n",
        "outputId": "4f5393be-aacb-4b47-f568-87a4b31eb8e2"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=450)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3838482121138409"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSVYt6SOvFjN",
        "outputId": "a75e0ea7-1e5b-45a9-e40a-d523e3e30a0c"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=375)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3904159571880321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpsirIG_vJEu",
        "outputId": "e3e9db6b-3cd9-4bde-c6d5-040370b6b078"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=400)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = PassiveAggressiveClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3699829725127706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZPTQ1n8vSyP",
        "outputId": "63c79590-df19-4b89-d19e-ac2c640e651c"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(real_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=80)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3320360009729993"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88dJLCW4w28H",
        "outputId": "7f620201-b388-4eed-8d5e-c1789765a8d1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(real_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=85)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46144490391632204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXsftNXaxpiG",
        "outputId": "3aaab93a-0184-4c91-8b70-7872ed189d5d"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(real_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=88)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.78175e-18): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46144490391632204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW4GvW9DxwJf",
        "outputId": "ccea483f-790d-4257-d9ea-b4ad50f31b6c"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(real_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=85)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf =Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3320360009729993"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFfg3VWOyDUe",
        "outputId": "8c27acc6-cbea-4df5-ea02-de9bb1b68b24"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(real_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=65)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf =Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3320360009729993"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5ICbZqTxysx",
        "outputId": "70986870-a0dd-4bf2-eade-6cd8235eeaab"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(real_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=65)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4500121624908781"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC0vkUFRxjYT",
        "outputId": "89c5311e-a350-4cd5-8631-860a4f128344"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(real_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=90)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.78175e-18): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46144490391632204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt7nWlWOxm74",
        "outputId": "6575779f-220c-4aac-90f4-7deb77514225"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(real_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=80)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45657990756506933"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWc2GCOSvP82"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=375)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-03yUQyuy8l",
        "outputId": "ca25862c-934b-4c92-af39-ef3b21877e23"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=350)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35392848455363657"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqV3UIv1ujsH",
        "outputId": "d365e5b1-c951-49c9-942f-3461b92b4120"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=300)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39095638255302123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9-LL6cCyeTm",
        "outputId": "efd4ae24-b2ff-45cd-83b2-a8d925a81967"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3626854779858915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vogkewo1ykD-",
        "outputId": "33f3d5e6-356b-4315-ed8f-9d6bd54ee9ac"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3624422281683289"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXL2LGJIyoze",
        "outputId": "daba6342-5f45-40f2-aea2-b86a033663df"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4429579177815617"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzWAIku_zDsn",
        "outputId": "f20abe1f-085f-45a8-9c4d-93e9f52be20d"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = LogisticRegression().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4390659207005595"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhKEVcm7zHPc",
        "outputId": "413a49fe-a506-4a02-8b4b-0926edc023a1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(pct_scaled_big_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = Perceptron().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3624422281683289"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vxqsy06_zL52",
        "outputId": "7b94a466-74b0-441f-90f1-efc67a8ca799"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(real_x, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3634152274385794"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LAxeOl9rrzb",
        "outputId": "44907d4b-9f1b-45e9-ab83-34884078469c"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(genius, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=500)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = RidgeClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42857142857142855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRA7xJXEIIKa"
      },
      "source": [
        "da_big_man"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wjafg3GPOIT"
      },
      "source": [
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(da_big_man, the_real_one['tripartite_score'], test_size=0.25, random_state=22)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fhzCHpwICnh",
        "outputId": "4e1bff6f-b2e0-4323-f01f-5777427feaa2"
      },
      "source": [
        "pca = PCA(.95)\n",
        "pca.fit(X_transformed_train)\n",
        "train = pca.transform(X_transformed_train)\n",
        "test = pca.transform(X_transformed_test)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "num_score = clf.score(test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42836292872780346"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKzlei2Rd1An"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets\n",
        "transformer = FastICA(n_components=85, random_state=0)\n",
        "X_transformed85 = transformer.fit_transform(real)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_transformed85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbByYirXtbLd",
        "outputId": "311086b0-fefa-4e77-9716-3f251ebf3319"
      },
      "source": [
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pitchfork_id</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>7.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>6.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>7.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16437</th>\n",
              "      <td>22319</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16438</th>\n",
              "      <td>22321</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16439</th>\n",
              "      <td>22322</td>\n",
              "      <td>9.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16440</th>\n",
              "      <td>22323</td>\n",
              "      <td>8.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16441</th>\n",
              "      <td>22324</td>\n",
              "      <td>7.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       pitchfork_id  score\n",
              "0                 2    7.5\n",
              "1                 3    7.7\n",
              "2                 5    6.5\n",
              "3                 6    7.6\n",
              "4                 7    8.0\n",
              "...             ...    ...\n",
              "16437         22319    7.5\n",
              "16438         22321    9.4\n",
              "16439         22322    9.3\n",
              "16440         22323    8.1\n",
              "16441         22324    7.4\n",
              "\n",
              "[16442 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5_0TPe0sJq9"
      },
      "source": [
        "pct_scaled_big_x = pd.read_csv('DA_BIG_MAN_MINMAXED_PCT.csv')\n",
        "scaled_big_x = pd.read_csv('DA_BIG_MAN_MINMAXED.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnR42X8-sGa1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(scaled, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "pca = PCA(n_components=700)\n",
        "pca.fit(X_train)\n",
        "train = pca.transform(X_train)\n",
        "test = pca.transform(X_test)\n",
        "clf = PassiveAggressiveClassifier().fit(train, y_train)\n",
        "predictions = clf.predict(test)\n",
        "clf.score(test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag8TP52nIAW4"
      },
      "source": [
        "sum = []\n",
        "print(len(list(the_real_one.columns)) / 2)\n",
        "for i in range(200) :\n",
        "  print(i)\n",
        "  pca = PCA(n_components=i)\n",
        "  pca.fit(the_real_one)\n",
        "  pca.explained_variance_ratio_\n",
        "  sum1 = np.sum(pca.explained_variance_ratio_)\n",
        "  sum.append(sum1)\n",
        "  print(sum1)\n",
        "  print(\"##############################\")\n",
        "  print(\"##############################\")\n",
        "\n",
        "\n",
        "plt.figure(0)\n",
        "plt.plot(range(0, 200), sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJHInUZufcjI"
      },
      "source": [
        "\n",
        "#feature_names = list(X_new.columns)\n",
        "#print(len(feature_names))\n",
        "ax = plt.axes()\n",
        "ax.figure.set_size_inches(30, 30)\n",
        "im = ax.imshow(np.corrcoef(X_new.T), cmap=\"RdBu_r\", vmin=-1, vmax=1)\n",
        "\n",
        "ax.set_xticks(range(0,100))\n",
        "ax.set_xticklabels(list(feature_names), rotation=90)\n",
        "ax.set_yticks(range(0,100))\n",
        "ax.set_yticklabels(list(feature_names))\n",
        "plt.colorbar(im).ax.set_ylabel(\"$r$\", rotation=0)\n",
        "ax.set_title(\"Pitchfork feature correlation matrix\")\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_full, test_size=0.25, random_state=22)\n",
        "\n",
        "reg = LinearRegression().fit(X_train, Y_train)\n",
        "y_true = Y_test['score'].tolist()\n",
        "CC = reg.predict(X_test)\n",
        "y_pred = CC[:,0]\n",
        "print(r2_score(y_true, CC))\n",
        "graphRegressionMetrics(y_true, CC, X_test)\n",
        "\n",
        "regr = ElasticNet()\n",
        "regr.fit(X_train, Y_train)\n",
        "ElasticNet(random_state=0)\n",
        "CC = regr.predict(X_test)\n",
        "CC\n",
        "y_true = Y_test['score'].tolist()\n",
        "\n",
        "print(r2_score(y_true, CC))\n",
        "graphRegressionMetrics(y_true, CC, X_test)\n",
        "\n",
        "rr = Ridge(alpha=0.0001)\n",
        "rr.fit(X_train, Y_train) \n",
        "CC = rr.predict(X_test)\n",
        "CC\n",
        "y_true = Y_test['score'].tolist()\n",
        "\n",
        "print(r2_score(y_true, CC))\n",
        "graphRegressionMetrics(y_true, CC, X_test)\n",
        "\n",
        "model_lasso = Lasso(alpha=0.01)\n",
        "model_lasso.fit(X_train, Y_train) \n",
        "CC = model_lasso.predict(X_test)\n",
        "CC\n",
        "y_true = Y_test['score'].tolist()\n",
        "\n",
        "print(r2_score(y_true, CC))\n",
        "graphRegressionMetrics(y_true, CC, X_test)\n",
        "\n",
        "reg = make_pipeline(StandardScaler(), SGDRegressor(max_iter=1000, tol=1e-3))\n",
        "reg.fit(X_train, Y_train)\n",
        "CC = reg.predict(X_test)\n",
        "CC\n",
        "y_true = Y_test['score'].tolist()\n",
        "\n",
        "print(r2_score(y_true, CC))\n",
        "graphRegressionMetrics(y_true, CC, X_test)\n",
        "\n",
        "reg = NuSVR()\n",
        "reg.fit(X_train, Y_train)\n",
        "CC = reg.predict(X_test)\n",
        "CC\n",
        "y_true = Y_test['score'].tolist()\n",
        "\n",
        "print(r2_score(y_true, CC))\n",
        "graphRegressionMetrics(y_true, CC, X_test)\n",
        "\n",
        "reg = SVR()\n",
        "reg.fit(X_train, Y_train)\n",
        "CC = reg.predict(X_test)\n",
        "CC\n",
        "y_true = Y_test['score'].tolist()\n",
        "\n",
        "print(r2_score(y_true, CC))\n",
        "graphRegressionMetrics(y_true, CC, X_test)\n",
        "\n",
        "reg = DecisionTreeRegressor()\n",
        "reg.fit(X_train, Y_train)\n",
        "CC = reg.predict(X_test)\n",
        "CC\n",
        "y_true = Y_test['score'].tolist()\n",
        "\n",
        "print(r2_score(y_true, CC))\n",
        "graphRegressionMetrics(y_true, CC, X_test)\n",
        "\n",
        "reg = ExtraTreeRegressor()\n",
        "reg.fit(X_train, Y_train)\n",
        "CC = reg.predict(X_test)\n",
        "CC\n",
        "y_true = Y_test['score'].tolist()\n",
        "\n",
        "print(r2_score(y_true, CC))\n",
        "graphRegressionMetrics(y_true, CC, X_test)\n",
        "\n",
        "reg = PoissonRegressor()\n",
        "\n",
        "reg.fit(X_train, Y_train)\n",
        "CC = reg.predict(X_test)\n",
        "CC\n",
        "y_true = Y_test['score'].tolist()\n",
        "\n",
        "print(r2_score(y_true, CC))\n",
        "graphRegressionMetrics(y_true, CC, X_test)\n",
        "\n",
        "reg = TweedieRegressor()\n",
        "\n",
        "reg.fit(X_train, Y_train)\n",
        "CC = reg.predict(X_test)\n",
        "CC\n",
        "y_true = Y_test['score'].tolist()\n",
        "\n",
        "print(r2_score(y_true, CC))\n",
        "graphRegressionMetrics(y_true, CC, X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iKluuEJk9S2"
      },
      "source": [
        "#feature_names = list(X_new.columns)\n",
        "#print(len(feature_names))\n",
        "ax = plt.axes()\n",
        "ax.figure.set_size_inches(30, 30)\n",
        "im = ax.imshow(np.corrcoef(X_new.T), cmap=\"RdBu_r\", vmin=-1, vmax=1)\n",
        "\n",
        "ax.set_xticks(range(0,100))\n",
        "ax.set_xticklabels(list(feature_names), rotation=90)\n",
        "ax.set_yticks(range(0,100))\n",
        "ax.set_yticklabels(list(feature_names))\n",
        "plt.colorbar(im).ax.set_ylabel(\"$r$\", rotation=0)\n",
        "ax.set_title(\"Pitchfork feature correlation matrix\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDYZwxLIk-5_"
      },
      "source": [
        "n_comps = 2\n",
        "\n",
        "x_test = StandardScaler().fit_transform(X_test)\n",
        "\n",
        "feature_names = list(X_test.columns)\n",
        "print(len(feature_names))\n",
        "ax = plt.axes()\n",
        "ax.figure.set_size_inches(30, 30)\n",
        "im = ax.imshow(np.corrcoef(x_test.T), cmap=\"RdBu_r\", vmin=-1, vmax=1)\n",
        "\n",
        "ax.set_xticks(range(0,len(feature_names)))\n",
        "ax.set_xticklabels(list(feature_names), rotation=90)\n",
        "ax.set_yticks(range(0,len(feature_names)))\n",
        "ax.set_yticklabels(list(feature_names))\n",
        "plt.colorbar(im).ax.set_ylabel(\"$r$\", rotation=0)\n",
        "ax.set_title(\"Pitchfork feature correlation matrix\")\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "methods = [('PCA', PCA()),\n",
        "           ('Unrotated FA', FactorAnalysis()),\n",
        "           ('Varimax FA', FactorAnalysis(rotation='varimax'))]\n",
        "fig, axes = plt.subplots(ncols=len(methods), figsize=(500, 300))\n",
        "\n",
        "for ax, (method, fa) in zip(axes, methods):\n",
        "    fa.set_params(n_components=n_comps)\n",
        "    fa.fit(x_test)\n",
        "\n",
        "    components = fa.components_.T\n",
        "    print(\"\\n\\n %s :\\n\" % method)\n",
        "    print(components)\n",
        "\n",
        "    vmax = np.abs(components).max()\n",
        "    ax.imshow(components, cmap=\"RdBu_r\", vmax=vmax, vmin=-vmax)\n",
        "    ax.set_yticks(np.arange(len(feature_names)))\n",
        "    if ax.is_first_col():\n",
        "        ax.set_yticklabels(feature_names)\n",
        "    else:\n",
        "        ax.set_yticklabels([])\n",
        "    ax.set_title(str(method))\n",
        "    ax.set_xticks([0, 1])\n",
        "    ax.set_xticklabels([\"Comp. 1\", \"Comp. 2\"])\n",
        "fig.suptitle(\"Factors\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jehV0P2S_cJ"
      },
      "source": [
        "# K-BEST 😎"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUYYXOY7hUnL"
      },
      "source": [
        "real_x = real\n",
        "y_10 = the_real_one['rounded_score']\n",
        "y_6 = the_real_one['sextile_score']\n",
        "y_3 = the_real_one['tripartite_score']\n",
        "scaled_x = y\n",
        "big_x = da_big_man"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoTyMYA5TFdw"
      },
      "source": [
        "#X_new_10 = SelectKBest(chi2, k=80).fit_transform(real_x, y_10)\n",
        "X_new_scaled_10 = SelectKBest(chi2, k=80).fit_transform(scaled_x, y_10)\n",
        "\n",
        "#X_new_6 = SelectKBest(chi2, k=80).fit_transform(real_x, y_6)\n",
        "X_new_scaled_6 = SelectKBest(chi2, k=80).fit_transform(scaled_x, y_6)\n",
        "\n",
        "#X_new_3 = SelectKBest(chi2, k=80).fit_transform(real_x, y_3)\n",
        "X_new_scaled_3 = SelectKBest(chi2, k=80).fit_transform(scaled_x, y_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viJz1YyX36XE"
      },
      "source": [
        "the_real_one['tripartite_score'].to_csv('THE_REAL_ONE_TRI_CLASSIFICATION_Y.csv', index=False)\n",
        "the_real_one['sextile_score'].to_csv('THE_REAL_ONE_SIX_CLASSIFICATION_Y.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEclmvAmioud"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: the real one scaled 10 buckets\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_10, the_real_one['rounded_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFi4C1Bqs1IT"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: the real one scaled 6 buckets\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_6, the_real_one['sextile_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM79eqWhs5Bs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f54c2a-b30a-41d9-8765-ef00ad4033cc"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: the real one scaled 3 buckets\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_10, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44660666504500124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "E4vwjsMZ1Rrv",
        "outputId": "8557ddc8-ef00-4dfb-a35c-86233f98cb8a"
      },
      "source": [
        "x_scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>total_tracks</th>\n",
              "      <th>album_duration_minutes</th>\n",
              "      <th>year</th>\n",
              "      <th>min_loudness</th>\n",
              "      <th>max_loudness</th>\n",
              "      <th>mean_loudness</th>\n",
              "      <th>stddev_loudness</th>\n",
              "      <th>label_frequency</th>\n",
              "      <th>mean_duration</th>\n",
              "      <th>min_valence</th>\n",
              "      <th>max_valence</th>\n",
              "      <th>stddev_valence</th>\n",
              "      <th>mean_valence</th>\n",
              "      <th>weighted_avg_valence</th>\n",
              "      <th>weighted_avg_speechiness</th>\n",
              "      <th>med_liveness</th>\n",
              "      <th>stddev_liveness</th>\n",
              "      <th>stddev_instrumentalness</th>\n",
              "      <th>weighted_avg_instrumentalness</th>\n",
              "      <th>explicit</th>\n",
              "      <th>weighted_avg_energy</th>\n",
              "      <th>min_danceability</th>\n",
              "      <th>max_danceability</th>\n",
              "      <th>mean_danceability</th>\n",
              "      <th>stddev_danceability</th>\n",
              "      <th>mean_acousticness</th>\n",
              "      <th>stddev_acousticness</th>\n",
              "      <th>med_acousticness</th>\n",
              "      <th>min_popularity</th>\n",
              "      <th>max_popularity</th>\n",
              "      <th>mean_popularity</th>\n",
              "      <th>stddev_popularity</th>\n",
              "      <th>key_0_pct</th>\n",
              "      <th>key_1_pct</th>\n",
              "      <th>key_2_pct</th>\n",
              "      <th>key_3_pct</th>\n",
              "      <th>key_4_pct</th>\n",
              "      <th>key_5_pct</th>\n",
              "      <th>key_6_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>sig_5_pct</th>\n",
              "      <th>num_artists</th>\n",
              "      <th>num_features</th>\n",
              "      <th>artist_popularity_mean</th>\n",
              "      <th>artist_followers_mean</th>\n",
              "      <th>artist_popularity_min</th>\n",
              "      <th>artist_popularity_max</th>\n",
              "      <th>artist_followers_min</th>\n",
              "      <th>artist_followers_max</th>\n",
              "      <th>artist_popularity_stddev</th>\n",
              "      <th>artist_followers_stddev</th>\n",
              "      <th>mean_feat_artist_popularity</th>\n",
              "      <th>mean_feat_artist_followers</th>\n",
              "      <th>min_feat_artist_popularity</th>\n",
              "      <th>min_feat_artist_followers</th>\n",
              "      <th>max_feat_artist_popularity</th>\n",
              "      <th>max_feat_artist_followers</th>\n",
              "      <th>stddev_feat_artist_popularity</th>\n",
              "      <th>stddev_feat_artist_followers</th>\n",
              "      <th>genre_0_pct</th>\n",
              "      <th>genre_1_pct</th>\n",
              "      <th>genre_2_pct</th>\n",
              "      <th>genre_3_pct</th>\n",
              "      <th>genre_4_pct</th>\n",
              "      <th>genre_5_pct</th>\n",
              "      <th>genre_6_pct</th>\n",
              "      <th>genre_7_pct</th>\n",
              "      <th>genre_8_pct</th>\n",
              "      <th>genre_9_pct</th>\n",
              "      <th>genre_10_pct</th>\n",
              "      <th>genre_11_pct</th>\n",
              "      <th>genre_12_pct</th>\n",
              "      <th>genre_13_pct</th>\n",
              "      <th>genre_14_pct</th>\n",
              "      <th>genre_15_pct</th>\n",
              "      <th>genre_16_pct</th>\n",
              "      <th>genre_17_pct</th>\n",
              "      <th>genre_18_pct</th>\n",
              "      <th>genre_19_pct</th>\n",
              "      <th>genre_20_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24</td>\n",
              "      <td>4.205607</td>\n",
              "      <td>5.216574</td>\n",
              "      <td>89.230769</td>\n",
              "      <td>39.344784</td>\n",
              "      <td>82.696360</td>\n",
              "      <td>73.918161</td>\n",
              "      <td>12.819280</td>\n",
              "      <td>0.142336</td>\n",
              "      <td>0.053809</td>\n",
              "      <td>44.99</td>\n",
              "      <td>50.0</td>\n",
              "      <td>12.949785</td>\n",
              "      <td>27.991818</td>\n",
              "      <td>30.245793</td>\n",
              "      <td>4.447069</td>\n",
              "      <td>15.10</td>\n",
              "      <td>21.153535</td>\n",
              "      <td>32.176957</td>\n",
              "      <td>44.898394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62.383915</td>\n",
              "      <td>31.40</td>\n",
              "      <td>57.0</td>\n",
              "      <td>41.400000</td>\n",
              "      <td>10.030952</td>\n",
              "      <td>34.881455</td>\n",
              "      <td>34.881455</td>\n",
              "      <td>22.600</td>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>11.727273</td>\n",
              "      <td>4.076540</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.272727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>35.0</td>\n",
              "      <td>9.463353</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>9.463353</td>\n",
              "      <td>9.463353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "      <td>5.140187</td>\n",
              "      <td>3.547831</td>\n",
              "      <td>84.615385</td>\n",
              "      <td>3.984052</td>\n",
              "      <td>71.497658</td>\n",
              "      <td>69.608254</td>\n",
              "      <td>1.280190</td>\n",
              "      <td>0.171533</td>\n",
              "      <td>0.029373</td>\n",
              "      <td>60.10</td>\n",
              "      <td>96.7</td>\n",
              "      <td>19.979390</td>\n",
              "      <td>70.846154</td>\n",
              "      <td>69.486688</td>\n",
              "      <td>3.513317</td>\n",
              "      <td>11.90</td>\n",
              "      <td>4.893759</td>\n",
              "      <td>27.287752</td>\n",
              "      <td>17.900103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.964133</td>\n",
              "      <td>43.70</td>\n",
              "      <td>65.6</td>\n",
              "      <td>43.153846</td>\n",
              "      <td>13.156786</td>\n",
              "      <td>14.313231</td>\n",
              "      <td>14.313231</td>\n",
              "      <td>10.400</td>\n",
              "      <td>8</td>\n",
              "      <td>28</td>\n",
              "      <td>14.153846</td>\n",
              "      <td>5.899804</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>27.0</td>\n",
              "      <td>9.391328</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>9.391328</td>\n",
              "      <td>9.391328</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.153846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32</td>\n",
              "      <td>7.476636</td>\n",
              "      <td>7.058179</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>54.782226</td>\n",
              "      <td>85.041614</td>\n",
              "      <td>68.918855</td>\n",
              "      <td>15.766528</td>\n",
              "      <td>0.029197</td>\n",
              "      <td>0.042183</td>\n",
              "      <td>48.10</td>\n",
              "      <td>53.8</td>\n",
              "      <td>11.907827</td>\n",
              "      <td>20.198333</td>\n",
              "      <td>20.467366</td>\n",
              "      <td>3.580182</td>\n",
              "      <td>16.35</td>\n",
              "      <td>17.250501</td>\n",
              "      <td>37.102197</td>\n",
              "      <td>7.120938</td>\n",
              "      <td>100.0</td>\n",
              "      <td>42.041608</td>\n",
              "      <td>47.23</td>\n",
              "      <td>56.4</td>\n",
              "      <td>27.453889</td>\n",
              "      <td>11.760904</td>\n",
              "      <td>56.753778</td>\n",
              "      <td>56.753778</td>\n",
              "      <td>63.900</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>12.777778</td>\n",
              "      <td>6.575852</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>...</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>53.0</td>\n",
              "      <td>12.128511</td>\n",
              "      <td>53</td>\n",
              "      <td>53</td>\n",
              "      <td>12.128511</td>\n",
              "      <td>12.128511</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>16.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42</td>\n",
              "      <td>4.205607</td>\n",
              "      <td>6.656771</td>\n",
              "      <td>76.923077</td>\n",
              "      <td>27.550293</td>\n",
              "      <td>83.058684</td>\n",
              "      <td>72.457424</td>\n",
              "      <td>8.320842</td>\n",
              "      <td>0.014599</td>\n",
              "      <td>0.069192</td>\n",
              "      <td>93.44</td>\n",
              "      <td>96.8</td>\n",
              "      <td>34.509269</td>\n",
              "      <td>45.536364</td>\n",
              "      <td>40.454860</td>\n",
              "      <td>4.322030</td>\n",
              "      <td>10.30</td>\n",
              "      <td>7.468719</td>\n",
              "      <td>31.851682</td>\n",
              "      <td>30.171808</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.876194</td>\n",
              "      <td>37.50</td>\n",
              "      <td>64.9</td>\n",
              "      <td>49.981818</td>\n",
              "      <td>11.898976</td>\n",
              "      <td>36.886091</td>\n",
              "      <td>36.886091</td>\n",
              "      <td>19.100</td>\n",
              "      <td>22</td>\n",
              "      <td>38</td>\n",
              "      <td>27.181818</td>\n",
              "      <td>5.600325</td>\n",
              "      <td>27.272727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.272727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>56.0</td>\n",
              "      <td>12.932638</td>\n",
              "      <td>56</td>\n",
              "      <td>56</td>\n",
              "      <td>12.932638</td>\n",
              "      <td>12.932638</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>27.272727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39</td>\n",
              "      <td>5.140187</td>\n",
              "      <td>8.593851</td>\n",
              "      <td>93.846154</td>\n",
              "      <td>12.132559</td>\n",
              "      <td>79.159529</td>\n",
              "      <td>74.213050</td>\n",
              "      <td>3.993543</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.074977</td>\n",
              "      <td>64.60</td>\n",
              "      <td>78.6</td>\n",
              "      <td>20.878642</td>\n",
              "      <td>37.953846</td>\n",
              "      <td>35.150907</td>\n",
              "      <td>3.878383</td>\n",
              "      <td>11.30</td>\n",
              "      <td>14.394478</td>\n",
              "      <td>21.857669</td>\n",
              "      <td>12.832999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.755922</td>\n",
              "      <td>29.60</td>\n",
              "      <td>63.0</td>\n",
              "      <td>51.623077</td>\n",
              "      <td>8.460610</td>\n",
              "      <td>84.638462</td>\n",
              "      <td>84.638462</td>\n",
              "      <td>85.200</td>\n",
              "      <td>16</td>\n",
              "      <td>30</td>\n",
              "      <td>23.307692</td>\n",
              "      <td>5.647782</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>60.0</td>\n",
              "      <td>13.220368</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>13.220368</td>\n",
              "      <td>13.220368</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12326</th>\n",
              "      <td>13</td>\n",
              "      <td>3.738318</td>\n",
              "      <td>4.254298</td>\n",
              "      <td>90.769231</td>\n",
              "      <td>9.958613</td>\n",
              "      <td>85.150766</td>\n",
              "      <td>81.752801</td>\n",
              "      <td>3.323804</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.048584</td>\n",
              "      <td>56.80</td>\n",
              "      <td>56.8</td>\n",
              "      <td>17.430659</td>\n",
              "      <td>28.861000</td>\n",
              "      <td>29.872854</td>\n",
              "      <td>4.454367</td>\n",
              "      <td>15.40</td>\n",
              "      <td>16.317463</td>\n",
              "      <td>28.971217</td>\n",
              "      <td>55.828525</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.117478</td>\n",
              "      <td>42.70</td>\n",
              "      <td>42.7</td>\n",
              "      <td>19.260000</td>\n",
              "      <td>11.252279</td>\n",
              "      <td>34.456726</td>\n",
              "      <td>34.456726</td>\n",
              "      <td>8.455</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>3.400980</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>18.0</td>\n",
              "      <td>8.232174</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>8.232174</td>\n",
              "      <td>8.232174</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12327</th>\n",
              "      <td>37</td>\n",
              "      <td>4.205607</td>\n",
              "      <td>5.724483</td>\n",
              "      <td>84.615385</td>\n",
              "      <td>18.001001</td>\n",
              "      <td>81.380471</td>\n",
              "      <td>74.569490</td>\n",
              "      <td>5.718241</td>\n",
              "      <td>0.354015</td>\n",
              "      <td>0.059234</td>\n",
              "      <td>69.35</td>\n",
              "      <td>72.9</td>\n",
              "      <td>24.466331</td>\n",
              "      <td>37.811818</td>\n",
              "      <td>35.467744</td>\n",
              "      <td>7.512930</td>\n",
              "      <td>11.50</td>\n",
              "      <td>10.682899</td>\n",
              "      <td>31.391878</td>\n",
              "      <td>39.110863</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.866022</td>\n",
              "      <td>56.50</td>\n",
              "      <td>84.7</td>\n",
              "      <td>64.718182</td>\n",
              "      <td>16.964717</td>\n",
              "      <td>47.109091</td>\n",
              "      <td>47.109091</td>\n",
              "      <td>46.400</td>\n",
              "      <td>18</td>\n",
              "      <td>36</td>\n",
              "      <td>22.090909</td>\n",
              "      <td>5.107926</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>46.0</td>\n",
              "      <td>11.135771</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>11.135771</td>\n",
              "      <td>11.135771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>27.272727</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>9.090909</td>\n",
              "      <td>18.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12328</th>\n",
              "      <td>18</td>\n",
              "      <td>1.401869</td>\n",
              "      <td>5.874063</td>\n",
              "      <td>84.615385</td>\n",
              "      <td>10.880342</td>\n",
              "      <td>82.249140</td>\n",
              "      <td>75.978352</td>\n",
              "      <td>4.021751</td>\n",
              "      <td>0.839416</td>\n",
              "      <td>0.142227</td>\n",
              "      <td>26.51</td>\n",
              "      <td>33.6</td>\n",
              "      <td>11.888691</td>\n",
              "      <td>15.762000</td>\n",
              "      <td>16.675182</td>\n",
              "      <td>3.976732</td>\n",
              "      <td>9.77</td>\n",
              "      <td>18.261575</td>\n",
              "      <td>36.789364</td>\n",
              "      <td>75.185119</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.887011</td>\n",
              "      <td>20.00</td>\n",
              "      <td>39.1</td>\n",
              "      <td>27.460000</td>\n",
              "      <td>8.071741</td>\n",
              "      <td>47.341000</td>\n",
              "      <td>47.341000</td>\n",
              "      <td>54.400</td>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>4.358899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>17.0</td>\n",
              "      <td>8.969415</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>8.969415</td>\n",
              "      <td>8.969415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12329</th>\n",
              "      <td>61</td>\n",
              "      <td>5.140187</td>\n",
              "      <td>10.466413</td>\n",
              "      <td>55.384615</td>\n",
              "      <td>26.278368</td>\n",
              "      <td>75.487773</td>\n",
              "      <td>67.820888</td>\n",
              "      <td>6.754800</td>\n",
              "      <td>0.083942</td>\n",
              "      <td>0.091901</td>\n",
              "      <td>69.12</td>\n",
              "      <td>71.0</td>\n",
              "      <td>20.595602</td>\n",
              "      <td>30.752308</td>\n",
              "      <td>33.554656</td>\n",
              "      <td>6.703597</td>\n",
              "      <td>11.20</td>\n",
              "      <td>11.064969</td>\n",
              "      <td>14.532638</td>\n",
              "      <td>89.266195</td>\n",
              "      <td>0.0</td>\n",
              "      <td>56.245494</td>\n",
              "      <td>58.20</td>\n",
              "      <td>76.5</td>\n",
              "      <td>58.307692</td>\n",
              "      <td>17.103239</td>\n",
              "      <td>44.790992</td>\n",
              "      <td>44.790992</td>\n",
              "      <td>42.000</td>\n",
              "      <td>39</td>\n",
              "      <td>56</td>\n",
              "      <td>45.153846</td>\n",
              "      <td>5.565461</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>66.0</td>\n",
              "      <td>13.498538</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>13.498538</td>\n",
              "      <td>13.498538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>38.461538</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.692308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12330</th>\n",
              "      <td>35</td>\n",
              "      <td>2.336449</td>\n",
              "      <td>3.429631</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>4.413080</td>\n",
              "      <td>76.454982</td>\n",
              "      <td>73.815624</td>\n",
              "      <td>1.782965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.058563</td>\n",
              "      <td>24.30</td>\n",
              "      <td>61.3</td>\n",
              "      <td>10.712054</td>\n",
              "      <td>48.614286</td>\n",
              "      <td>47.977867</td>\n",
              "      <td>3.147087</td>\n",
              "      <td>10.20</td>\n",
              "      <td>7.772850</td>\n",
              "      <td>5.393461</td>\n",
              "      <td>3.076247</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.097611</td>\n",
              "      <td>29.60</td>\n",
              "      <td>69.9</td>\n",
              "      <td>51.285714</td>\n",
              "      <td>9.941064</td>\n",
              "      <td>21.012857</td>\n",
              "      <td>21.012857</td>\n",
              "      <td>9.190</td>\n",
              "      <td>20</td>\n",
              "      <td>35</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>5.033223</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>28.571429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.846154</td>\n",
              "      <td>52.0</td>\n",
              "      <td>12.094163</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>12.094163</td>\n",
              "      <td>12.094163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.285714</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16442 rows × 90 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       popularity  total_tracks  ...  genre_19_pct  genre_20_pct\n",
              "0              24      4.205607  ...      0.000000      0.000000\n",
              "1              30      5.140187  ...      0.000000      0.000000\n",
              "2              32      7.476636  ...     16.666667     16.666667\n",
              "3              42      4.205607  ...      0.000000      0.000000\n",
              "4              39      5.140187  ...      7.692308      0.000000\n",
              "...           ...           ...  ...           ...           ...\n",
              "12326          13      3.738318  ...     20.000000      0.000000\n",
              "12327          37      4.205607  ...      0.000000      9.090909\n",
              "12328          18      1.401869  ...      0.000000      0.000000\n",
              "12329          61      5.140187  ...      0.000000      7.692308\n",
              "12330          35      2.336449  ...     14.285714      0.000000\n",
              "\n",
              "[16442 rows x 90 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSeFJL0hpVET"
      },
      "source": [
        "x_scaled = pd.concat([x_scaled_test, x_scaled_train])\n",
        "#x_scaled = x_scaled.sort_values('pitchfork_id')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWIrQjdp2v5S"
      },
      "source": [
        "y_test_tri = pd.read_csv('THE_REAL_ONE_Y_TEST_CLASSIFICATION_TRI.csv')\n",
        "y_train_tri = pd.read_csv('THE_REAL_ONE_Y_TRAIN_CLASSIFICATION_TRI.csv')\n",
        "y_scaled = pd.concat([y_test_tri, y_train_tri])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9lbEfSMzour"
      },
      "source": [
        "scaled_x = x_scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW4cIPIEoYOu"
      },
      "source": [
        "x_scaled = pd.read_csv('THE_REAL_ONE_SCALED.csv')\n",
        "the_real_one = x_scaled[['rounded_score', 'sextile_score', 'tripartite_score']]\n",
        "x_scaled = x_scaled.drop(labels=['score', 'rounded_score', 'sextile_score', 'tripartite_score'], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsXpPLDLtBES"
      },
      "source": [
        "#X_new_10 = SelectKBest(chi2, k=80).fit_transform(real_x, y_10)\n",
        "#X_new_scaled_10_65 = SelectKBest(chi2, k=65).fit_transform(x_scaled, the_real_one['rounded_score'])\n",
        "\n",
        "#X_new_6 = SelectKBest(chi2, k=80).fit_transform(real_x, y_6)\n",
        "#X_new_scaled_6_65 = SelectKBest(chi2, k=65).fit_transform(x_scaled, the_real_one['sextile_score'])\n",
        "\n",
        "#X_new_3 = SelectKBest(chi2, k=80).fit_transform(real_x, y_3)\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=65).fit_transform(x_scaled, y_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8APsOyftFgC",
        "outputId": "0ebd5463-ff3e-4643-d300-0db41791ec91"
      },
      "source": [
        "# TRANSFORMING TO 80 FEATURES: the real one scaled 3 buckets\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, y_scaled['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4417416686937485"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i9b8Dx9oS01"
      },
      "source": [
        "confusion_matrix_metric(y_test, predictions, ['0', '1', '2'], True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlM-HlSWoT_I"
      },
      "source": [
        "classification_scores(predictions, y_test, ['0', '1', '2'], True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq28elRrRVah",
        "outputId": "ac616134-4a80-40a3-b217-82423afc97f3"
      },
      "source": [
        "# TRANSFORMING TO 500 FEATURES: genius 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=500).fit_transform(genius, genius_scores['tripartite_score'])\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4361744697879152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWtImGY4iAG8",
        "outputId": "5fbf3bcb-0a15-4240-fce0-766f436d7da5"
      },
      "source": [
        "# TRANSFORMING TO 500 FEATURES: genius 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=500).fit_transform(genius, genius_scores['tripartite_score'])\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4361744697879152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkL94G26nhBk",
        "outputId": "509ae028-4498-4566-85e8-d0bebebc0fd8"
      },
      "source": [
        "# TRANSFORMING TO 600 FEATURES: genius 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=600).fit_transform(genius, genius_scores['tripartite_score'])\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4485794317727091"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAPkrEZTnxxq",
        "outputId": "71071c22-56ce-40d5-c170-1eb330d5454e"
      },
      "source": [
        "# TRANSFORMING TO 625 FEATURES: genius 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=625).fit_transform(genius, genius_scores['tripartite_score'])\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44377751100440177"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXKoTZ4xnz1B",
        "outputId": "dda3cfb5-e798-45f7-a0bd-74d99f6a8d79"
      },
      "source": [
        "# TRANSFORMING TO 575 FEATURES: genius 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=575).fit_transform(genius, genius_scores['tripartite_score'])\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44537815126050423"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0hdDIJHnj9n",
        "outputId": "b6f2c23e-8c23-4c5a-999c-f204b0b94525"
      },
      "source": [
        "# TRANSFORMING TO 700 FEATURES: genius 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=700).fit_transform(genius, genius_scores['tripartite_score'])\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44057623049219685"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTk5OCUDnmMx",
        "outputId": "8300f355-4e8c-4c76-a306-ea6dd87d4600"
      },
      "source": [
        "# TRANSFORMING TO 650 FEATURES: genius 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=650).fit_transform(genius, genius_scores['tripartite_score'])\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44537815126050423"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txQ5XAZInpLI",
        "outputId": "b8031537-2844-4259-d943-f7356f879879"
      },
      "source": [
        "# TRANSFORMING TO 800 FEATURES: genius 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=800).fit_transform(genius, genius_scores['tripartite_score'])\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.437374949979992"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwBBcggtnsKX",
        "outputId": "9b79b721-80ed-4dcd-8004-7ddd9ea46d74"
      },
      "source": [
        "# TRANSFORMING TO 500 FEATURES: genius 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=500).fit_transform(genius, genius_scores['tripartite_score'])\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, genius_scores['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4361744697879152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5KElAe_v475",
        "outputId": "1a98b2df-d7a2-4617-a10c-c45894bd40cb"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one scaled 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=85).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45487715884213087"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HIMWb32EAW5",
        "outputId": "152e3179-c5ed-4ac2-c874-3e7865ec4cdd"
      },
      "source": [
        "# TRANSFORMING TO 90 FEATURES: the real one scaled 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(k=90).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45803940647044517"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE1ALc7RxSBs",
        "outputId": "dfc0e339-8033-43d2-9e73-7dab75bb23c9"
      },
      "source": [
        "# TRANSFORMING TO 90 FEATURES: the real one scaled 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(score_func=f_regression,k=90).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45803940647044517"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5YEjy-fw8NT",
        "outputId": "c0de0837-c473-44fe-d89f-c66cec998973"
      },
      "source": [
        "# TRANSFORMING TO 90 FEATURES: the real one scaled 3 buckets\n",
        "X_new_scaled_3_65 = SelectKBest(chi2, k=90).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_65, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=10000).fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning: Rounding errors prevent the line search from converging\n",
            "  warn(msg, LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45803940647044517"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKylfCc71TOr"
      },
      "source": [
        "df.to_csv('BEST_X.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "CNp8MDbdzEy5",
        "outputId": "54cebd1a-7c44-43d1-c15b-a1b762e89804"
      },
      "source": [
        "confusion_matrix_metric(y_test, predictions, ['0', '1', '2'], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[700 433 323]\n",
            " [471 596 335]\n",
            " [320 325 608]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "Rdv1rfsRzQeD",
        "outputId": "8d542af3-dca8-45c9-8a9b-1320a7691402"
      },
      "source": [
        "classification_scores(predictions, y_test, ['0', '1', '2'], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.48      0.48      1456\n",
            "           1       0.44      0.43      0.43      1402\n",
            "           2       0.48      0.49      0.48      1253\n",
            "\n",
            "    accuracy                           0.46      4111\n",
            "   macro avg       0.46      0.46      0.46      4111\n",
            "weighted avg       0.46      0.46      0.46      4111\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.47      0.48      0.48      1456\\n           1       0.44      0.43      0.43      1402\\n           2       0.48      0.49      0.48      1253\\n\\n    accuracy                           0.46      4111\\n   macro avg       0.46      0.46      0.46      4111\\nweighted avg       0.46      0.46      0.46      4111\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsQ9W2WRtZ4K",
        "outputId": "bf7480f9-9ec2-483b-c389-7ba07195f89e"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=85).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45560690829481876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsfX7vgyF4dL",
        "outputId": "9d911c12-026c-447a-9a8e-54dab4f159cb"
      },
      "source": [
        "# TRANSFORMING TO 300 FEATURES: da big man 3 buckets\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=300).fit_transform(big_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4147409389442958"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsrNzcQVF_a1",
        "outputId": "12c79321-c4c5-47f1-efbe-89b7b761e089"
      },
      "source": [
        "# TRANSFORMING TO 300 FEATURES: da big man scaled 3 buckets\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=300).fit_transform(scaled_big_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.13524e-80): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4174166869374848"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct5ahcyFGDMZ",
        "outputId": "9f230cf7-3e8e-4fe8-fc04-c4f17f16f372"
      },
      "source": [
        "# TRANSFORMING TO 400 FEATURES: da big man scaled 3 buckets\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=400).fit_transform(scaled_big_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.95196e-81): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42811967891024083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNtmou9bGGRe",
        "outputId": "5e8014e2-21e1-4e92-aedd-199fd546c046"
      },
      "source": [
        "# TRANSFORMING TO 450 FEATURES: da big man scaled 3 buckets\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=450).fit_transform(scaled_big_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.07592e-81): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4307954269034298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAwqMmC9GJIx",
        "outputId": "ffad7923-5e9e-452a-81e7-0ffaa065fdf0"
      },
      "source": [
        "# TRANSFORMING TO 475 FEATURES: da big man scaled 3 buckets\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=475).fit_transform(scaled_big_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.22335e-82): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4327414254439309"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RHl3WPStnyE",
        "outputId": "9c590f18-16a3-438b-95dc-f22b3f2d0ac7"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=75).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4432011675991243"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_giPKHmtrqv",
        "outputId": "583b4e76-2101-4a82-f315-fcff74ee49c8"
      },
      "source": [
        "# TRANSFORMING TO 85 FEATURES: the real one 3 buckets\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=70).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = RidgeClassifier().fit(X_transformed_train, y_train)\n",
        "predictions = clf.predict(X_transformed_test)\n",
        "num_score = clf.score(X_transformed_test, y_test)\n",
        "num_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4470931646801265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kL__jJGzd88",
        "outputId": "c89e1d1c-cd59-47e1-f64c-2d036c4df6e9"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=70).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4147409389442958"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhGncPkzz6LI",
        "outputId": "c259855b-a840-4840-8100-716a80e60678"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=85).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42033568474823646"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfzwQOcwz8WJ",
        "outputId": "17664c74-69fe-4353-9f0c-dcbb1531e6d8"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=60).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = PassiveAggressiveClassifier(max_iter=10000, random_state=0)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4176599367550474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYtVHWluz-LZ",
        "outputId": "ae88e669-2611-443f-e093-94aa5dfc1a6d"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=70).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.41303819022135735"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx2pKLHPv18c",
        "outputId": "0a6fbdc1-dd9b-4253-f85c-63aa1d2107c9"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(k=70).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36682072488445633"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pf2nb5h0HSq",
        "outputId": "0737b03f-6d9a-4109-fe9f-73da473cca5c"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=85).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38141571393821455"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdJ6wtjH0JWk",
        "outputId": "0f1378f1-79f0-435a-e450-f897066274fa"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=60).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39941620043784964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmfnYq_B0M37",
        "outputId": "12d32880-bae6-4c0a-b158-d33d84b12780"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=50).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = Perceptron(random_state=0, max_iter=10000)\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3899294575529068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEPZsOjO0TCQ",
        "outputId": "c3fb2f1d-ee1a-4bc3-fd15-cdc1f0c9fe1f"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=50).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.38214546339090244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7QiO0eB2PKE",
        "outputId": "6d5630da-9754-4af9-8c0c-5ce3b4b44be0"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=75).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42520068109948916"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_vAC8AL0Fcm",
        "outputId": "efad0018-c58e-4297-cb56-003fecce4589"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(k=75).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4288494283629287"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH-gyuJR2ZfX",
        "outputId": "a0c45851-da3c-41eb-8ef7-8a0420fd8210"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=65).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.421308684018487"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtLwVGSC0JuS",
        "outputId": "ec1257ed-a793-4cdd-f0dc-25689767c928"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(k=65).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42179518365361224"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d95n-IKV0Mmx",
        "outputId": "57a7e385-79ce-4e7d-fdc0-a79985aa2b37"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(k=85).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42836292872780346"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7sMBp5D2eaw",
        "outputId": "9da3ce92-9c8d-4257-984c-37ebd2ac72a1"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=85).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42714667963999026"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l72rpyHoD2eb",
        "outputId": "8307c0b0-f9e2-439e-c419-66c7bed5c3a5"
      },
      "source": [
        "# DA BIG MAN SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=85).fit_transform(scaled_big_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3626854779858915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4iLCYOfD8QO",
        "outputId": "7ba22b80-6b79-4116-b6d6-219f3709eda9"
      },
      "source": [
        "# DA BIG MAN SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(k=85).fit_transform(scaled_big_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4188761858428606"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpz-9ao22gOF",
        "outputId": "b2b221b5-e175-49ff-e23b-93e6a04b5551"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=90).fit_transform(scaled_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4254439309170518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3r_A02nDwaq",
        "outputId": "e08146b5-13af-42dd-a538-585c5de203f0"
      },
      "source": [
        "# DA BIG MAN SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=90).fit_transform(scaled_big_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3626854779858915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-6G7J4B2ikR",
        "outputId": "55c68490-b876-4e4b-af8a-8a6e13e6b3fc"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=90).fit_transform(big_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40184869861347605"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlZooecwGYDz",
        "outputId": "7758cac2-9fbb-48ff-98dc-0ba2d99f05d9"
      },
      "source": [
        "# DA BIG MAN SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(k=90).fit_transform(big_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4188761858428606"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGF4xsAnGceb",
        "outputId": "daf2acb4-f9e0-4c97-dd8e-15f843ba0300"
      },
      "source": [
        "# THE REAL ONE SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(k=80).fit_transform(scaled_big_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4181464363901727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw8sVn0G3IdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3fd91ce-3bb3-4c6b-925e-82f35c1686da"
      },
      "source": [
        "# THE BIG ONE SCALED SCALED: 3 BUCKETS\n",
        "X_new_scaled_3_85 = SelectKBest(chi2, k=90).fit_transform(scaled_big_x, y_3)\n",
        "X_transformed_train, X_transformed_test, y_train, y_test = train_test_split(X_new_scaled_3_85, the_real_one['tripartite_score'], test_size=0.25, random_state=22)\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_transformed_train, y_train)\n",
        "clf.predict(X_transformed_test)\n",
        "clf.score(X_transformed_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3626854779858915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    }
  ]
}